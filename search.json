[
  {
    "id": 0,
    "title": "Architecture",
    "url": "/technology/architecture/architecture.html",
    "content": "[TOC]\n# SDLC\n\n## Continuous integration\n* Hudson / Jenkins\n* TeamCity\n* CruiseControl\n* Ivy\n\n## Code Analysis\n* Emma\n* Corbetura/Clover\n* Fortify\n* JDepend\n* FindBugs\n* SONAR\n\n## Code Metrics\n\n* Novel way to visualize whole project, package structure & lines of code - http://redotheweb.com/CodeFlower/\n* Cyclomatic Complexity - \n  * http://www.onjava.com/lpt/a/4917\n  * http://c2.com/cgi/wiki?CyclomaticComplexityMetric\n  * http://www.guru99.com/cyclomatic-complexity.html\n\n\n\n## Development Methodologies\nhttp://en.wikipedia.org/wiki/List_of_software_development_philosophies\n\n### Agile\n\n\n### XP\n\n\n### Scrum\n\n\n### KanBan\n\n## Architecture Patterns\n\n### Domain Driven Design\n\n**Tutorial**\n* [Part 1: Domain-Driven Design and MVC Architectures](http://blog.fedecarg.com/2009/03/11/domain-driven-design-and-mvc-architectures/)\n* [Part 2: Domain-Driven Design: Data Access Strategies](http://blog.fedecarg.com/2009/03/12/domain-driven-design-and-data-access-strategies/)\n* [Part 3: Domain-Driven Design: The Repository](http://blog.fedecarg.com/2009/03/15/domain-driven-design-the-repository/)\n* [Part 4: Sample Application](http://blog.fedecarg.com/2009/03/22/domain-driven-design-sample-application/)\n\n#### Domain Model\n\n* Responsible only represent the concepts of the business, information about business situations and business rules\n* Named after the nouns in domain space\n* Should have both data and behaviour (basic idea of object oriented design)\n* well connected with other domain objects with relationship and structure\n* Examples of behaviour - validations, calculations, business rules\n* Only business logic - no persistence or presentation logic\n* Completely persistance Ignorant (Mithra domain model breaks this)\n* When to use?\n* When NOT to use?\n\n#### Value Objects\n\n* 2 value objects are equal if all their fields are equal. Although all fields are equal, you don't need to compare all fields if a subset is unique - for example currency codes for currency objects are enough to test equality\n* Should be immutable\n* A value object should always override .equals() & .hashCode() in Java\n* http://c2.com/cgi/wiki?ValueObject\n* Diff between Value objects and Domain objects?\n\n#### Data Transfer Object\n\n* Simply contain for a set of aggregated data that needs to be transfered across process or network boundary\n* holds only data - no business logic\n* Needs to be serializable to work with remote interfaces\n* Usually an assembler is used to transfer data between DTOs and Domain objects\n\n#### Service Layer\n\n* Service layer on top of 'Behaviourally rich domain model' is recommended\n* Should be a thin layer\n\n#### Anemic Domain Model (Anti-pattern)\n\n* Objects which has only data but no business logic. \n* All the business logic is implemented in a separate 'Service Layer' - Domain model is used only for data\n* Incurs all the cost of domain model - No benefits\n* Cost related to mapping to database\n\n\nMartin Fowler - Service Layer, Model Layer\nEric Evans - Application Layer, Domain Layer\n\n\n### Domain Specific Language (DSL)\n\n* Writing internal DSL in Java - http://jmock.org/oopsla2006.pdf\n* http://blog.jooq.org/2012/01/05/the-java-fluent-api-designer-crash-course/\n* http://www.infoq.com/articles/internal-dsls-java\n* http://weblogs.java.net/blog/carcassi/archive/2010/02/04/building-fluent-api-internal-dsl-java\n\n### Naked Objects Pattern\n\n## Programming Paradigms\n### Aspect Oriented Programming (AOP)\n### Functional Programming\n### MDD - Model Driven Design\n### TDD - Test Driven Design\n### FDD - Feature Driven Development\n\n\n# Bibliography\n\n* Patterns of Enterprise Application Architecture - Martin Fowler \n* http://martinfowler.com/bliki/ValueObject.html\n* http://martinfowler.com/eaaCatalog/dataTransferObject.html\n* http://java.sun.com/blueprints/patterns/TransferObject.html\n"
  },
  {
    "id": 2,
    "title": "Big Data",
    "url": "/technology/bigdata.html",
    "content": "[TOC]\n\n# Big Data Concepts\n\n* Large data processing in low latency\n* Process unstructured data\n* 3Vs of Big Data - Volume, Velocity and Variety\n* [7Vs of Big Data](http://fizalihsan.wordpress.com/2014/01/02/7vs-of-big-data-briefly/) - Volume, Velocity and Variety, Veracity, Variability, Visualization and Value\n* Why Big Data?\n  * Old data mining systems were expensive, not easily scalable\n* Scaling concepts\n  * Scale Up\n    * When volume of data increases, add computing power to a single server or move to a bigger server.\n    * Pros: no change in architecture needed.\n    * Cons: there are limitation on how big a single host can be.\n  * Scale Out\n    * Processing is handled by more than 1 server. When data volume increases, add more servers to the farm.\n    * Pros: Cheaper purchase costs than scale up, High availability\n    * Cons: complex data processing stratagies involved.\n    * Features: smart-software-dumb-hardware, move-processing-not-data.\n    * Challenges: Bottlenecks, increased risk of failure\n* Consistency - CAP theorem\n* Caching\n* Adhoc query\n* Sharding\n* Replication\n* Fault tolerance\n\n# MapReduce (Programming Model)\n\n> Source: Hadoop Operations -OReilly\n\n\n* Designed to simplify the development of large-scale, distributed, fault-tolerant data processing applications\n* In MapReduce, developers write jobs that consist primarily of a map function and a reduce function, and the framework handles the gory details of parallelizing the work, scheduling parts of the job on worker machines, monitoring for and recovering from failures, and so forth.\n* User-provided code is invoked by the framework rather than the other way around.\n* Features\n  * **Simplicity of development** - Developers use functional programming concepts to operate on one record at a time. Map functions operate on these records and produce intermediate key-value pairs. The reduce function then operates on the intermediate key-value pairs, processing all values that have the same key together and outputting the result. These primitives can be used to implement filtering, projection, grouping, aggregation, and other common data processing functions.\n  * **Scalability** - MapReduce is designed to be a 'share-nothing' system. Since tasks are independent, they can run in parallel in one or more machines.\n  * **Automatic parallelization and distribution of work** -  Developers focus on the map and reduce functions that process individual records (where “record” is an abstract concept—it could be a line of a file or a row from a relational database) in a dataset. The storage of the dataset is not prescribed by MapReduce, although it is extremely common, as we’ll see later, that files on a distributed filesystem are an excellent pairing. The framework is responsible for splitting a MapReduce job into tasks. Tasks are then executed on worker nodes or (less pleasantly) slaves.\n  * **Fault Tolerance** - MapReduce treats failure as a first-class citizen and supports reexecution of failed tasks on healthy worker nodes in the cluster. Should a worker node fail, all tasks are assumed to be lost, in which case they are simply rescheduled elsewhere.\n\n\n# Big Data Ecology\n## Apache Hadoop\n\n* Hadoop is an open source platform that provides implementations of both the MapReduce and GFS (Google File System) technologies and allows the processing of very large data sets across clusters of low-cost commodity hardware.\n* The terms host or server refer to the physical hardware hosting Hadoop's various components. The term node will refer to the software component comprising a part of the cluster.\n* Where Hadoop is not a good fit?\n  * not well suited for low-latency queries like websites, real time systems, etc. (HBase on top of Hadoop serves low-latency queries)\n  * smaller data sets.\n* The term *Hadoop Streaming* refers to a mechanism allowing scripting languages to be used to write map and reduce tasks\n* Hadoop installation consists of four types of nodes—a NameNode, DataNodes, a JobTracker, and TaskTracker HDFS nodes (NameNode and DataNodes) provide a distributed filesystem where the JobTracker manages the jobs and TaskTrackers run tasks that perform parts of the job. Users submit MapReduce jobs to the JobTracker, which runs each of the Map and Reduce parts of the initial job in TaskTrackers, collects results, and finally emits the results.\n\n### HDFS (Hadoop Distributed File System)\n\n* is a distributed filesystem that can store very large data sets by scaling out across a cluster of hosts. It has specific design and performance characteristics; in particular, it is optimized for throughput instead of latency, and it achieves high availability through replication instead of redundancy.\n* similar to any other linux file system like ext3 - but cannot be mounted - and requires applications to be specially built for it.\n* Block size in old file systems are typically 4KB or 8KB of size. In HDFS, it is 64MB to 1GB.\n* Replicates each block to multiple machines (default 3) in the cluster. Should the number of copies of a block drop below the configured replication factor, the filesystem automatically makes a new copy from one of the remaining replicas. \n* Due to replicated data, failures are easily tolerated.\n* not a POSIX-compliant filesystem.\n* HDFS is optimized for throughput over latency; it is very efficient at streaming read requests for large files but poor at seek requests for many small ones.\n\n{% img right /technology/hadoop-server-roles.png %}\n\n### Daemons\n\n* Namenode (NN)\n  * 1 per cluster\n  * Purpose: Stores filesystem metadata, stores file to block map, and provides a global picture of the filesystem\n* Secondary namenode (SNN)\n  * 1 per cluster (better not to share machine with NameNode)\n  * Purpose: Performs internal namenode transaction log checkpointing\n* DataNode \n  * Many per cluster\n  * Purpose: Stores block data (file contents)\n* Each storage node runs a process called a DataNode that manages the blocks on that host, and these are coordinated by a master NameNode process running on a separate host.\n* Instead of handling disk failures by having physical redundancies in disk arrays or similar strategies, HDFS uses replication. Each of the blocks comprising a file is stored on multiple nodes within the cluster, and the HDFS NameNode constantly monitors reports sent by each DataNode to ensure that failures have not dropped any block below the desired replication factor. If this does happen, it schedules the addition of another copy within the cluster. (include archictecture diagram from internet)\n* The master (NameNode) monitors the health of the cluster and handle failures by moving data blocks around.\n* Processes on each server (DataNode) are responsible for performing work on the physical host, receiving instructions from the NameNode nd reporting health/progress status back to it.\n* NameNode Federation - Since NameNodes keep all the metadata in memory, there is inherent limitation up to which it can scale up. Scaling out with multiple namenodes is called namenode federation\n* HDFS interface\n  * HDFS shell\n  * Java API\n  * REST API - WebHDFS, HttpFS(standalone RESTful HDFS proxy service) \n\n### MapReduce (Hadoop Implementation)\n\n* is a data processing paradigm that takes a specification of how the data will be input and output from its two stages (called map and reduce) and then applies this across arbitrarily large data sets. MapReduce integrates tightly with HDFS, ensuring that wherever possible, MapReduce tasks run directly on the HDFS nodes that hold the required data.\n* Concepts\n  * concepts of functions called map and reduce come straight from functional programming languages where they were applied to lists of input data.\n  * divide and conquer\", where a single problem is broken into multiple individual subtasks. This approach becomes even more powerful when the subtasks are executed in parallel;\n* Unlike traditional relational databases that require structured data with well-defined schemas, MapReduce and Hadoop work best on semi-structured or unstructured data.\n* Instead of data conforming to rigid schemas, the requirement is instead that the data be provided to the map function as a series of key value pairs. The output of the map function is a set of other key value pairs, and the reduce function performs aggregation to collect the final set of results.\n* Hadoop provides a standard specification (that is, interface) for the map and reduce functions, and implementations of these are often referred to as mappers and reducers. A typical MapReduce job will comprise of a number of mappers and reducers, and it is not unusual for several of these to be extremely simple. The developer focuses on expressing the transformation between source and result data sets, and the Hadoop framework manages all aspects of job execution, parallelization, and coordination.\n* The master (JobTracker) monitors the health of the cluster and handle failures by rescheduling failed work.\n* Processes on each server (TaskTracker) are responsible for performing work on the physical host, receiving instructions from the JobTracker, and reporting health/progress status back to it.\n\n## HCatalog\n\n* provides one consistent data model for various Hadoop tools.\n* provides a shared schema.\n* allows users to see when shared data is available.\n* decouples tools like Pig and Hive from data location, data format, etc.\n* Based currently on Hive's metastore.\n\n## Hive\n\n* Hive is a data warehouse system layer build on Hadoop.\n* Allows you to define a structure for your unstructured Big Data.\n* Simplifies analysis and queries with an SQL-like scripting language called HiveQL for adhoc querying on HDFS data.\n* Hive is \n  * not a relational database. It uses a database to store metadata, but the data that Hive processes is stored in HDFS.\n  * not designed for online transaction processing. not suited for real-time queries and row-level updates. \n* Components\n  * CLI, Web interface (Beeswax?), Micrsoft HDInsight\n* When to use Hive? \n  * for adhoc querying; for analysts with SQL familiarity\n* HiveQL - SQL-like syntax. based on SQL-92 specification.\n* Hive Table\n  * A Hive Table consists of (1) Data: typically a file or group of files in HDFS (2) Schema: in the form of metadata stored in a database\n  * Schema and data are separate\n  * A schema can be defined for existing data; Data can be added/removed independently; Before querying data in HDFS using Hive, a schema needs to be defined.\n\n## Pig\n\n3 components of Pig: \n\n### 1. Pig Latin\n* High level scripting language to describe data flow - statements translate into a series of MapReduce jobs - can invoke Java, JRuby or Jython programs and vice versa - User defined functions (UDF) can be written in Java and uploaded as jar.\n* Sample Pig Latin script\n```\n a = LOAD 'nyse_stocks' using org.apache.hcatalog.pig.HCatLoader();\n b = filter a by stock_symbol == 'IBM';\n c = group b all;\n d = foreach c generate AVG(b.stock_volume);\n dump d;\n```\n\n* Pig Latin script describes a DAG (directed acyclic graph) - http://vkalavri.com/tag/apachepig/\n* Pig script is not converted to a MapReduce job unless a DUMP/STORE command is invoked.\n```\n runs = foreach batting generate $0 as playerID, $1 as year, $8 as runs;\n (playerID,yearID,R)\n (john,2008,10)\n (john,2009,22)\n (john,2010,0)\n (adam,2008,58)\n (adam,2009,105)\n (adam,2010,106)\n (adam,2011,118)\n\n grp_data = group runs by (year);\n (2008, [(john,2008,10), (adam,2008,58)])\n (2009, [(john,2009,22), (adam,2009,105)])\n (2010, [(john,2010,0),  (adam,2010,106)])\n (2011, [(adam,2011,118)])\n```\n\n### 2) Grunt\nInteractive command-line shell\n\n### 3) Piggybank\n* A repository to store the UDFs\n* When to use Pig?\n  * for ETL purposes; for preparing data for easier analysis; when you have a long series of steps to perform.\n* Data Model difference b/w Pig and Hive\n  * In Pig, data objects exist and are operated on in the script. They are deleted after the script completes. They can be stored explicitly for later use.\n  * In Hive, data objects exist in Hadoop data store. After every line of execution, results are stored in Hadoop which can be useful for debugging.\n\n# Clustering\n\n* What is Clustering\n* How clustering works\n* Why clustering\n* Terms to know\n* Failover\n* Replication\n* Scalability vs. High availability\n* Physical node vs. virtual node\n* Quorum\n* Load balancing\n\n\n# Bibliography\n\n* Hadoop\n  * Hadoop Beginner's Guide\n* Clustering\n  * http://publib.boulder.ibm.com/infocenter/iseries/v5r4/index.jsp?topic=%2Frzaig%2Frzaigconceptsbasiccluster.htm\n  * http://www.slideshare.net/yashamwan/cluster-16097908?from_search=9\n  * http://www.slideshare.net/itsec/clustering-and-high-availability"
  },
  {
    "id": 3,
    "title": "Coding Principles",
    "url": "/technology/architecture/coding-principles.html",
    "content": "[TOC]\n\n## Excerpts from book 'Clean Code - A Handbook of Agile Software Craftmanship - Bob Martin'\n\n### Chapter 2 - Naming\n* Don't reveal implementation detail in variables. e.g., declare accounts instead accountList\n* Use single letter variables only as a local variable\n* No need for prefix on variables and class names. e.g., ICustomer interface\n* Class name should NOT be a verb. Avoid words like Manager, Processor, Data or Info\n* Use a common word per concept across method names and class names. e.g., fetch(), get(), retrieve(). Stick to one.\n\n### Chapter 3 - Function\n* Function should one thing only. One level of abstraction per function.\n* Switch statement - tolerated if it appears only once at very low level. Hide it with 'AbstractFactory' and polymorphism.\n* Function arguments\n  * Number of arguments\n    * Niladic (zero args) - Best\n    * Monadic (1) - Better\n    * Dyadic (2) - Good\n    * Polyadic (multiple) - Needs good justification\n  * Avoid functions with output arguments. e.g., public boolean foo(String input, String output);\n  * Passing flags as arguments is ugly. Based on the flag value, the function might perform one or more things. .e.g., render(boolean isSuite). Split the logic into renderForSuite() and renderForSingleTest() to make it explicit.\n  * Ambiguity issue with dyadic or polyadic functions with same type of arguments. e.g, assertEquals(int expected, int actual). Make function explicit as assertExpectedEqualsActual(int, int).\n  * Fix for polyadic functions\n    * Club the different arguments into an object and pass that object as input argument\n    * Or, make those arguments are field variables. (only for private functions)\n* **Side effects**\n  * A function promises to do one thing, but it also does other hidden things. e.g., checkPassword(String user, String password) method which authenticates and initializes a user session. Session initialization part is hidden from user.\n  * Side effects create temporal couplings and order dependencies. Temporal couplings mean that the function can only be invoked at certain times. In the above example, if it is called out of order the current session data might be destroyed.\n* **Double take** - Any line of code within function forces you to look at the function signature, then it is called \"double take\".\n* **Prefer exceptions to return error codes** - Function should do one thing. Error handling is another thing. Extract try..catch in a separate function.\n\n```\n if (delete(page) == OK){\n       ....\n } else {\n       Error out\n }\n```\n\n```\ntry{\n   ...\n } catch (...){\n    //Error processing is separated from the happy path\n } \n```\n* **Command Query Separation***: Functions should either do something or return something, but not both.\n  * http://martinfowler.com/bliki/CommandQuerySeparation.html\n"
  },
  {
    "id": 4,
    "title": "Coding Bibliography",
    "url": "/technology/coding_bibliography.html",
    "content": "[TOC]\n\n# Craftsmanship\n\n1. 97 Things Every Programmer Should Know\n* Algorithms of the Intelligent Web\n* Beautiful Code\n* Clean Code: A Handbook of Agile Software Craftsmanship\n* Code Complete, Second Edition\n* Code Simplicity\n* Coders at Work: Reflections on the Craft of Programming\n* Design Patterns\n* Design Patterns For Dummies\n* Design Patterns: Elements of Reusable Object-Oriented Software\n* Domain-Driven Design: Tackling Complexity in the Heart of Software\n* ESSENTIALS OF software engineering\n* Head First Design Patterns\n* Head First Object-Oriented Analysis and Design\n* Head First Software Development\n* Mythical Man-Month, The: Essays on Software Engineering, Anniversary Edition\n* Program Development in Java: Abstraction, Specification, and Object-Oriented Design\n* Refactoring to Patterns\n* Refactoring: Improving the Design of Existing Code\n* Software Development and Professional Practice\n* Software Engineering: Principles and Practice\n* The Art of Readable Code\n* The Clean Coder: A Code of Conduct for Professional Programmers\n* The Object-Oriented Thought Process, Third Edition\n* The Pragmatic Programmer: From Journeyman to Master\n* Think Complexity\n\n# Agile Development\n\n1. Agile Estimating and Planning\n* Agile Java Development with Spring, Hibernate and Eclipse\n* Agile Project Management: Creating Innovative Products, Second Edition\n* Agile Software Engineering with Visual Studio: From Concept to Continuous Feedback, Second Edition\n* Agile Software Requirements: Lean Requirements Practices for Teams, Programs, and the Enterprise\n* Agile Testing: A Practical Guide for Testers and Agile Teams\n* Clean Code: A Handbook of Agile Software Craftsmanship\n* Coaching Agile Teams: A Companion for ScrumMasters, Agile Coaches, and Project Managers in Transition\n* Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation\n* Disciplined Agile Delivery: A Practitioner’s Guide to Agile Software Delivery in the Enterprise\n* Effective Project Management: Traditional, Agile, Extreme\n* Essential Scrum: A Practical Guide to the Most Popular Agile Process\n* Lean Architecture for Agile Software Development\n* Lean-Agile Software Development: Achieving Enterprise Agility\n* Managing Software Requirements: A Use Case Approach, Second Edition\n* Mythical Man-Month, The: Essays on Software Engineering, Anniversary Edition\n* Professional Scrum with Team Foundation Server 2010\n* Rapid Development\n* Requirements Engineering Fundamentals\n* Running Lean, Second Edition\n* Software Requirements, Second Edition\n* The Art of Agile Development\n\n# Testing\n\n1. Advanced Automated Software Testing\n* Advanced Software Testing—Vol. 3\n* Agile Testing: A Practical Guide for Testers and Agile Teams\n* Beautiful Testing\n* Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation\n* Foundations of Software Testing: Fundamental Algorithms and Techniques\n* Growing Object-Oriented Software, Guided by Tests\n* How Google Tests Software\n* Lessons Learned in Software Testing: A Context-Driven Approach\n* Pragmatic Software Testing: Becoming an Effective and Efficient Test Professional\n* SOFTWARE TESTING: Interview Questions\n* Scrum in Action: Agile Software Project Management and Development\n* Software Testing Foundations, Third Edition\n* Software Testing, Second Edition\n* Test Driven Development: By Example\n* Test-Driven Infrastructure with Chef\n* xUnit Test Patterns: Refactoring Test Code\n\n# Build and Maintenance\n\n* Advanced Automated Software Testing\n* Code Complete, Second Edition\n* Growing Object-Oriented Software, Guided by Tests\n* Software Build Systems: Principles and Experience\n* Test Driven: Practical TDD and Acceptance TDD for Java Developers\n* Think Complexity\n\n# Architecture\n\n1. Patterns of Enterprise Application Architecture\n* Enterprise Integration Patterns: Designing, Building, and Deploying Messaging Solutions\n* Software Systems Architecture: Working with Stakeholders Using Viewpoints and Perspectives, Second Edition\n* HTML5 Architecture\n* Software Architecture in Practice, Second Edition\n* Service Design Patterns: Fundamental Design Solutions for SOAP/WSDL and RESTful Web Services\n* Service Oriented Architecture For Dummies, 2nd Edition\n* Sun Certified Enterprise Architect for Java EE Study Guide, Second Edition\n* Applying Domain-Driven Design and Patterns: With Examples in C# and .NET\n* Framework Design Guidelines: Conventions, Idioms, and Patterns for Reusable .NET Libraries, Second Edition\n* Service Management for Dummies\n* Lean Architecture for Agile Software Development\n* Advanced Internet Protocols, Services, and Applications\n* 97 Things Every Software Architect Should Know\n* The Architecture of Computer Hardware, System Software, and Networking: An Information Technology Approach, Fourth Edition\n* Beautiful Architecture\n* Implementing SOA Using Java EE\n* Applied SOA: SERVICE-ORIENTED ARCHITECTURE AND DESIGN STRATEGIES\n\n# Secure Coding\n\n1. Implementing SSL/TLS Using Cryptography and PKI\n* Security in Computing, Fourth Edition\n* The Basics of Hacking and Penetration Testing\n* Getting Started with OAuth 2.0\n* Metasploit\n* Gray Hat Hacking: The Ethical Hacker’s Handbook, Third Edition\n* Android Forensics: Investigation, Analysis, and Mobile Security for Google Android\n* Computer Security Fundamentals, Second Edition\n* Web Application Security\n* Hacking and Securing iOS Applications\n* Coding for Penetration Testers\n* Network Security Bible, 2nd Edition\n* Hacking: The Art of Exploitation, Second Edition\n* Analyzing Computer Security: A Threat/Vulnerability/Countermeasure Approach\n* Hacking Exposed Web Applications: Web Application Security Secrets and Solutions, Third Edition\n* Industrial Network Security\n* Writing Secure Code\n* Secure Programming with Static Analysis\n\n# References \n\n## Sites\n\n* Java - http://java.dzone.com/\n* Database - http://use-the-index-luke.com/\n* Design\n  * Patterns - http://www.sourcemaking.com\n  * http://www.martinfowler.com\n* Security\n  * http://www.itbriefcase.net/downloads/Beginners_Guide_to_SSL_Certificates_WP_en_AU.PDF\n  * http://www.itbriefcase.net/downloads/Fundamental_Principles_Network_Security_WP.pdf \n"
  },
  {
    "id": 5,
    "title": "Data Science Overview",
    "url": "/datascience/datascience.html",
    "content": "{% img /datascience/overview-mindmap.PNG %}\n\n# Bibliography\n## Books\n1. R in a Nutshell - A quick and practical reference to learn what is becoming the * standard for developing statistical software.\n* Statistics in a Nutshell - An introduction and reference for anyone with no * previous background in statistics.\n* Data Analysis with Open Source Tools - This book shows you how to think about * data and the results you want to achieve with it.\n* Programming Collective Intelligence - Learn how to build web applications that * mine the data created by people on the Internet.\n* Beautiful Data - Learn from the best data practitioners in the field about how * wide-ranging — and beautiful — working with data can be.\n* Beautiful Visualization - This book demonstrates why visualizations are * beautiful not only for their aesthetic design, but also for elegant layers of * detail.\n* Head First Statistics - This book teaches statistics through puzzles, stories, * visual aids, and real-world examples.\n* Head First Data Analysis - Learn how to collect your data, sort the distractions from the truth, and find meaningful patterns."
  },
  {
    "id": 6,
    "title": "Data Structures",
    "url": "/technology/datastructures.html",
    "content": "Data Structures\n\n* Heap sort visualization - http://www2.hawaii.edu/~copley/665/HSApplet.html\n* B+ tree & Balanced B+ tree - used in DB indexes\n* Red-Black tree - implemented in java.util.TreeMap\n* Basics\n* Iteration\n* Sorting\n* Hashing\n* Searching\n* [Guide - An Extensive Examination of Data Structures Using C# 2.0](http://msdn.microsoft.com/en-US/library/ms379570(v=vs.80).aspx)\n* http://www.mpi-inf.mpg.de/~mehlhorn/Toolbox.html \n* http://www.cs.auckland.ac.nz/software/AlgAnim/ds_ToC.html\n\n* List\n  * Array\n  * LinkedList\n  * Skiplist (invented by William Pugh - look paper on alternative to Binary Tree - learn the Java implementations - when to prepare this over Maps)\n* Trees (http://webdocs.cs.ualberta.ca/~holte/T26/top.realTop.html)\n  * Types\n  * Binary search tree (BST)\n  * Balanced tree or \n  * Height-balanced binary search tree (OR) AVL tree (after their Russian inventors  * Adelson-Velskii and Landis.)\n  * Self-balanced tree\n  * M-way trees\n  * B trees: Perfectly Height-balanced M-way search trees\n  * 2-3-4 trees\n  * Red-Black trees\n  * Heap\n  * Operations\n  * Insertion, Deletions\n  * Traversals - inorder, pre-order, post-order\n  * Tree Rotation\n* Graphs\n  * Types - Directed, Undirected, Weighted\n  * Operations\n  * Algorithms\n \n\n## Algorithms\n\n* Space-time complexity\n\n### Efficiency and Big-O notation\n\nA good algorithm is economical in its use of two resources: time and space. The O-notation is a way of describing the performance of an algorithm in an abstract way, without the detail required to predict the precise performance of a particular program running on a particular machine. Main reason for using it is that it gives us a way of describing how the execution time for an algorithm depends on the size of its data set, provided the data set is large enough.\n\n* How to calculate the BigO values?\n* Diff use cases - best case, worst case, amortized, probablistic???\n* [Informal Introduction to BigO notation](http://www.perlmonks.org/?node_id=227909) \n* **Common Big-O functions**\n\n| # | Time | Common Name     |Effect on running time if N is doubled|Example|\n| - | -----|-----------------|--------------------------------------|-------  |\n| 1 | O(1) |**Constant Time**|unchanged | insertion into a hash table |\n| 2 | O(log N) | **Logarithmic Time** | increased by a constant amount | insertion into a tree |\n| 3 | O(N) | **Linear Time** | Doubled e.g. linear search ||\n| 4 | O(N log N) | | doubled plus an amount proportional to N | merge sort|\n| 5 | O(N2) | **Quadratic Time** | Increases fourfold. | bubble sort |\n| 6 | | **Amortized Constant Time** | adding an element to the end of an ArrayList can normally be done in constant time, unless the ArrayList has reached its capacity. In that case, a new and larger array must be allocated, and the contents of the old array transferred into it. The cost of this operation is linear in the number of elements in the array, but it happens relatively rarely. In situations like this, we calculate the amortized cost of the operation—that is, the total cost of performing it n times divided by n, taken to the limit as n becomes arbitrarily large. In the case of adding an element to an ArrayList, the total cost for N elements is O(N), so the amortized cost is O(1). ([Wiki link](http://en.wikipedia.org/wiki/Big_O_notation#Orders_of_common_functions) for more examples)||\n\n* Download algorithms and solutions from book site : Cracking coding interviews"
  },
  {
    "id": 7,
    "title": "Design Principles",
    "url": "/technology/architecture/design-principles.html",
    "content": "[TOC]\n\n# Design Idioms\n\n* http://www.slideshare.net/nadeembtech/code-craftsmanship\n* Technical debt\n* Code smell\n* Orthogonal concerns (design & architecture)\n* RIA technolgies?\n* Data extraction patterns\n* Backward Compatibility (Refer to *Practical API Design - Confessions of a Java * Framework Architect*)\n  * Source Compatibility\n  * Binary Compatibility\n  * Functional Compatibility\n\n# API Design - Best Practices\n\n* Do not expose more than you want\n  * A method is better than a field\n  * A Factory is better than a constructor\n  * Make Everything final\n  * Do not put setters where they do not belong\n  * Give the creator of an object more rights\n  * Do not expose deep hierarchies\n* Code against Interfaces, not Implementations\n  * Removing a method or a field\n  * Removing or Adding a Class or an Interface\n  * Inserting an Interface or a Class into an Existing Hierarchy\n  * Adding a Method or a Field\n  * Comparing Java Interfaces and Classes\n  * Are Abstract Classes Useful?\n* Use Modular Architecture\n  * Cyclic dependencies\n\n# Interface \n\n## Interface Types\n\n(Refer to *Interface Oriented Design*)\n* Data Interfaces & Service Interfaces\n* Data Access Interface Structures\n  * Sequential Vs. Random retrieval\n  * Push & Pull Interfaces\n  * Alternative Interfaces\n* Stateless Vs. Stateful Interfaces\n\n## Properties of an Interface\n\n* Cohesiveness\n* Printer interface\n* Coupling\n* Minimal Vs. Complete\n* Complete Vs. Simple\n\n# 5 principles of class design (SOLID)\n\n1. **SRP** [The Single Responsibility Principle](https://docs.google.com/open?id=0ByOwmqah_nuGNHEtcU5OekdDMkk) - A class should have one, and only one, reason to change.\n* **OCP** [The Open Closed Principle](http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgN2M5MTkwM2EtNWFkZC00ZTI3LWFjZTUtNTFhZGZiYmUzODc1&hl=en) - You should be able to extend a classes behavior, without modifying it.\n* **LSP** [The Liskov Substitution Principle](http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgNzAzZjA5ZmItNjU3NS00MzQ5LTkwYjMtMDJhNDU5ZTM0MTlh&hl=en) - Derived classes must be substitutable for their base classes.\n* **ISP** [The Interface Segregation Principle](http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgOTViYjJhYzMtMzYxMC00MzFjLWJjMzYtOGJiMDc5N2JkYmJi&hl=en) - Make fine grained interfaces that are client specific.\n* **DIP** [The Dependency Inversion Principle](http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgMjdlMWIzNGUtZTQ0NC00ZjQ5LTkwYzQtZjRhMDRlNTQ3ZGMz&hl=en) - Depend on abstractions, not on concretions.\n\n# 6 principles of package design\n\nThe next six principles are about packages. In this context a package is a binary deliverable like a .jar file, or a dll as opposed to a namespace like a java package or a C++ namespace. \n\n## 3 principles of package cohesion\n\nThese principles are about package cohesion, they tell us what to put inside packages:\n\n1. **REP** [The Release Reuse Equivalency Principle](http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgOGM2ZGFhNmYtNmE4ZS00OGY5LWFkZTYtMjE0ZGNjODQ0MjEx&hl=en) - The granule of reuse is the granule of release.\n* **CCP** [The Common Closure Principle](http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgOGM2ZGFhNmYtNmE4ZS00OGY5LWFkZTYtMjE0ZGNjODQ0MjEx&hl=en) - Classes that change together are packaged together.\n* **CRP** [The Common Reuse Principle](http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgOGM2ZGFhNmYtNmE4ZS00OGY5LWFkZTYtMjE0ZGNjODQ0MjEx&hl=en) - Classes that are used together are packaged together.\n\n## 3 principles of package coupling\n\nThese principles are about the couplings between packages, and talk about metrics that evaluate the package structure of a system.\n\n1. **ADP** [The Acyclic Dependencies Principle](http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgOGM2ZGFhNmYtNmE4ZS00OGY5LWFkZTYtMjE0ZGNjODQ0MjEx&hl=en) - The dependency graph of packages must have no cycles.\n* **SDP** [The Stable Dependencies Principle](http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgZjI3OTU4ZTAtYmM4Mi00MWMyLTgxN2YtMzk5YTY1NTViNTBh&hl=en) - Depend in the direction of stability.\n* **SAP** [The Stable Abstractions Principle](http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgZjI3OTU4ZTAtYmM4Mi00MWMyLTgxN2YtMzk5YTY1NTViNTBh&hl=en) - Abstractness increases with stability.\n\n# Object Calisthenics\n\n* http://williamdurand.fr/2013/06/03/object-calisthenics/\n* http://www.slideshare.net/rdohms/bettercode-phpbenelux212alternate\n* https://github.com/TheLadders/object-calisthenics\n\n* **Rule 1**: One level of indentation per method\n  * Each method should do exactly one thing. \n  * How to fix it: Use the 'Extract Method' to pull out behaviors until your methods only have 1 level of indentation.\n* **Rule 2**: Don't use the ELSE keyword\n  * Every conditional branch creates confusion.\n  * How to fix it: Use polymorphism; Use the Null Object pattern.\n* **Rule 3**: Wrap all primitives and Strings\n  * If the variable of your primitive type has a behaviors, you MUST encapsulate it. And this is especially true for Domain Driven Design. DDD describes Value Objects like Money, or Hour for instance which expresses the intent explicitly.\n* **Rule 4**: First class collections\n* **Rule 5**: One dot per line\n* **Rule 6**: Don’t abbreviate\n* **Rule 7**: Keep all entities small\n* **Rule 8**: No classes with more than two instance variables\n* **Rule 9**: No getters/setters/properties\n\n# Law of Demeter (or Don't talk to strangers)\n\n???"
  },
  {
    "id": 8,
    "title": "Groovy",
    "url": "/technology/groovy.html",
    "content": "[TOC]\n\n# Overview\n\n* Use Groovy for flexibility and readability. Use Java for performance\n* Runs on JVM - Groovy is nothing but a new way of creating Java classes - Java code can be called from Groovy and vice-versa\n* Is type in Groovy synonymous to class in Java ?\n* Every Groovy type is a subtype of java.lang.Object - Every Groovy object is an instance of a type in the normal way\n* Groovy class IS A Java class\n* Groovy supports dynamic typing\n* To compile a Groovy script - `groovyc –d classes Foo.groovy`\n* To run a compiled Groovy class in Java - `java -cp $GROOVY_HOME/embeddable/groovy-all-1.0.jar:classes Foo`\n* To run a Groovy script - `groovy Foo.groovy`\n* Behind the scenes it compiles to a Java class and executes\n* Any Groovy code can be executed this way as long as it can be run; that is, it is either a script, a class with a main method, a Runnable, or a GroovyTestCase.\n* Groovy is purely object-oriented\n* everything is an object. E.g `2*3`, though they look like primitives, they are actually java.lang.Integer objects\n* every operator is a method call. E.g. `a+b` //logic for the + operator is implemented in method plus() on the object \n* Groovy automatically imports following packages: `groovy.lang.*, groovy.util.*, java.lang.*, java.util.*, java.net.*, and java.io.*` as well as the classes `java.math.BigInteger` and `BigDecimal`.\n* Say there is a Groovy class called Foo, we can use Foo objects without explicitly compiling the Book class as long as Foo.groovy is on the classpath.\n* A Groovy script can also have a class definition inside them.\n* **Scope**: Class and methods are public by default. Fields are private by default.\n\n# Fundamentals\n\n## Control Structure\n\n### Boolean Evaluation\n\n* Groovy’s `==` Is Equal to Java’s `equals()` only if the class does not implement the `Comparable` interface. If it does, then it maps to the class’s `compareTo()` method. \n* Reference comparison is done via `is()` method. Custom truth conventions can be added by implementing `asBoolean()` method.\n* **Groovy Truth** - Following evaluate to true : non-null references, non-empty strings or collections, non-zero numbers, and the boolean literal true.\n\n``` groovy\nstr = 'Hello'\nif(str) println str + 'World' //Groovy checks if the object reference is null\nlist = [1]\nif(list) println list //Groovy checks if list is not-null and not empty\n```\n\n### Operators\n\n#### Elvis operator / Safe-navigation operator (?.) \n\n* eliminates the mundane null check. If input is null, returns null instead of NPE.\n\n``` groovy\ndef foo(str) { if (str != null) { str.reverse() } } //Before\ndef foo(str) { str?.reverse() } //After\n```\n\n#### Spread-dot operator \n\nExample: `collections*.size()` - returns the size of each element in the collection\n\n#### Spaceship \n\n`obj1 <=> obj2` compares obj1 and obj2 through `compareTo()` method\n\n### Looping methods\n\n* Using Ranges: `for(i in 0..5){println i}  //prints 0,1,2,3,4`\n* Using times function: `5.times { println \"$it\" } //prints 0,1,2,3,4`\n* Using upto function: `0.upto(5) { println \"$it\" } //prints 0,1,2,3,4`\n* Using step function: `0.step(5, 2) { println \"$it\" } //prints 0,2,4`\n\n### Static imports\n\n``` groovy\nimport static Math.random as rand \ndouble value = rand() // alias name is used here to avoid confusion among static imports\n```\n\n## Exceptions\n\n* Not forced to catch exceptions we don't care. Any exception we don’t handle is automatically passed on to a higher level.\n* Catching all exceptions that may be thrown. (not Throwables or Errors) e.g., `try{...} catch(ex){...}`\n\n---\n\n## OOPS\n\n* All methods and classes are public by default.\n* Getters and setters are automatically created by Groovy. No setters created for final fields. To prevent non-final fields from modification, implement setter method manually and throw an error.\n* `\"hello\".class.name` instead of `\"hello\".getClass().getName()`. This class property has special meaning in Map and Builders so it won't work.\n* We can use 'this' within static methods to refer to the Class object.\n\n### Basics\n\n#### Optional Parameters\n\n* With Default value\n\n``` groovy\ndef log(x, base=10) { Math.log(x) / Math.log(base) }\nlog(1024) //default base 10 is used\nlog(1024, 2)\n```\n\n* Trailing array parameter as optional. Much like Java varargs.\n\n``` groovy\ndef task(name, String[] details) { println \"$name - $details\" }\ntask 'name1'\ntask 'name2', 'blah..'\ntask 'name3', 'blah..blah..'\n```\n\n#### Named arguments in method calls\n\n* Class with no-argument constructor\n\n``` groovy\nclass Robot { def type, height, width }\nrobot = new Robot(type: 'arm', width: 10, height: 40)\nprintln \"$robot.type, $robot.height, $robot.width\"\n```\n\n* Excess Parameters as Map - If the number of arguments sent is more than what the method parameters, and if the excess arguments are in name-value pair, then Groovy treats the name-value pairs as a Map.\n\n``` groovy\nclass Robot { \n  def access(location, weight, fragile) {\n    println \"Received fragile? $fragile, weight: $weight, loc: $location\"\n  }\n}\nnew Robot().access(x: 30, y: 20, z: 10, 50, true)\n//You can change the order\nnew Robot().access(50, true, x: 30, y: 20, z: 10, a:5)\n```\n\n#### Multiple Assignments\n\n* Method returning an array is assigned to multiple variables \n\n``` groovy\ndef splitName(fullName) { fullName.split(' ') }\ndef (firstName, lastName) = splitName('James Bond')\nprintln \"$lastName, $firstName $lastName\"\n```\n\n* Swapping two variables without a temporary variable using above technique\n\n``` groovy\ndef (first, last) = [\"James\", \"Bond\"]\n(first, last) = [last, first]\nprintln \"$first $last\"\n```\n\n#### Implementing Interface\n\n* Block of code morphed as the implementation of an interface\n\n``` groovy\ninterface Greeting { void greet(greeting) }\ninterface WellWisher { void wish(wish) }\nvoid greeter(Greeting greeting){ greeting.greet()}\nvoid wellwisher(WellWisher wellwisher){ wellwisher.wish()}\n\ngreeter(new Greeting(){ void greet(greeting){println 'Java style'}}) \ngroovyStyle = {println 'Groovy style'}\ngreeter(groovyStyle as Greeting) \n//block of code is morphed into an implementation of the\n// interface via 'as' operator\nwellwisher(groovyStyle as WellWisher) \n```\n\n* Groovy does not force us to implement all the methods in an interface. Very useful while mocking for unit testing.\n* Implementation of multi-method interface as a Map\n\n``` groovy\ninterface Greeting { void greet(greeting); void wish(wish); void regard(regard); }\nvoid callMe(Greeting greeting){ greeting.greet(); greeting.wish()}\n//method name as key, implementation as value. Not all methods are implemented\ngreetingsMap = [ greet: {println 'Greet Hello World'}, wish: {println 'Wish Hello World'} ] \ncallMe(greetingsMap as Greeting) \n```\n\n\n#### Operator Overloading\n\n* Each operator has a standard mapping to methods.\n\n``` groovy\n== equals\n+ plus\n- minus\n++ next\n.. next (for-each syntax)\n-- previous\n<< leftShift\n<=> compareTo\n```\n\n* Example 1: `for (ch in 'a'..'c') { println ch }`\n* Example 2: `lst = ['hello']; lst << 'there'; println lst`\n* Example 3: Custom class and operator overriding\n\n``` groovy\nclass Name{\n  def name; \n  def plus(other){\n    new Name(name: name + \"~~\" + other.name)\n  }\n  String toString() { \"name: \" + name}\n}\ndef name1 = new Name(name: \"Hello\")\ndef name2 = new Name(name: \"World\")\nprintln name1 + name2\n```\n\n### Duck typing \n\n* A static reference can only be assigned to an object of that type or one of its subclasses, or a class that implements that interface if the reference is of interface type. e.g., `Car car = `\n* In a dynamically typed language, however, we can have any classes stand in for another, as long as they implement the methods we need. e.g., in the below case, as long as the objects implement the method size() it will work.\n\n``` groovy\n//Duck typing example\ndef collection = \nprintln collection.size()\n```\n\n* if it walks like a duck, and quacks like a duck, then it is a duck.\n\n### Coercion\n\n* Implementing operators is straightforward when both operands are of the same type. Things get more complex with a mixture of types, say 1 + 1.0. One of the two arguments needs to be promoted to the more general type, and this is called coercion.\n* Closure Coersion - e.g. `Collections.sort(list, { ... } as Comparator)` \n  * closure here is coerced to implement interface Comparator\n  * if the interface has more than one methods, then pass different closure implementations as map\n\n* <span style=\"color:red\">Double dispatch???? - Need better description & example ????</span>\n\n* Examples\n\n``` groovy\n== equals\n+ plus\n- minus\n++ next\n-- previous\n<=> compareTo\n```\n\n\n### Strings\n\n* Plain strings (instance of java.lang.String)\n* GStrings (instance of groovy.lang.GString)\n* GStrings allow placeholder expressions to be resolved and evaluated at runtime. ( Also called String interpolation ) Placeholders may appear in a full `${expression}` syntax or an abbreviated $reference syntax.\n\n\n## POGOs\n\n* `object.property` - though this looks like accessing a private properties on the object, Groovy goes through the getter and setter methods provided in the class when it looks like properties are being accessed or assigned.\n* Map-based constructors\n  * `def faith = new Person(name:'Faith',id:1)` - By default, Groovy creates this map-based constructor. (Map is not used behind the implementation though)\n  * `def willow = [name:'Willow',id:2] as Person` - a map is coerced into an object\n\n## Arrays and Collection\n\n* Groovy supports collections at language level\n* Groovy supports generics but favors dynamic behavior. Compile-time type checking is turned off by default.\n\n### Arrays\n``` groovy\n[1,2,3] //Groovy treats this as list. \n[1,2,3] as int[] //Now the list is converted to an array here\n```\n\n### Ranges\n\nFor loops and conditionals are not objects, cannot be reused, and cannot be passed around, but ranges can. Ranges let you focus on what the code does, rather than how it does it. This is a pure declaration of your intent, as opposed to fiddling with indexes and boundary conditions.\n\nCustom Range - Any datatype can be used with ranges, provided that both of the following are true:\n\n1. The type implements next and previous; that is, it overrides the ++ and -- operators.\n2. The type implements java.lang.Comparable; that is, it implements compareTo, effectively overriding the `<=>` spaceship operator.\n\n### List\n\n* The sequence can be empty to declare an empty list. \n* Lists are by default of type `java.util.ArrayList` and can also be declared explicitly by calling the respective constructor. The resulting list can still be used with the subscript operator. In fact, this works with any type of list, as we show here with type `java.util.LinkedList`.\n* Lists can be created and initialized at the same time by calling `toList` on ranges.\n\n## Annotations / AST (Abstract Syntax Tree) Transformations\n\n* groovyc ignores @Override\n* `@Canonical` - auto-generates `toString()` implementation as comma-separated field values\n\n``` groovy\n import groovy.transform.*\n @Canonical(excludes=\"age, password\")\n class Person {\n String firstName, lastName, password\n int age\n }\n def sara = new Person(firstName: \"Sara\", lastName: \"Walker\", age: 49, password: \"passw0rd\")\n println sara\n```\n\n* `@Delegate`\n\n``` groovy\nimport groovy.transform.*\nclass Worker {\n def work() { println 'get work done' }\n def analyze() { println 'analyze...' }\n def writeReport() { println 'get report written' }\n}\nclass Expert {\n def analyze() { println \"expert analysis...\" }\n}\nclass Manager {\n //At compile time, Groovy examines the Manager class and brings \n // in methods from the delegated classes only if those methods \n // don’t already exist\n @Delegate Expert expert = new Expert() \n //only work() and writeReport() methods are brought here\n @Delegate Worker worker = new Worker()\n}\ndef bernie = new Manager()\nbernie.analyze()      //invokes Expert.analyze()\nbernie.work()         //invokes Worker.work()\nbernie.writeReport()  //invokes Worker.writeReport\n```\n\n* `@Immutable` - Groovy adds the hashCode(), equals(), and toString() methods\n``` groovy\n import groovy.transform.*\n @Immutable\n class CreditCard { String cardNumber; int creditLimit }\n println new CreditCard(\"4000-1111-2222-3333\", 1000)\n```\n\n* `@Lazy` - provides a painless way to implement the virtual proxy pattern with thread safety as a bonus\n\n``` groovy\n class AsNeeded {\n def value\n //heavy1 and heavy2 are lazy-initialized only at the time of invocation\n @Lazy Heavy heavy1 = new Heavy()\n @Lazy Heavy heavy2 = { new Heavy(size: value) }()\n AsNeeded() { println \"Created AsNeeded\" }\n }\n```\n\n* `@Newify` - Create objects via Ruby-like and Python-like constructors without using 'new Foo()' style. Comes handy in DSL creation.\n\n``` groovy\n@Newify([CreditCard, Person]) //specify the list of types here. \ndef fluentCreate() {\n println CreditCard(\"1234-5678-1234-5678\", 2000) //Python-like constructor invocation with new keyword\n println Person.new(\"John\", \"Doe\") //Ruby-like constructor invocation where new() is a method\n}\nfluentCreate()\n```\n\n* `@Singleton`\n\n``` groovy\n @Singleton(lazy = true)\n class TheUnique {\n  private TheUnique() { println 'Instance created' }\n def hello() { println 'hello' }\n }\n TheUnique.instance.hello()\n TheUnique.instance.hello()\n new TheUnique().hello() //Caveat: since Groovy does not honor private methods, clients can still do this.\n```\n\n* `@InheritConstructors`\n\n``` groovy\n @Canonical\n class Car {\n def make, model, year\n Car(make, model){ this.make = make; this.model = model; this.year = 2000; }\n Car(make, model, year){ this.make = make; this.model = model; this.year = year; }\n }\n @InheritConstructors\n class Honda extends Car{\n //no need to explicitly override all the constructors here\n }\n println new Car(\"Honda\", \"Accord\")\n```\n---\n\n## Closures\n\nIn OO languages, the Method-Object pattern has often been used to simulate the same kind of behavior by defining types whose sole purpose is to implement an appropriate single-method interface so that instances of those types can be passed as arguments to methods, which then invoke the method on the interface. e.g., `java.io.File.list(FilenameFilter)` where FilenameFilter interface specifies a single method, and its only purpose is to allow the list of files returned from the list method to be filtered while it’s being generated.\n\n\n# Groovy Metaprogramming\n\nIn Groovy every class has a metaclass. A metaclass is another class that manages the actual invocation process. If you invoke a method on a class that doesn’t exist, the call is ultimately intercepted by a method in the metaclass called `methodMissing`. Likewise, accessing a property that doesn’t exist eventually calls `propertyMissing` in the metaclass. Customizing the behavior of `methodMissing` and `propertyMissing` is the heart of Groovy runtime metaprogramming.\n\n\n``` groovy \"Example of meta-programming in Groovy\"\n\n/* Every closure has a delegate property. \nBy default the delegate points to the object that the closure was invoked on.\n*/\n\nComplex.metaClass.plus = { Complex c -> delegate.add c }\nComplex.metaClass.minus = { Complex c -> delegate.subtract c }\n\ndef c1 = new Complex(real: 1, imaginary: 2)\ndef c2 = new Complex(real: 3, imaginary: 4)\ndef c3 = c1 + c2\n\nprintln c3 == new Complex(real: 4, imaginary: 6)\n\n@EqualsAndHashCode\nclass Complex{\n    def real, imaginary\n\n    Complex add(Complex c){\n        this.real += c.real\n        this.imaginary += c.imaginary\n        this\n    }\n\n    Complex subtract(Complex c){\n        this.real -= c.real\n        this.imaginary -= c.imaginary\n        this\n    }\n\n    @Override\n    public String toString() {\n        return \"($real + ${imaginary}i)\"\n    }\n}\n```\n\n# Concurrency\n\n# DSL\n\n## Questions\n\n1. What is the difference between a Groovy script and a Groovy class?\n* how closure is better than an anonymous inner class?\n* what is a spaceship operator? <=>\n* how to implement dynamic parameters and method?\n* What is relaying and how dynamic typing enables to achieve it?\n* How to write new AST annotations?  \n* Spring + Groovy\n* 'Liquid Heart' technique by Dierk Koenig, lead author of Groovy in Action [Manning, 2007]\n* Groovy iteration patterns\n* JMX 2"
  },
  {
    "id": 11,
    "title": "",
    "url": "/index.html.old",
    "content": "<ul>\n  <li><a href=\"{{ root_url }}/datascience/statistics.html\">Statistics</a></li>\n  <li><a href=\"{{ root_url }}/datascience/r.html\">R Programming</a></li>\n</ul>\n"
  },
  {
    "id": 12,
    "title": "Search Results",
    "url": "/search/index.html",
    "content": "{% include custom/lunr-search/entries.html %}"
  },
  {
    "id": 14,
    "title": "Java Collections",
    "url": "/technology/java-collections.html",
    "content": "[TOC]\n\n\n# Generics\n\n## Types\n* Generic type - e.g., `List<T>`.\n* Specific type - `List<String>`.\n* Raw type - `List<T>` should be used along with an associated type like `List<String>`. If the associated type is not specified, then it is called raw type. e.g., `List list = new ArrayList();`\n* Type parameter - In `List<T>`, T is the type parameter\n* Wildcard parameters - `List<?>`. Here <?> stands for unknown type.\n* Bounded Wildcard parameters - `List<? extends X>` and `List<? super X>`\n\n* Reification\n\n## Subtyping Principle\n\n* Integer is a subtype of Number\n* Integer[] is a subtype of Number[]\n* List<E> is a subtype of Collection<E>\n* List<Integer> is NOT a subtype of List<Number>\n\n## Wildcard parameters\n\n> Note: When wildcard is used, only get operation is allowed - no mutable operations like add/put.\n\n| # | Type | Sample | Description | Get & Put principle |\n| - | - | - | - | - |\n| 1 | Generic Type | `List<T>`  | Only type T is allowed  | Both get and put of type T allowed on this collection. |\n| 2 | Unbounded wildcard | `List<?>` | Any type | Only get is allowed. <br/><p><code>List<?> nums = new ArrayList<Integer>(); <br/>nums.add(1); //not allowed <br/>nums.add(null); //exception: allowed </code></p> |\n| 3 | Wildcard with lower bound | `List<? extends T>` | Any subtype of T | Only get of any subtype of T is allowed <br/><p><code>List<? extends Number> nums = new ArrayList<Integer>(); <br/>nums.add(1); //not allowed <br/>nums.add(null); //exception: allowed </code></p> |\n| 4 | Wildcard with lower bound | `List<? super T>` | Any supertype of T | <br/><p><code>List<? super Integer> ints = Arrays.asList(1,2,3,4); <br/>Integer i = ints.get(1); //not allowed <br/>Object o = ints.get(1); //allowed </code></p> |\n| 5 | Multiple bounds | `List<? extends T & Comparable<T>>` | Only types that subclass T and implement Comparable. <br/>The first (leftmost) bound is a class or an interface; <br/>all remaining bounds must be interfaces. | Only *get* of any subtype of T and comparable is allowed |\n\n## Variance\n\n* **Covariant** - Java arrays are covariant, meaning that type S[] is considered to be a subtype of T[] whenever S is a subtype of T. Due to this nature, the following code throws exception at runtime. When an array is allocated (as on the first line), it is tagged with its reified type (a run-time representation of its component type, in this case, Integer), and every time an array is assigned into (as on the third line), an array store exception is raised if the reified type is not compatible with the assigned value (in this case, a double cannot be stored into an array of Integer).\n\n```java\nInteger[] ints = new Integer[] {1,2,3};\nNumber[] nums = ints;\nnums[2] = 3.14; //array store exception at runtime\n```\n\n* **Invariant** - Java Generics are invariant, meaning that type `List<S>` is not considered to be a subtype of `List<T>`, except in the trivial case where S and T are identical.\n\n```java\nList<Integer> ints = Arrays.asList(1,2,3);\nList<Number> nums = ints; // compile-time error\nnums.set(2, 3.14);\n```\n\n* **Contravariant** - Wildcards also introduce contravariant subtyping for generics, in that type `List<S>` is considered to be a subtype of `List<? super T>` when S is a supertype of T (as opposed to a subtype). Arrays do not support contravariant subtyping.\n\n> **Points to remember**\n> * Avoid mixing raw type and generic type.\n> * (T t = new T(); //not allowed, where T is a generic type\n> * Do not mix generics and varargs - http://www.javaspecialists.eu/archive/Issue140.html\n\n## Type Erasure\n\n* Example 1 is implemented using generics and #2 is not. However, the bytecode for both the programs are exactly the same. Java internally converts the generic representation into #2 model, by erasing the type details and adding casts. This is called 'type erasure'.\n* The reason behind such implementation is for backward compatibilty.\n\n```java Example 1\nList<String> words = new ArrayList<String>();\nwords.add(\"Hello \");\nwords.add(\"world!\");\nString s = words.get(0)+words.get(1); \nassert s.equals(\"Hello world!\");\n```\n\n```java Example 2\nList words = new ArrayList(); \nwords.add(\"Hello \"); \nwords.add(\"world!\"); \nString s = ((String)words.get(0))+((String)words.get(1));\nassert s.equals(\"Hello world!\");\n```\n\n# Collections Framework\n\n## Concurrent Collections\n\nThe latest concurrent collections achieve thread-safety by different mechanisms. \n\n* **Copy-On-Write**: Classes that use copy-on-write store their values in an internal array, which is effectively immutable; any change to the value of the collection results in a new array being created to represent the new values. \n  * Synchronization is used by these classes, though only briefly, during the creation of a new array; because read operations do not need to be synchronized, copy-on-write collections perform well in the situations for which they are designed—those in which reads greatly predominate over writes. \n* **Copy-on-write** is used by the collection classes `CopyOnWriteArrayList` and `CopyOnWriteArraySet`.\n  * **Compare-and-Swap (CAS)**: A second group of thread-safe collections relies on compare-and-swap (CAS), a fundamental improvement on traditional synchronization. To see how it works, consider a computation in which the value of a single variable is used as input to a long-running calculation whose eventual result is used to update the variable. Traditional synchronization makes the whole computation atomic, excluding any other thread from concurrently accessing the variable. This reduces opportunities for parallel execution and hurts throughput. An algorithm based on CAS behaves differently: it makes a local copy of the variable and performs the calculation without getting exclusive access. Only when it is ready to update the variable does it call CAS, which in one atomic operation compares the variable’s value with its value at the start and, if they are the same, updates it with the new value. If they are not the same, the variable must have been modified by another thread; in this situation, the CAS thread can try the whole computation again using the new value, or give up, or—in some algorithms— continue, because the interference will have actually done its work for it! \n  * Collections using CAS include `ConcurrentLinkedQueue` and `ConcurrentSkipListMap`.\n* **Lock interface**: The third group uses implementations of java.util.concurrent.locks.Lock interface. Some of the collection classes in this group make use of these facilities to divide the collection into parts that can be separately locked, giving improved concurrency. \n  * For example, `LinkedBlockingQueue` has separate locks for the head and tail ends of the queue, so that elements can be added and removed in parallel. \n  * Other collections using these locks include `ConcurrentHashMap` and most of the implementations of `BlockingQueue`.\n\n## Iterators\n\n* Purpose: The purpose of iterators is to provide a uniform way of accessing collection elements sequentially\n* Any class that implements `java.lang.Iterable` can be used in foreach statement. `Collection implements Iterable`.\n\n### Types\n\n#### Fail-fast iterators\n* Iterators throw `ConcurrentModificationException` whenever they detect that the collection from which they were derived has been structurally changed (i.e., elements have been added or removed). \n* Iterators are implemented as a view of their underlying collection so, if that collection is structurally changed, the iterator may well not be able to continue operating correctly when it reaches the changed part of the collection. \n* Instead of allowing the manifestation of failure to be delayed, making diagnosis difficult, the general-purpose Collections Framework iterators are fail-fast. The methods of a fail-fast iterator check that the underlying collection has not been structurally changed (by another iterator, or by the methods of the collection itself) since the last iterator method call. If they detect a change, they throw `ConcurrentModificationException`. \n\n  * #### Fail-safe iterators\n* **Snapshot iterators**\n  * Copy-on-write collections have snapshot iterators. These collections are backed by arrays which, once created, are never changed; if a value in the collection needs to be changed, a new array is created. So an iterator can read the values in one of these arrays (but never modify them) without danger of them being changed by another thread. Snapshot iterators do not throw `ConcurrentModificationException`.\n* **Weakly consistent iterators**\n  * Collections which rely on CAS have weakly consistent iterators, which reflect some but not necessarily all of the changes that have been made to their backing collection since they were created. For example, if elements in the collection have been modified or removed before the iterator reaches them, it definitely will reflect these changes, but no such guarantee is made for insertions. Weakly consistent iterators also do not throw `ConcurrentModificationException`. \n  * can tolerate concurrent modiﬁcation, traverses elements as they existed when the iterator was constructed, and may (but is not guaranteed to) reﬂect modiﬁcations to the collection after the construction of the iterator. `ConcurrentHashMap` and other concurrent collections create such iterators. \n  * The third group described above also have weakly consistent iterators. In Java 6 this includes `DelayQueue` and `PriorityBlockingQueue`, which in Java 5 had fail-fast iterators. This means that you cannot iterate over the Java 5 version of these queues unless they are quiescent, at a time when no elements are being added or inserted; at other times you have to copy their elements into an array using toArray and iterate over that instead.\n\n#### ListIterator \n`ListIterator` offers the following benefits over a regular Iterator. Since Set does not have the concept of a 'given point', there is no SetIterator.\n* iterate backwards\n* modify the list safely while iterating\n\n## Lists\n\n> [Class Diagram](http://static.karambelkar.info/static/java_collections/Java-Collections_API-List-ImageMap.html)\n\n{% img /technology/list-types.png %}\n\n### ArrayList\n\n* Backed up array and an integer pointing to the next empty slot\n* By default, an arraylist is created with initial capacity as 10. The capacity grows as and when needed (as per Sun's implementation it grows by the order of `int newCapacity = (oldCapacity * 3)/2 + 1;` . \n* An application can call `ArrayList.trimToSize()` method to trim the capacity of the ArrayList instance to be the list's current size to minimize the storage of an ArrayList instance.\n* BigO cost\n  * Access elements has constant time\n  * Insert/update/delete at the tail is cheap - constant complexity\n  * Insert/update/delete  at the head is expensive - linear complexity (everything to the right from the update position must be moved to the right for insertions and to the left for removals)\n  * cost of array size doubling???\n* CPU-cache friendly collection due to being backed by an array (unfortunately, not too friendly, because contains Objects, which are just pointers to the actual objects).\n\n### LinkedList\n\n* Deque implementation – doubly-linked list. \n* BigO cost\n  * Accessing elements has linear complexity \n  * Updating an element has linear complexity (due to an optimization, these methods do not traverse more than a half of the list, so the most expensive elements are located in the middle of the list).\n  * Insert/Delete elements - at head/tail - constant time\n* You need to use ListIterators if you want to try to write fast LinkedList code. If you want a Queue/Deque implementation (you need to access only first and last elements) – consider using ArrayDeque instead.\n* Why is ListIterator faster???\n* when to prefer linkedlist over ArrayList???\n\n\n### CopyOnWriteArrayList\n\n* List implementation -  A thread-safe variant of ArrayList in which all mutative operations (add, set, and so on) are implemented by making a fresh copy of the underlying array. \n* Copying is an expensive operation, so this class should be used only when traversals seriously outnumber updates. The usual use case for this collection is listeners/observers collection.\n* Element-changing operations on iterators themselves (remove, set, and add) are not supported. These methods throw UnsupportedOperationException.\n* Iterator is fail-safe and doesn't throw ConcurrentModificationException.\n* BigO cost\n  * Accessing elements - how fast???\n  * Updating elements - how slow???\n\n## Queues and Deques\n\n> [Class Diagram](http://static.karambelkar.info/static/java_collections/Java-Collections_API-Queue-ImageMap.html)\n\n{% img /technology/queue-types.png %}\n\n### ArrayDeque\n\n* Backed Data Structure: Deque implementation based on the array (circular buffer) with head/tail pointers. Unlike LinkedList, this class does not implement List interface, which means that you can not access anything except the first and the last elements. \n* BigO cost:\n  * Most operations run in amortized constant time (except remove(), contains(), removeFirstOccurrence(), removeLastOccurrence())\n  * Bulk operations run in linear time\n* Use case: This class is generally preferable to LinkedList for queues/deques due to a limited amount of garbage it generates (old array will be discarded on the extensions).\n\n### Stack\n\na LIFO queue. DO NOT use it in the production code. Use any Deque implementation instead (ArrayDeque is preferable).\n\n### PriorityQueue\n\n* Backed Data Structure: a queue based on the priority heap. \n* Uses either natural ordering or a provided Comparator. Its main property – poll/peek/remove/element methods always return the smallest remaining element in the queue. Despite that, this queue implements Iterable which does not iterate this queue in a sorted order (or any other particular order). \n* BigO cost\n  * Enque and Dequeing method run in logarthmic time\n  * remove(e) and contains(e) run in linear time\n  * retrieval methods (peek, element, size) run in constant time.\n* Use Case: This queue is generally preferable to other sorted collections, like TreeSet if all you need is a smallest element in the queue.\n\n### ArrayBlockingQueue\n\na bounded blocking queue backed by an array. Can not be resized, so when you will try to add an element to a full queue, a method call will block until another thread will extract an element from the queue. \n\nThis class supports an optional fairness policy for ordering waiting producer and consumer threads. By default, this ordering is not guaranteed. However, a queue constructed with fairness set to true grants threads access in FIFO order. Fairness generally decreases throughput but reduces variability and avoids starvation.\n\n### ConcurrentLinkedQueue / ConcurrentLinkedDeque\n\n* an unbounded deque/queue based on the linked list. \n* Adding elements to this queue does not block, but this has an unfortunate requirement that a consumer for this collection must work at least as fast as a producer, otherwise you will run out of memory. Heavily relies on CAS (compare-and-set) operations.\n* This implementation employs an efficient \"wait-free\" algorithm based on one described in [Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms by Maged M. Michael and Michael L. Scott](http://www.cs.rochester.edu/~scott/papers/1996_PODC_queues.pdf).\n* Iterators are weakly-consistent.\n* BigO cost\n  * size() is NOT a constant-time operation. Because of the asynchronous nature of these queues, determining the current number of elements requires a traversal of the elements, and so may report inaccurate results if this collection is modified during traversal.\n  * Bulk operations addAll, removeAll, retainAll, containsAll, equals, and toArray are not guaranteed to be performed atomically. \n\n### DelayDeque\n\n* an unbounded blocking queue of Delayed elements. An element could be taken from a queue only after its delay has expired. The head of the queue is the element with the smallest remaining delay (including negative values – delay has already expired). \n* Use case: This queue could be useful, for example, when you want to implement a queue of delayed tasks (do not implement such queue manually – use ScheduledThreadPoolExecutor instead).\n* size() returns the count of both expired and unexpired elements\n\n### LinkedBlockingQueue / LinkedBlockingDeque\n\n* optionally bounded (could be created with specified maximal capacity or without it) queue/deque based on the linked list. \n* It uses ReentrantLocks for empty/full conditions.\n* BigO cost - Linked queues typically have higher throughput than array-based queues but less predictable performance in most concurrent applications. ????\n\n### LinkedTransferQueue\n\n* an unbounded queue based on the linked list. Besides ordinary queue operations, it has a group of transfer methods, which allow a producer to send a message straight to the waiting consumer, thus removing the need to store an element into a queue. This is a lock-free collection based on CAS operations ???.\n* BigO cost\n  * size is NOT a constant time operation\n  * bulk operations are not atomic\n\n### PriorityBlockingQueue\n\nan unbounded blocking queue version of PriorityQueue.\n\n### SynchronousQueue\n\n* A blocking queue in which each insert operation must wait for a corresponding remove operation by another thread, and vice versa. A synchronous queue does not have any internal capacity, not even a capacity of one.\n* You cannot peek at a synchronous queue because an element is only present when you try to remove it; you cannot insert an element (using any method) unless another thread is trying to remove it; you cannot iterate as there is nothing to iterate. \n* If you don’t need a Queue interface, then the same functionality could be achieved via Exchanger class.\n* Use case:\n  * They are well suited for handoff designs, in which an object running in one thread must sync up with an object running in another thread in order to hand it some information, event, or task.\n\n### Queues Summary\n\n* Queue - Class Diagram\n  * Methods react in 2 ways in case of a failure\n  * Throws exception - add, remove, element\n  * Special value - offer, poll, peek\n  * JavaDoc \"Queue implementations generally do not define element-based versions of methods equals and hashCode but instead inherit the identity based versions from class Object, because element-based equality is not always well-defined for queues with the same elements but different ordering properties.\" - it means that queues do not really care about what is inside them.\n* BlockingQueue \n  * useful for producer-consumer problems\n  * Blocking methods - put(e), take()\n  * Time methods - offer(e, time, unit), poll(time, unit)\n  * All queuing methods achieve their effects atomically using internal locks or other forms of concurrency control. However, the bulk Collection operations addAll, containsAll, retainAll and removeAll are not necessarily performed atomically unless specified otherwise in an implementation. So it is possible, for example, for addAll(c) to fail (throwing an exception) after adding only some of the elements in c.\n  * Memory consistency effects: As with other concurrent collections, actions in a thread prior to placing an object into a BlockingQueue [happen-before](http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/package-summary.html#MemoryVisibility) actions subsequent to the access or removal of that element from the BlockingQueue in another thread. happen-before??? \n* TransferQueue\n  * A BlockingQueue in which producers may wait for consumers to receive elements. A TransferQueue may be useful for example in message passing applications in which producers sometimes (using method transfer(E)) await receipt of elements by consumers invoking take or poll, while at other times enqueue elements (via method put) without waiting for receipt. Non-blocking and time-out versions of tryTransfer are also available. A TransferQueue may also be queried, via hasWaitingConsumer(), whether there are any threads waiting for items, which is a converse analogy to a peek operation.\n\n## Sets\n\n> [Class Diagram](http://static.karambelkar.info/static/java_collections/Java-Collections_API-Set-ImageMap.html)\n\n{% img /technology/set-types.png %}\n\n### HashSet\n\n* a set implementation based on a HashMap with dummy values (same Object is used for every value). Has the same properties as a HashMap. Due to such implementation, consumes more memory than actually required for this data structure.\n* BigO cost\n  * constant time for add, remove, contains and size operations\n  * For better iteration performance, never set initial capacity too high and load factor too low ???\n\n### BitSet\n\n* This class implements a vector of bits that grows as needed. Each component of the bit set has a boolean value. The bits of a BitSet are indexed by nonnegative integers. Individual indexed bits can be examined, set, or cleared. One BitSet may be used to modify the contents of another BitSet through logical AND, logical inclusive OR, and logical exclusive OR operations.\n* By default, all bits in the set initially have the value false.\n* same as using `& | ^` etc. with a primitive numeric type.\n\n### EnumSet\n\n* Enum sets are represented internally as bit vectors. This representation is extremely compact and efficient. The space and time performance of this class should be good enough to allow its use as a high-quality, typesafe alternative to traditional int-based \"bit flags\"\n* There are 2 private implementations – \n  * `RegularEnumSet` backed up by a single long for enum types with 64 or fewer enum constants (which covers 99.9% use cases)\n  * `JumboEnumSet` backed by a long[] for enum types with more than 64 enum constants.\n* Iterator is weakly-consistent; will never throw `ConcurrentModificationException`\n* BigO cost\n  * All basic operations operate in constant time\n  * Likely (not guaranteed) to be faster than HashMap\n  * Bulk operations are constant time if input is also EnumSet\n\n### LinkedHashSet\n\n* backed by LinkedHashMap. \n* This is the only set which keeps its elements in the insertion order.\n* BigO cost\n  * O(1) - add, remove, contains\n  * Generally slower than HashSet exception the iteration\n\n### TreeSet\n\n* backed up a TreeMap instance. \n* Only non-thread-safe sorted set using their natural ordering or by a `Comparator` provided\n* Typically Set interface is defined in terms of the equals operation, but a TreeSet instance performs all element comparisons using its `compareTo` (or `compare`) method, so two elements that are deemed equal by this method are, from the standpoint of the set, equal.\n* BigO cost\n  * O(1) - add, remove, contains\n\n### ConcurrentSkipListSet\n\n* backed by ConcurrentSkipListMap for storage. \n* Only thread-safe sorted set using their natural ordering or by a Comparator provided\n* iterators are weakly-consistent; never throws ConcurrentModificationException\n* Use case: when you need an thread-safe order set \n* BigO cost\n  * O(log n) - add, remove, contains\n  * Ascending ordered views and their iterators are faster than descending ones.\n  * size() is not a constant time operation\n  * bulk operations aren't atomic\n* Both the concurrent sets are based on [High Performance Dynamic Lock-Free Hash Tables and List-Based Sets by Maged Michael](http://www.research.ibm.com/people/m/michael/spaa-2002.pdf) from IBM\n* There's currently no [Red-Black tree](http://en.wikipedia.org/wiki/Red%E2%80%93black_tree) based concurrent Map/Set implementation in Java. I looked through the literature a bit and found a couple papers that showed concurrent RB trees outperforming skip lists, but a lot of these tests were done with [transactional memory](http://en.wikipedia.org/wiki/Transactional_memory), which isn't supported in hardware on any major architectures at the moment.\n\n### CopyOnWriteArraySet\n\nbacked up a `CopyOnWriteArrayList` and shares its properties\n\n### Sets Summary\n\n* Uses equals() method to check for duplication\n* Great care must be exercised if mutable objects are used as set elements. The behavior of a set is not specified if the value of an object is changed in a manner that affects equals comparisons while the object is an element in the set. A special case of this prohibition is that it is not permissible for a set to contain itself as an element.\n* SortedSet - TreeSet, ConcurrentSkipListSet\n* NavigableSet - TreeSet, ConcurrentSkipListSet\n* Creating a ConcurrentHashSet - `Collections.newSetFromMap(new ConcurrentHashMap<String, Boolean>);`\n\n## Maps\n\n> [Class Diagram](http://static.karambelkar.info/static/java_collections/Java-Collections_Map-API-ImageMap.html)\n\n{% img /technology/map-types.png %}\n\n### HashMap\n\n* backed up chaining Hash table; \n* Collection view methods (keySet and values) retun fail-fast iterators\n* BigO Cost\n  * O(1) - get and put; assuming the hash function disperses the elements properly among the buckets\n  * Iteration: Iteration over collection views requires time proportional to the \"capacity\" of the HashMap instance (the number of buckets) plus its size (the number of key-value mappings). Thus, it's very important not to set the initial capacity too high (or the load factor too low) if iteration performance is important.\n  * Iteration using entrySet is better in performance\n  * Significance of 'initial capacity' and 'load factor' in performance ??? \n  * The capacity is the number of buckets in the hash table, and the initial capacity is simply the capacity at the time the hash table is created. \n  * The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased. When the number of entries in the hash table exceeds the product of the load factor and the current capacity, the hash table is rehashed (that is, internal data structures are rebuilt) so that the hash table has approximately twice the number of buckets.\n\n### EnumMap\n\n* Enum maps are maintained in the natural order of their keys (the order in which the enum constants are declared). This is reflected in the iterators returned by the collections views (keySet(), entrySet(), and values()).\n* weakly-consistent iterators\n* BigO Cost\n  * O(1) - all basic operations\n  * Generally works faster than a HashMap due to a known maximal number of keys and built-in enum to int mapping (it is a fixed size array of values).\n\n### IdentityHashMap\n\n* backed up simple linear-probe hash table; \n* a very special version of a Map, violating the Map general contract: it compares references using reference-equality (==) instead of object-equality (Object.equals). In other words, in an IdentityHashMap, two keys k1 and k2 are considered equal if and only if (k1==k2). (In normal Map implementations (like HashMap) two keys k1 and k2 are considered equal if and only if (k1==null ? k2==null : k1.equals(k2)\n* Iterators are fail-fast\n* Use case: useful for various graph traversal algorithms – you may easily store already processed nodes in the IdentityHashMap along with some node-related data.\n* BigO Cost\n  * O(1) - get and put; assuming the system identity hash function (System.identityHashCode(Object)) disperses elements properly among the buckets\n  * iteration over collection views requires time proportional to the number of buckets in the hash table\n  * one tuning parameter (which affects performance but not semantics): expected maximum size. This parameter is the maximum number of key-value mappings that the map is expected to hold. Internally, this parameter is used to determine the number of buckets initially comprising the hash table. The precise relationship between the expected maximum size and the number of buckets is unspecified.\n  * this class will yield better performance than HashMap (which uses [chaining hash table](http://www.cs.rmit.edu.au/online/blackboard/chapter/05/documents/contribute/chapter/05/chaining.html) rather than [linear-probing](https://www.cs.auckland.ac.nz/software/AlgAnim/hash_tables.html))\n    * **Linear-probing**: A simple re-hashing scheme in which the next slot in the table is checked on a collision.\n    * chaining: uses a linked list to store the values. all the collision and retrieval functions are handled on the list.\n\n### LinkedHashMap\n\n* backed by a combination of a HashMap and a LinkedList\n* insertion order of all elements is stored inside a LinkedList. That’s why LinkedHashMap entries, keys and values are always iterated in the insertion order. \n* Use case: well-suited for LRU/FIFO caches by overriding removeEldestEntry; a simple FIFO cache. \n  * `return size() > maximumCapacity) or LRU cache (return size() > maximumCapacity;` \n* fail-fast iterators\n* A structural modification is any operation that adds or deletes one or more mappings or, in the case of access-ordered linked hash maps, affects iteration order. In insertion-ordered linked hash maps, merely changing the value associated with a key that is already contained in the map is not a structural modification. In access-ordered linked hash maps, merely querying the map with get is a structural modification.\n* BigO Cost\n  * O(1) - add, contains, remove\n  * This is the most expensive JDK collection in terms of memory consumption per element.\n  * Performance is likely to be just slightly below that of HashMap, due to the added expense of maintaining the linked list, with one exception: Iteration over the collection-views of a LinkedHashMap requires time proportional to the size of the map, regardless of its capacity\n\n### TreeMap\n\n* a red-black tree based sorted navigable Map. \n* It sorts all entries based on the natural order or a given Comparator of keys. \n* This map requires that implementation of equals and Comparable/Comparator.compareTo to be consistent. \n* implements a NavigableMap interface: it allows getting a map of all entries less than/more than given key; getting a prev/next entry (based on the key ordering); getting a map with a given range of keys (which roughly corresponds to SQL BETWEEN operator) and many variations of these methods.\n* Map interface is defined in terms of the equals operation, but a sorted map performs all key comparisons using its compareTo (or compare) method, so two keys that are deemed equal by this method are, from the standpoint of the sorted map, equal. The behavior of a sorted map is well-defined even if its ordering is inconsistent with equals; it just fails to obey the general contract of the Map interface.\n* fail-fast iterators\n* BigO Cost\n  * O(log n) - guaranteed for containsKey, get, put and remove operations. (Algorithms are adaptations of those in Cormen, Leiserson, and Rivest's Introduction to Algorithms.)\n\n### WeakHashMap\n\n* hash table based implementation with weak keys.\n* Use case: generally used in data cache implementations. \n* It keeps all its keys with WeakReference, which means that these keys may be garbage collected if there are no strong references to the key objects. Values, on the other hand, are stored using strong references. Because of this, you should either ensure that there are no references from values to keys, or keep values inside weak references too: `m.put(key, new WeakReference(value))`.\n* fail-fast iterator\n* BigO Cost: same as HashMap\n  * For the visual representation: How to write a simple yet “bullet-proof” object cache using WeakHashMap\n\n### ConcurrentHashMap\n\n* a hash table with full concurrency for get operations and configurable level of concurrency for put operations. This level is adjusted via concurrencyLevel constructor parameter (default 16), which defines a number of partitions inside this map. Only an updated partition is locked during put operation. \n* Remember that this map is not a thread-safe replacement for HashMap algorithms – any compound actions like “get-then-put” sequences of method calls on this map (or any other concurrent collection) should be externally synchronized.\n* Retrieval operations (like get) do not block; \n* iterators are fail-safe; but designed to be used only by one thread at a time.\n* The one feature offered by the synchronizedMap implementations but not by ConcurrentHashMap is the ability to lock the map for exclusive access. With Hashtable and synchronizedMap, acquiring the Map lock prevents any other thread from accessing it. This might be necessary in unusual cases such as adding several mappings atomically, or iterating the Map several times and needing to see the same elements in the same order.\n\n### ConcurrentSkipListMap \n\n* based on skip lists; this could serve as a thread-safe replacement for TreeMap.\n* Only thread-safe sorted Map using their natural ordering or by a Comparator provided\n* Insertion, removal, update, and access operations safely execute concurrently by multiple threads.\n* iterators are weakly-consistent; never throws ConcurrentModificationException\n* Use case: when you need an thread-safe ordered map\n* BigO cost\n  * expected average log(n) time cost for the containsKey, get, put and remove operations and their variants. \n  * size() is not a constant time operation\n  * bulk operations aren't atomic\n\n{% img /technology/lock-contention.png %}\n\n### Maps Summary\n\n* `System.identityHashCode(Object);`\n* SortedMap - TreeMap, ConcurrentSkipListMap\n* NavigableMap (extends SortedMap) - allows range searches\n* Great care must be exercised if mutable objects are used as map keys. The behavior of a map is not specified if the value of an object is changed in a manner that affects equals comparisons while the object is a key in the map. A special case of this prohibition is that it is not permissible for a map to contain itself as a key. While it is permissible for a map to contain itself as a value, extreme caution is advised: the equals and hashCode methods are no longer well defined on such a map.\n* Many methods in Collections Framework interfaces are defined in terms of the equals method. For example, the specification for the containsKey(Object key) method says: \"returns true if and only if this map contains a mapping for a key k such that (key==null ? k==null : key.equals(k)).\" This specification should not be construed to imply that invoking Map.containsKey with a non-null argument key will cause key.equals(k) to be invoked for any key k. Implementations are free to implement optimizations whereby the equals invocation is avoided, for example, by first comparing the hash codes of the two keys. (The Object.hashCode() specification guarantees that two objects with unequal hash codes cannot be equal.) More generally, implementations of the various Collections Framework interfaces are free to take advantage of the specified behavior of underlying Object methods wherever the implementor deems it appropriate.\n* [Unique hashCodes is not enough to avoid collisions](http://vanillajava.blogspot.com/2013/10/unique-hashcodes-is-not-enough-to-avoid.html)\n* **Best way to iterate a Map** - 2 ways of iterating a Map via the entry set or the key set. In terms of performance, it seems to me that the approach of iterating over the entry set should be much faster. The iteration is O(n). However, if the HashMap is well balanced, then we should get O(1) performance on the lookup call to get(), thus the complexity of the two approaches is the same. There might be a small difference, but they both should scale linearly. This is not true with other types of maps, such as the TreeMap. The lookup complexity is O(log n), thus the complexity of the second loop would be O(n x log n).\n* SortedMap\n  * All keys inserted into a sorted map must implement the Comparable interface (or be accepted by the specified comparator). Furthermore, all such keys must be mutually comparable: k1.compareTo(k2) (or comparator.compare(k1, k2)) must not throw a ClassCastException for any keys k1 and k2 in the sorted map. Attempts to violate this restriction will cause the offending method or constructor invocation to throw a ClassCastException.\n  * Note that the ordering maintained by a sorted map (whether or not an explicit comparator is provided) must be consistent with equals if the sorted map is to correctly implement the Map interface. (See the Comparable interface or Comparator interface for a precise definition of consistent with equals.) This is so because the Map interface is defined in terms of the equals operation, but a sorted map performs all key comparisons using its compareTo (or compare) method, so two keys that are deemed equal by this method are, from the standpoint of the sorted map, equal. The behavior of a tree map is well-defined even if its ordering is inconsistent with equals; it just fails to obey the general contract of the Map interface.\n\n## Arrays & Collections\n\n### Arrays\n\n```java resulting list is modifiable, but not resizable\nList<X> list = Arrays.asList(new X[desiredSize]); \n```\n\n### Collections\n\n* Collections.sort() - what if the object is not Comparable???\n* Collections.rotate() and Arrays.rotate() ???\n* To create read-only collections? - Collections.unmodifiableCollection() or unmodifiableList(), unmodifiableSet(), etc.\n\n## Comparable & Comparator\n\n| # | Comparable interface| Comparator interface | \n| - | -------------------- | -------------------- | \n| 1 | Used when the objects need to be compared in their natural order. | Used when the objects need to be compared in custom user-defined order (other than the natural order).| \n| 2 | You do not create a separate class just to implement the Comparable interface.| You create a separate class just to implement the Comparator interface.| \n| 3 | For a given class type, you have only that class (and that class alone) implementing the Comparable interface.| You can have many separate (i.e., independent) classes implementing the Comparator interface, with each class defining different ways to compare objects.| \n| 4 | The method in the Comparable interface is declared as `int compareTo(ClassType type);`| The method in the Comparator interface is declared as `int compare(ClassType type1, ClassType type2);`| \n\n# Bibliography \n* Oracle Certified Professional, Java SE 7 Programmer\n* Java Generics and Collection\n"
  },
  {
    "id": 15,
    "title": "Java Concurrency",
    "url": "/technology/java-concurrency.html",
    "content": "[TOC]\n\n\nMemory Consistency - http://docs.oracle.com/javase/tutorial/essential/concurrency/memconsist.html \nMemory consistent properties - happens-before? Read more on Java Language Specification book \n\n# Basics Concepts\n\n* Thread\n  * Each thread has its own stack and local variable.\n  * Threads share the memory address space of the owning process; due to this, all threads have access to the same variables and allocate objects from same heap.\n* Definitions\n   * Parallel processing - refers to two or more threads running simultaneously, on different cores (processors), in the same computer. It is essentially a hardware term.\n  * Concurrent processing - refers to two or more threads running asynchronously, on one or more cores, usually in the same computer. It is essentially a software term.\n  * Distributed processing - refers to two or more processes running asynchronously on one or more JVMs or boxes.\n\n\n## Threading Models\n\n### Pre-emptive multi-threading \n\n* OS determines when a context switch should occur\n* System may make context switch at an inappropriate time\n* This model is widely used nowadays\n \n### Co-operative multi-threading\n\n* The threads themselves determine relinquish control once they are at a stopping point.\n* Can create problems if a thread is waiting for a resource to become available.\n\n## Thread Types\n\n### Green thread\n\n* Green threads emulate multithreaded environments without relying on any native OS capabilities. They run code in user space that manages and schedules threads;\n* Scheduled by JVM rather underlying OS\n* Sun wrote green threads to enable Java to work in environments that do not have native thread support.\n* Uses cooperative multitasking - dangerous\n\n### Native thread\n\n* Uses underlying OS native threads\n* Can be scheduled across cores in multi-core or multiprocessor systems\n* Performs better than green threads even in single-core\n\n## Atomicity\n\nCompound Action Anti-Patterns\n### Check-then-act\n\n```java\nif(foo==null) //Another thread could set foo to non-null. \n    foo = new Foo();\n```\n\n**Solution**: synchronize or use concurrent methods like `ConcurrentHashMap.putIfAbsent()`\n\n### Read-modify-write\n\n```java\n++numRequests; //non-atomic compound action\n```\n\n**Solution**: synchronize or use atomic objects `AtomicInteger.getAndSet()`\n\n## Visibility\n\nChanges made by one thread may not be visible to other threads since the data could be residing in local working memory of a thread instead of main memory. In order to make it visible, **Memory Barrier** is needed. \"Memory Barrier\" means copying data from local working memory to main memory.\n\nA change made by one thread is guaranteed to be visible to another thread only if the writing thread crosses the memory barrier and then the reading thread crosses the memory barrier. **synchronized** and **volatile** keywords force that the changes are globally visible on a timely basis; these help cross the memory barrier.\n\n{% img right /technology/memory-barrier.jpg %}\n\n## Synchronization\n\nSynchronization allows you to control program flow and access to shared data for concurrently executing threads.\n\nThe four synchronization models are mutex locks, read/write locks, condition variables, and semaphores.\n\n\n### (1) Mutex locks \n\n* allow only one thread at a time to execute a specific section of code, or to access specific data.\n* Each Java class and object has their own mutex locks. Each thread has it's own separate call stack.\n\n### (2) Read/write locks \n\n* permit concurrent reads and exclusive writes to a protected shared resource. To modify a resource, a thread must first acquire the exclusive write lock. An exclusive write lock is not permitted until all read locks have been released.\n\ne.g., Java ReadWriteLock\n\n### (3) Condition variables \n\n* block threads until a particular condition is true.\n\n### (4) Counting semaphores \n\n* typically coordinate access to resources. The count is the limit on how many threads can have access to a semaphore. When the count is reached, the semaphore blocks.\n\n# Locks\n\n## Intrinsic Lock (synchronized keyword)\n\n### What should be used as a monitor?\n\n* The field being protected. e.g., \n```java\nprivate final Map map = ...;\nsynchronized(map){...}\n```\n* an explicit private lock  e.g., \n```java\nprivate final Object lock = new Object();\nsynchronized(lock){...}\n```\n* `this` object \n```java\nsynchronized(this){...} //uses current object's lock\n```\n* Class-level lock \n```java\nsynchronized(Foo.class){...} \n```\n\n### What SHOULD NOT be used as a monitor?\n* DO NOT synchronize on objects that can be re-used. Examples below: (For more information: [Securecoding.cert.org - Do not synchronize on objects that may be reused)](https://www.securecoding.cert.org/confluence/display/java/LCK01-J.+Do+not+synchronize+on+objects+that+may+be+reused)\n```java\nprivate final Boolean lock = Boolean.FALSE; //UNSAFE if some other thread uses the same reused object from heap it could lead to unexpected overhead and deadlock\nprivate final Integer lock = 10; //UNSAFE if autoboxed primitive value is shared from heap\nprivate final Integer lock = new Integer(10); //SAFE. explicitly constructed Integer object has a unique reference and its own intrinsic lock is distinct not only from other Integer objects, but also from boxed integers that have the same value.\nprivate final String lock = \"LOCK\"; //UNSAFE if some other thread uses the same reused object from heap.\nprivate final String lock = new String(\"LOCK\").intern(); //UNSAFE interned strings act like a global variable in a JVM.\nprivate final Object lock = new Object(); //SAFE.\n```\n* DO NOT synchronize on Lock objects.\n```java\nprivate final Lock lock = new ReEntrantLock();\nsynchronized(lock){...}\n```\n\n### Limitations \n* Single monitor per object\n* Not possible to interrupt thread waiting for lock\n* Not possible to time-out when waiting for a lock\n* Acquiring multiple locks is complex.\n\n## Extrinsic Lock\n\n### Lock Interface\n\n* implementations provide more extensive locking operations than can be obtained using synchronized methods and statements.\n* Commonly, a lock provides exclusive access to a shared resource: only one thread at a time can acquire the lock and all access to the shared resource requires that the lock be acquired first. However, some locks may allow concurrent access to a shared resource, such as the read lock of a ReadWriteLock.\n* offers more flexible lock acquiring and releasing. For example, some algorithms for traversing concurrently accessed data structures require the use of \"hand-over-hand\" or \"chain locking\": you acquire the lock of node A, then node B, then release A and acquire C, then release B and acquire D and so on. Implementations of the Lock interface enable the use of such techniques by allowing a lock to be acquired and released in different scopes, and allowing multiple locks to be acquired and released in any order.\n* Lock implementations provide additional functionality over the use of synchronized methods and statements by providing a non-blocking attempt to acquire a lock (`tryLock()`), an attempt to acquire the lock that can be interrupted (`lockInterruptibly()`, and an attempt to acquire the lock that can timeout (`tryLock(long, TimeUnit)`).\n* Never use a Lock object as a monitor in a synchronized block\n* Common idiom to follow\n \n``` java\n    Lock l = ...;\n    l.lock();\n    try {\n       // access the resource protected by this lock\n    } finally {\n       l.unlock();\n    }\n```\n\n### Re-entrant locks/Recursive locking \n\nOnce a thread acquires the lock of an object, it can call other synchronized methods on that object without having to wait to acquire the lock again. Otherwise the method call would get into deadlock. \n\n### Condition\n\ninstead of spin wait(sleep until a flag is true) which is inefficient, use `Condition`. Even better is to use coordination classes like `CountDownLatch` or `CyclicBarrier` which is concise and better than `Condition`.\n\n# Sharing Objects\n\n* \"synchronized\" guarantess 2 things\n  * ensures **atomicity** or demarcates 'critical section'\n  * **memory visibility** - ensures other threads see the state change from a given thread\n\n```java\npublic class NoVisibility{\n   private static boolean ready;\n   private static int number;\n   \n   private static class ReaderThread extends Thread{\n      public void run(){\n         while(!ready) Thread.yield();\n         println(number);\n      }\n   }\n   \n   public static void main(){\n      new ReaderThread().start();\n      number = 42;\n      ready = true;\n   }\n}\n```  \n\n**Possible outcomes**\n* prints zero and exists\n* prints nothing and never ends\n\n**Reason**\n* changes made by main thread are not visitible to ReaderThread\n* Stale values are visible\n* changes made by main thread were visible to ReaderThread in a different order\n\n\n## Re-ordering\n\n* Processor: could rearrange the execution order of machine instructions.\n* Compiler: could optimize by rearranging the order of the statements.\n* Memory: could rearrange the order in which the writes are committed to the memory cells.\n* http://gee.cs.oswego.edu/dl/cpj/jmm.html\n* http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html\n\n> Note: Always run server apps with \"-server\" JVM setting to catch re-ordering related bugs in development stage instead of prod.\n\nNon-atomic 64-bit operations - JMM requires the read and write operations to be atomic, except 'long' and 'double' variables unless it is declared 'volatile'. JVM is permitted to treat 64-bit read/write as two separate 32-bit operations.\n\n\n## Volatile Variables\n\n{% img right /technology/memory-cache.png %}\n\nIn Java, volatile keyword does 3 things:\n\n* prevents re-ordering of statements by processor/compiler/memory\n* forces to read the values from memory instead of cache.\n* guarantees atomicity in 64-bit data type assignments. \n\n```java\nprivate long x;\nprivate double y;\npublic Foo(long longValue, double doubleValue){\n   this.x = longValue; //not atomic\n   this.y = doubleValue; //not atomic\n}\n```\n\nMore info: \n* [Volatile fields and memory barrier: A look inside](http://www.codeproject.com/Articles/31283/Volatile-fields-in-NET-A-look-inside)\n* [InfoQ: Memory Barriers and JVM Concurrency](http://www.infoq.com/articles/memory_barriers_jvm_concurrency)\n\n### Pros of volatile\n* weaker form of synchronization\n* notices JIT compiler and runtime that \"re-ordering\" SHOULD NOT happen.\n* It warns the compiler that the variable may change behind the back of a thread and that each access, read or write, to this variable should bypass cache and go all the way to the memory.\n* don't rely too much on volatile for visibility\n* when to use volatiles??????\n\n### Limitations of volatile\n* Synchronization guarantees both atomicity and visibility \n* Volatile guarantees only visibility\n* Making all variables volatile will result in poor performance since every access to cross the memory barrier\n* volatile arrays? is this safe? \n`private volatile int[] vals;`\n\n# Publishing and Escaping\n\n* **Publishing** - making an object available to code outside of current scope. 2 ways of publishing - returning objects and passing it as parameter to another method.\n* **Escaping** - An object published when it should not have been. e.g., partially constructed (Object reference visible to another thread does not necessarily mean that the state of the object is visible.)\n\n## Things to avoid\n\n* **Do not publish state** via 'public static' fields. Solution: Use encapsulation\n* **Do not allow internal mutable state to escape** \n  * (a) e.g., `public String[] foo();` <--- Caller can modify the array. Solution: Use defensive copy.\n  * (b) e.g., `public void foo(Set<Car> car){}` <--- calling a method passing the reference. 'foo' can potentially modify 'Car' object. Solution: Use defensive copy.\n  * (c) sub-classes can violate by overriding methods. Solution: Use final methods.\n* **Do not allow 'this' reference to escape via inner classes** (Try examples??????) Solution: Use factory methods\n```java\npublic class EventListener2 {\n  public EventListener2(EventSource eventSource) {\n\n    eventSource.registerListener(\n      new EventListener() { //indirectly this non-static anonymous class publishes a reference to an instance of parent EventListener2\n        public void onEvent(Event e) { \n          eventReceived(e);\n        }\n      });\n  }\n\n  public void eventReceived(Event e) {\n  }\n}\n```\n* **Don't start threads from within constructors** - A special case of the problem above is starting a thread from within a constructor, because often when an object owns a thread, either that thread is an inner class or we pass the this reference to its constructor (or the class itself extends the Thread class). If an object is going to own a thread, it is best if the object provides a start() method, just like Thread does, and starts the thread from the start() method instead of from the constructor. While this does expose some implementation details (such as the possible existence of an owned thread) of the class via the interface, which is often not desirable, in this case the risks of starting the thread from the constructor outweigh the benefit of implementation hiding.\n```java\npublic class EventListener2 {\n  public EventListener2(EventSource eventSource) {\n\n        new Thread(){\n            @Override\n            public void run() {\n                ... // 'this' escapes here\n            }\n        }.start();\n  }\n\n  public void eventReceived(Event e) {\n  }\n}\n```\n\n## Thread Confinement\n\nDo not share anything outside of the scope or at least outside of the thread.\n\n(1) Adhoc - manually ensuring the object does not escape to more than a thread.\n(2) Stack confinement - make it a local variable.\n(3) ThreadLocal confinement - ensures each thread has its own copy of the object. \n\n## Data Sharing Options\n\n1. DO NOT share anything out of current scope\n2. DO NOT share anything out of current thread\n3. Share only immutable data\n4. Share mutable data - make vars volatile (thread safety not guaranteed)\n5. Share mutable data - make vars atomic\n6. Share mutable data - protect data using lock (intrinsic-lock synchronized or extrinsic-lock)\n\n## Immutability\n\nImmutable objects \n- are inherently thread-safe since the state cannot be changed.\n- Initialization Safety - JMM guarantees that immutables are published safely - meaning when the reference to an immutable is published, it is guaranteed that - the object is fully constructed\nImmutables offer additional performance advantage such as reduced need for locking or defensive copies.\n \nAn object is immutable if\n\n1. its state cannot be modified after construction\n2. all its fields are final (not necessarily)\n3. it is properly constructed ('this' does not escape during its construction)\n \n## Safe Publication\n\nTo publish an object safely, both the reference to the object and the state of the object must be visible to the other thread at the same time.\n\nA properly constructed object can be safely published by:\n\n1. Initializing an object reference from static initializer (executed by JVM at class initialization)\n2. storing the reference in a 'volatile' field or 'AtomicReference'\n3. storing the reference in a 'final' field of a properly constructed object\n4. storing the reference in a field guarded by a lock\n\n# Concurrency Problems\n\n## 1) Race condition\n\n{% img right /technology/deadlock.png %}\n\n* If 2 threads compete to use the same resource of data, we have a race condition\n* A race condition doesn't just happen when 2 threads modify data. It can happen even when one is changing data while the other is trying to read it.\n* Race conditions can render a program's behavior unpredictable, produce incorrect execution, and yield incorrect results.\n\nHazards of Liveness - deadlocks, livelocks, starvation and missed signals\n\n## 2) Deadlock\n\n\n### Type 1: Lock-Ordering Deadlock\n\n\n* Thread 1 holds lock A and waits for lock B. Thread 2 holds lock B and waits for lock A. (e.g., Dining philosopher's problem) This is a cyclic locking dependency, otherwise called 'deadly embrace'.\n* DBs handle deadlock by victimizing one of the threads. JVMs don't have that feature.\n\n#### Dynamic lock-ordering deadlocks \n\nbelow code deadlocks if 2 threads pass in the same objects in different order\n\n```java\nvoid foo(Object A, Object B){ \n\tlock A, then B \n}\n```\nTo prevent this, use some kind of unique values like System.identityHashCode() to define the order of locking. If the objects being locked has unique, immutable and compareable-keys, then inducing locking order is even easier.\n\n```java \nObject tieBreaker = new Object();\n\nvoid foo(Object A, Object B){\n if (hashA < hashB){ lock A, then B} \n else if (hashA > hashB){ lock B, then A } \n else { lock tieBreaker, lock A, lock B} //during hash-collision, due tie-breaker locks\n}\n```\n\n#### Open Calls\n\nCalling an alien method with no locks held is known as 'open-calls'. Invoking alien method with locks held is asking for liveness trouble because the alient method might acquire other locks leading to lock-order deadlocks. Here is an innocent looking example: Thread 1 calls setLocation() locking Taxi and waiting for lock on Dispatcher. Thread 2 calls getStatus() locking dispatcher and waiting for lock on Taxi.\n```java\nclass Taxi{\n private Dispatcher dispatcher;\n public Taxi(Dispatcher dispatcher){this.dispatcher = dispatcher;}\n \n public synchronized void setLocation(){\n dispatcher.notify();\n }\n \n public synchronized Object getLocation(){\n ...\n }\n}\n \nclass Dispatcher{\n private Set<Taxi> taxis = new HashSet<>();\n \n public synchronized void getStatus(Taxi taxi){\n taxi.getLocation();\n }\n \n public synchronized void notify(){\n ...\n }\n}\n```\n\n### Type 2: Thread-starvation deadlocks\n\nTask that submits a task and waits for its result in a single-threaded executor\nBounded pools and inter-dependent tasks don't mix well.\n\n### How to avoid deadlocks?\n1. Avoid acquiring multiple locks\n2. If not, establish lock-ordering protocol\n3. Use open-calls while invoking alient methods\n4. Avoid mixing bounded pools and inter-dependent tasks\n5. Attempt timed-locks (lock-wait timeouts)\n\n## 3) Starvation\n\noccurs when a thread is perpetually denied access to a resource it needs to make progress; most commonly the CPU cycles. In Java it typically happens due to inappropriate use of thread priorities. \n\n## 4) Livelocks\n\nis a form of liveness failure in which a thread, while not blocked, still cannot make progress because it keeps retrying an operation that will always fail. It often occurs in transactional messaging applications, where the messaging infrastructure rolls back a transaction if a message cannot be processed successfully, and puts it back at the head of the queue. (This is often also called 'poison message' problem).\n\n## 5) Missed Signals\n\n???\n\n## 6) Fairness\n\n??? \n\n# Concurrency Limitations\n\nConcurrency/Parallelism does not necessarily make a program run faster; it may even make it slower. Here's why:\n\n* **Overhead** is work that a sequential program does not need to do. Creating, initializing, and destroying threads adds overhead, and may result in a slower program. Using thread pools may reduce the overhead somewhat.\n* **Non-parallelizable computation**:  Some things can only be done sequentially.\n  * **Amdahl's law** states that if 1/S of a computation is inherently sequential, then the computation can be speeded up by at most a factor of S. For example, if 1/5 of a computation must be done sequentially and 4/5 can be done in parallel, then (assuming unlimited parallelism with zero additional overhead) the 4/5 can be done \"instantaneously\", the 1/5 is not speeded up at all, and the program can execute 5 times faster.\n  * **Idle processors**: Unless all processors get exactly the same amount of work, some will be idle. Threads may need to wait for a lock, processes may need to wait for a message.\n* **Contention for resources**: Shared state requires synchronization, which is expensive.\n\n# Executors Framework\n\n* Executor framework provides a standard means of decoupling 'task submission' and 'task execution'\n* Independent Task  - task that doesn't depend on the state/result of other tasks\n* Only independent tasks should be submitted to executors/thread pool. Otherwise leads to starvation deadlock\n \n## Disadvantages of unbounded thread creation\n\n1. Overhead involved in thread creation and teardown\n2. Resource consumption - threads consume memory and adds pressure to GC\n3. Stability - there is a limit on how many threads could be created. Breaching that will crash the program.\n\n## Task Execution Policy\n\n* # of threads       -> single/multi-threaded\n* queue              -> bounded/unbounded queue\n* order of execution -> FIFO, LIFO, priority order\n \n## Task Types\n\n* `Runnable` & `Callable` - represent abstract computation tasks. Runnable neither returns results nor throws exception\n* `Future` - represents lifecycle of a task and provides methods to test whether the task completed/cancelled/result available.\n  * Future.get() call blocks until the result is available\n  * Instead of polling on Futures, use CompletionService\n* **Periodic tasks**\n  * `Timer` - supports only absolute timing\n    * If a recurring TimerTask is scheduled to run every 10 ms and another Timer-Task takes 40 ms to run, the recurring task either (depending on whether it was scheduled at fixed rate or fixed delay) gets called four times in rapid succession after the long-running task completes, or “misses” four invocations completely. Scheduled thread pools address this limitation by letting you provide multiple threads for executing deferred and periodic tasks.\n    * Timer thread doesn’t catch the exception, so an unchecked exception thrown from a TimerTask terminates the timer thread.\n* `ScheduledThreadPoolExecutor` - supports only relative timing. Always prefer this over Timer.\n\n## Class diagram\n\n{% img /technology/executor-class-diagram.png %}\n\n* `Executor` Interface \n  * has only one method - `execute(Runnable)`\n  * useful tool to solve producer-consumer type problems\n  * Executors decouple task execution & task submission\n* `ExecutorService` interface\n  * extends Executor interface\n  * provides additional methods to shutdown executor either forcefully/gracefully\n\n# Concurrent Data Structures\n\n## Blocking Data Structures\n\n* Blocking Queue - used in producer-consumer problems.\n  * Bounded Queue - blocks read when empty and blocks write when full\n  * Unbounded Queue - blocks read when empty and never full\n  * ArrayBlockingQueue - FIFO\n  * LinkedBlockingQueue - FIFO\n  * PriorityBlockingQueue - Priority-ordered\n* SynchronousQueue - No storage space (size=0). Producer blocks until consumer is available.\n* Semaphore - Explained below\n* Blocking Deque (double-ended queue)\n  * Deque & Blocking Deque are good for \"work stealing pattern\" which is better than producer-consumer pattern.\n\n# Synchronizers\n\nSynchronizer is any object that keeps the shared mutable data consistent. Don't need it if we can make immutable or unshared data.\n \n> Note: Blocking Queue is both collection and a synchronizer\n\n## 1) FutureTask\n* represents asynchronous tasks (implement Future) \n* acts like a latch. \n* Future.get()\n  * if complete, returns computation result\n  * if not, blocks until result is available or an exception is thrown\n\n## 2) Sempahore\n\n{% img right /technology/semaphore.png %}\n\n{% img right /technology/mutex.png %}\n\n* Counting semaphores control the number of activities that can access a certain resource or perform a given action at the same time.\n* semaphores manage a set of virtual permits\n* activities acquire permit and release them\n* if no permit available, acquire blocks\n* semaphore with 1 permit acts as a mutex\n* can be used to convert any collection into a 'blocking bounded collection'\n* semaphore does not associate permits with threads. So a permit acquired in one thread can be release from another thread.\n\n## 3) Latches\n\n{% img right /technology/latches.jpg %}\n\n* acts as a gate: \n* initially when the gate is closed, no threads can pass. \n* gate opens after the terminal state is reached and all threads pass. \n* once open the gate never closes\n* any thread is allowed to call countDown() as many times as they like. Coordinating thread which called await() is blocked until the count reaches zero.\n\n### Limitations\n* A latch cannot be reused after reaching the final count\n* number of participating threads should be specified at creation time and cannot be changed.\n* In the picture, Thread TA waits until all the 3 threads (1-3) complete.\n\n## 4) Barriers\n\n{% img right /technology/cyclicbarrier.jpg %}\n\n* `CyclicBarrier` lets a group of threads wait for each other to reach a common barrier point. \n* It also allows you to get the number of clients waiting at the barrier and the number required to trigger the barrier. Once triggered the barrier is reset and can be used again.\n* Unlike CountdownLatch, barrier can be reused by calling reset() (hence the name cyclic). \n* `CyclicBarrier` can be provided an optional Runnable to execute after reaching the barrier point.\n* Useful in loop/phased computations where a set of threads need to synchronize before starting the next iteration/phase.\n* `CyclicBarrier` - if a thread has a problem (timeout, interrupted...), all the others that have reached await() get an exception. The CyclicBarrier uses an all-or-none breakage model for failed synchronization attempts: If a thread leaves a barrier point prematurely because of interruption, failure, or timeout, all other threads waiting at that barrier point will also leave abnormally via BrokenBarrierException (or InterruptedException if they too were interrupted at about the same time).\n\n### Limitations\n\n* number of participating threads should be specified at creation time and cannot be changed.\n\n## 5) Exchanger\n\nAn Exchanger lets a pair of threads exchange objects at a synchronization point.\n\n<span style=\"color:red\">TODO</span>\n\n## 6) Phaser (1.7)\n\n* A flexible synchronizer to do latch and barrier semantics\n* with less code and better interrupt management\n* only synchronizer in Java that is compatible with fork/join framework\n\n<span style=\"color:red\">TODO</span>\n\n## 7) ForkJoinPool (1.7)\n\n<span style=\"color:red\">TODO</span>\n\n## 8) StampedLock (1.8)\n\n<span style=\"color:red\">TODO</span>\n[Phaser and StampedLock Concurrency Synchronizers (Heinz Kabutz) ](http://vimeo.com/74553130)\n\n# Java Memory Model\n\n<span style=\"color:red\">TODO</span>\n\n# Concurrency Programming Models\n\n<span style=\"color:red\">TODO</span>\n\n* ForkJoin model\n* Actor Model\n* STM model\n\n# Concurrency Frameworks\n\n<span style=\"color:red\">TODO</span>\n\n[LMAX Disruptor](http://lmax-exchange.github.io/disruptor/) - High Performance Inter-Thread Messaging Library. Excellent blog on this topic : http://mechanitis.blogspot.com/2011_07_01_archive.html\n\n\n# FAQs\n\n* how to test throughput of concurrent programs?\n* System.millis and System.nanos\n* Work stealing pattern - learn\n* CompletionService\n* Why thread.start() shouldn't be invoked from a constructor?\n* Java 1.5 Double-checked locking mechanism\n* What is the significance of Stack Size in a thread? (JVM Option -Xss)\n* Difference between sleep(), yield(), and wait()\n  * `sleep(n)` says “I’m done with my time slice, and please don’t give me another one for at least n milliseconds.” The OS doesn't even try to schedule the sleeping thread until requested time has passed. \n  * `yield()` says “I’m done with my time slice, but I still have work to do.” The OS is free to immediately give the thread another time slice, or to give some other thread or process the CPU the yielding thread just gave up. \n  * `wait()` says “I’m done with my time slice. Don’t give me another time slice until someone calls notify().” As with sleep(), the OS won’t even try to schedule your task unless someone calls notify() (or one of a few other wake up scenarios occurs).\n* THOU SHALT NOT\n  * call `Thread.stop()` - All monitors unlocked by ThreadDeath \n  * call `Thread.suspend()` or `Thread.resume()` - Can lead to deadlock \n  * call `Thread.destroy()` - Not implemented (or safe) \n  * call `Thread.run()` - Wonʼt start Thread! Still in caller Thread. \n  * use ThreadGroups - Use a ThreadPoolExecutor instead.\n\n# Bibliography\n\n* Books\n  * Java Concurrency in Practice\n  * The CERT Oracle Secure Coding Standard for Java\n* Blogs & Articles\n  * Oracle's Multithreaded Programming Guide - concepts and terminologies\n  * Alex Miller's Concurrency Gotchas - http://www.slideshare.net/alexmiller/java-concurrency-gotchas-3666977\n  * http://www.slideshare.net/nadeembtech/java-concurrecny\n  * http://www-128.ibm.com/developerworks/library/j-csp1.html \n  * http://www-128.ibm.com/developerworks/library/j-csp2.html \n  * http://www-128.ibm.com/developerworks/library/j-csp3.html \n  * http://www.javaworld.com/javaworld/jw-10-1998/jw-10-toolbox_p.html\n  * http://www.baptiste-wicht.com/series/java-concurrency-tutorial/\n  * http://www.slideshare.net/sjlee0/robust-and-scalable-concurrent-programming-lesson-from-the-trenches\n  * http://www.slideshare.net/choksheak/advanced-introduction-to-java-multi-threading-full-chok\n  * http://www.ibm.com/developerworks/library/j-jtp08223/\n  * [DZone RefCard - Java Concurrency](https://docs.google.com/file/d/0BwRO-bJaP9EvU1M5d3pCc3BGVnc/edit?usp=sharing)\n\n"
  },
  {
    "id": 16,
    "title": "Java & Database",
    "url": "/technology/java-database.html",
    "content": "[TOC]\n\n# JDBC\n\n* Types of drivers? \n* BLOB, CLOB(singlebyte LOB), \n* DBCLOB(doublebyte LOB) \n* Scrollable resultsets \n* Rowsets http://java.sun.com/developer/Books/JDBCTutorial/chapter5.html \n* Is it good? conn.getHoldability()?  the holdability, one of ResultSet.HOLD_CURSORS_OVER_COMMIT or ResultSet.CLOSE_CURSORS_AT_COMMIT \n\n<span style=\"color:red\">TODO</span>\n\n`javax.sql.rowset.WebRowSet`\n\n# ORM\n\n* Define ORM\n* Why ORM is required? \n* What other ORM tools are available? How is Hibernate better?\n* http://blog.8thlight.com/uncle-bob/2013/10/01/Dance-You-Imps.html\n* http://java.dzone.com/articles/martin-fowler-orm-hate\n\n<span style=\"color:red\">TODO</span>\n\n## Hibernate\n\n* Challenges in migrating Hibernat 2 to 3? \n* Impedence mismatch http://t.co/4KWqBeJkOs\n* http://www.deepakgaikwad.net/index.php/2009/03/14/complete-hibernate-tutorial-with-example.html?goback=%2Egde_43888_member_255672872\n* http://www.hibernate-alternative.com/\n\n# JPA\n\nJPA specification - Apache open JPA\n\n"
  },
  {
    "id": 17,
    "title": "Java I/O",
    "url": "/technology/java-io.html",
    "content": "[TOC]\n\n# Basics\n\n* I/O in Java is divided into two types: byte- and number-oriented I/O, which is handled by input and output streams; and character and text I/O, which is handled by readers and writers.\n* Java Communications API (javax.comm),which provides the ability to do low-level I/O through a computer's serial and parallel ports.\n* Streams classes read and write bytes. Reader classes read characters and writers write characters.\n* Numeric data\n  * `int` - Fundamental integer data type in Java is 'int', a 4-byte, big endian, two's complement integers\n  * `long` - 8-byte, big endian, two's complement integers\n  * `short` - 2-byte, big endian, two's complement integers (rarely used)\n  * `byte` - 1-byte, big endian, two's complement integer from -128 to 127 (heavily used in I/O)\n* There are no short or byte literals in Java. \n``` java\nbyte b = 42; //though 42 is an int, compiler specially converts them to narrower type \nshort s = 24000; //same as above\nint i = 42; // not allowed\nshort s = i; //assigning from int variables to shorts or bytes is not allowed without explicit cast.\nbyte b = i; // not allowed\nbyte b = 1 + 2; // not allowed\n```\n\n# Stream Classes\n* A stream is an ordered sequence of bytes of undetermined length.\n* The two main classes are java.io.InputStream and java.io.OutputStream . \n* The java.util.zip package contains four input stream classes that read data in a compressed format and return it in uncompressed format and four output stream classes that read data in uncompressed format and write in compressed format.\n* The java.util.jar package includes two stream classes for reading files from JAR archives.\n* The java.security package includes a couple of stream classes used for calculating message digests.\n* The Java Cryptography Extension (JCE) adds two classes for encryption and decryption.\n\n## Input Stream \n`public abstract int read() throws IOException`\n\nThough read() returns stream of bytes, it is declared as int. This int is not a Java byte with a value between -128 and 127 but a more general unsigned byte with a value between 0 and 255. Hence, -1 can easily be distinguished from valid data values read from the stream.\n\n# OutputStream \n\n`public abstract void write(int byte) throws IOException`\n\nThis int is intended to be an unsigned byte value between and 255. However, there's nothing to stop a careless programmer from passing in an int value outside that range. In this case, the eight low-order bits are written and the top 24 high-order bits are ignored. \n\n# Character classes\n\n* Character Data type - In Java, a char is a two-byte, unsigned integer, the only unsigned type in Java. \n* The java.io.Reader and java.io.Writer classes are abstract superclasses for classes that read and write character-based data. The subclasses are notable for handling the conversion between different character sets.\n* For the most part, these classes have methods that are extremely similar to the equivalent stream classes. Often the only difference is that a byte in the signature of a stream method is replaced by a char in the signature of the matching reader or writer method.\n\n# Streams\n\n## Byte Streams\n\nByte streams for reading and writing are called input streams and output streams, respectively (represented by the abstract classes InputStream and OutputStream). \n\nPrograms use byte streams to perform input and output of 8-bit bytes. It should only be used for the most primitive I/O.\n\n``` java\n\tprivate void byteStreams(){\n   byte[] magicalJavaClassSignature = new byte[]{(byte)0xCA, (byte)0xFE, (byte)0xBA, (byte)0xBE, };\n   String filename = \"C:/temp/bytestream.data\";\n\n\n   try(FileOutputStream fos = new FileOutputStream(filename)){\n      fos.write(magicalJavaClassSignature);\n   }catch (Exception e){\n      e.printStackTrace();\n   }\n\n\n   try(FileInputStream fis = new FileInputStream(filename)){\n      byte[] bytes = new byte[4];\n      fis.read(bytes);\n      if(Arrays.equals(magicalJavaClassSignature, bytes)){\n         System.out.println(\"Matching...\");\n      } else {\n         System.out.println(\"Not matching...\");\n      }\n   }catch (Exception e){\n      e.printStackTrace();\n   }\n}\n```\n\n## Data Streams\n\n* Data streams support binary I/O of primitive data type values (boolean, char, byte, short, int, long, float, and double) as well as String values. \n* All data streams implement either the DataInput interface or the DataOutput interface. \n* Also notice that each specialized write in DataStreams is exactly matched by the corresponding specialized read. It is up to the programmer to make sure that output types and input types are matched in this way: The input stream consists of simple binary data, with nothing to indicate the type of individual values, or where they begin in the stream.\n\n``` java\nprivate void dataStreams() {\n   String filename = \"C:/temp/datastream.data\";\n   try (DataOutputStream dos = new DataOutputStream(new FileOutputStream(filename))) {\n      for (int i = 0; i < 10; i++) {\n         dos.writeByte(i);\n         dos.writeShort(i);\n         dos.writeInt(i);\n         dos.writeLong(i);\n         dos.writeFloat(i);\n         dos.writeDouble(i);\n      }\n   } catch (Exception e) {\n      e.printStackTrace();\n   }\n\n   try (DataInputStream dis = new DataInputStream(new FileInputStream(filename))) {\n      for (int i = 0; i < 10; i++) {\n         System.out.printf(\"%d %d %d %d %g %g %n\",\n            dis.readByte(),\n            dis.readShort(),\n            dis.readInt(),\n            dis.readLong(),\n            dis.readFloat(),\n            dis.readDouble());\n      }\n   } catch (Exception e) {\n      e.printStackTrace();\n   }\n}\n```\n\n## Object Streams\n\nThe object stream classes are `ObjectInputStream` and `ObjectOutputStream`. These classes implement `ObjectInput` and `ObjectOutput`, which are subinterfaces of `DataInput` and `DataOutput`. That means that all the primitive data I/O methods covered in Data Streams are also implemented in object streams. So an object stream can contain a mixture of primitive and object values.\n\n``` java\n\tprivate void objectStreams() {\n   String filename = \"C:/temp/objectstream.data\";\n   try (ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(filename))) {\n      oos.writeObject(Arrays.asList(\"hello\", \"how\", \"are\", \"you\")); //write object to stream\n   } catch (Exception e) {\n      e.printStackTrace();\n   }\n\n\n   try (ObjectInputStream ois = new ObjectInputStream(new FileInputStream(filename))) {\n      Object obj = ois.readObject(); //read object from stream\n      if (obj != null && obj instanceof List) {\n         System.out.println(obj);\n      } else {\n         System.out.println(\"Object is null or not a Map\");\n      }\n   } catch (Exception e) {\n      e.printStackTrace();\n   }\n}\n```\n\n## Character Streams\n\n* are often \"wrappers\" for byte streams. Byte stream is used to perform the physical I/O, while the character stream handles translation between characters and bytes.\n* represented by the abstract classes Reader and Writer\n* The Java platform stores character values using Unicode conventions. Character stream I/O automatically translates this internal format to and from the local character set. In Western locales, the local character set is usually an 8-bit superset of ASCII.\n* For most applications, I/O with character streams is no more complicated than I/O with byte streams. Input and output done with stream classes automatically translates to and from the local character set. A program that uses character streams in place of byte streams automatically adapts to the local character set and is ready for internationalization — all without extra effort by the programmer.\n* If internationalization isn't a priority, you can simply use the character stream classes without paying much attention to character set issues. Later, if internationalization becomes a priority, your program can be adapted without extensive recoding.\n* There are two general-purpose byte-to-character \"bridge\" streams: InputStreamReader and OutputStreamWriter. Use them to create character streams when there are no prepackaged character stream classes that meet your needs.\n\n``` java\nprivate void characterStreams(){\n   String filename = \"C:/temp/charactstream.data\";\n   try (FileWriter fw = new FileWriter(filename)) {\n      fw.write(\"What do you want to do today?\");\n      fw.append(\"\\nhello\").append(\"world\");\n      fw.flush();\n   } catch (Exception e) {\n      e.printStackTrace();\n   }\n\n\n   try (FileReader fr = new FileReader(filename)) {\n      char[] chars = new char[100];\n      fr.read(chars);\n      System.out.println(\"Char stream read: \" + new String(chars));\n   } catch (Exception e) {\n      e.printStackTrace();\n   }\n}\n```\n\n## Buffered Streams\n\n* This means each read or write request is handled directly by the underlying OS. This can make a program much less efficient, since each such request often triggers disk access, network activity, or some other operation that is relatively expensive.\n* To reduce this kind of overhead, the Java platform implements buffered I/O streams. Buffered input streams read data from a memory area known as a buffer; the native input API is called only when the buffer is empty. Similarly, buffered output streams write data to a buffer, and the native output API is called only when the buffer is full.\n* Invoking readLine returns a line of text with the line. CopyLines outputs each line using println, which appends the line terminator for the current operating system. This might not be the same line terminator that was used in the input file.\n* There are four buffered stream classes used to wrap unbuffered streams: BufferedInputStream and BufferedOutputStream create buffered byte streams, while BufferedReader and BufferedWriter create buffered character streams.\n\n``` java Buffered Byte Streams\nprivate void bufferedByteStreams(){\n   String filename = \"C:/temp/bufferedbytestream.data\";\n   try (BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(filename))) {\n      bos.write(\"hello world \\n What do you want to do today?\".getBytes());\n   } catch (Exception e) {\n      e.printStackTrace();\n   }\n\n   try (BufferedInputStream bis = new BufferedInputStream(new    FileInputStream(filename))) {\n      byte[] bytes = new byte[100];\n      bis.read(bytes);\n      System.out.println(new String(bytes));\n   } catch (Exception e) {\n      e.printStackTrace();\n   }\n}\n```\n\n``` java Buffered Character Streams\n\nprivate void bufferedCharacterStreams(){\n   String filename = \"C:/temp/bufferedcharstream.data\";\n   try (BufferedWriter bw = new BufferedWriter(new FileWriter(filename))) {\n      bw.write(\"hello world\");\n      bw.newLine();\n      bw.write(\"What do you want to do today?\");\n   } catch (Exception e) {\n      e.printStackTrace();\n   }\n\n   try (BufferedReader br = new BufferedReader(new FileReader(filename))) {\n      String input = null;\n      while( (input = br.readLine()) !=null){\n         System.out.println(input);\n      }\n   } catch (Exception e) {\n      e.printStackTrace();\n   }\n}\n```\n\n# Scanner\n\nObjects of type Scanner are useful for breaking down formatted input into tokens and translating individual tokens according to their data type.\n\n``` java\nprivate void scanner() {\n   Scanner scanner = new Scanner(\"Hello/1/2.3/\");\n   scanner = scanner.useDelimiter(Pattern.compile(\"/\"));\n   System.out.println(scanner.next());\n   System.out.println(scanner.nextInt());\n   System.out.println(scanner.nextFloat());\n}\n```\n\n# Serialization\n\n## Customize default serialization protocol \n\nImplement following methods to custom read/write objects. Notice that both methods are (and must be) declared private, proving that neither method is inherited and overridden or overloaded. The trick here is that the virtual machine will automatically check to see if either method is declared during the corresponding method call. If your super class implements Serializable and if you don't want your class to be serialized, then implement these 2 methods to throw NotSerializableException. \n\n``` java\nprivate void writeObject(ObjectOutputStream out) throws IOException; \nprivate void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException; \n```\n\n## Customize your own protocol \n\nIf you dont want to use the default java serialization technique, you can define your own technique by implementing 'Externalizable' instead of 'Serializable'. Following 2 methods needs to be implemented by your class which would contain the algorithm to persist your object. \n``` java\npublic void writeExternal(ObjectOutput out) throws IOException; \npublic void readExternal(ObjectInput in) throws IOException, ClassNotFoundException; \n```\n\n## Caching objects in the stream \nBy default, an ObjectOutputStream will maintain a reference to an object written to it. That means that if the state of the written object is written and then written again, the new state will not be saved! \n\n```java\nObjectOutputStream out = new ObjectOutputStream(...); \nMyObject obj = new MyObject(); // must be Serializable \nobj.setState(100); \nout.writeObject(obj); // <--------saves object with state = 100 \nobj.setState(200); \nout.writeObject(obj); // <--------does not save new object state \n```\n\nTo avoid the situation, do either one of the below : \n1. Close and open the stream again, or \n2. call stream.reset() \n\nChanges to a class that can hurt de-serialization : \n1. deleting an instance variable \n2. change\n\n## Difference b/w Serialiazable and Externalizable interfaces?\n???\n\n# Java NIO\n\n## Why NIO?\n\n* The File class lacked the significant functionality required to implement even commonly used functionality. For instance, it lacked a copy method to copy a file/directory.\n* The File class defined many methods that returned a Boolean value. Thus, in case of an error, false was returned, rather than throwing an exception, so the developer had no way of knowing why that call failed.\n* The File class did not provide good support for handling symbolic links.\n* The File class handled directories and paths in an inefficient way (it did not scale well).\n* The File class provided access to a very limited set of file attributes, which was insufficient in many situations.\n\n## Buffers, Channels, Selectors\n\n<span style=\"color:red\">TODO </span>\n\n## File Watcher Service\n\n``` java File Watcher Service\n private void fileWatcherService() throws Exception{\n        Path path = Paths.get(\"C:/temp\");\n        WatchService watchService = path.getFileSystem().newWatchService();\n        path.register(watchService, StandardWatchEventKinds.ENTRY_MODIFY); //only event can be registered per watch service\n\n        for(;;){\n            final WatchKey watchKey = watchService.take();\n            for (WatchEvent<?> watchEvent : watchKey.pollEvents()) {\n                final Path context = (Path) watchEvent.context();\n                System.out.println(\"Event kind: \" + watchEvent.kind().name() + \" - \" + context.getFileName());\n            }\n            watchKey.reset(); //resetting the key is important to receive subsequent notifications\n        }\n    }\n```\n\n# Character Sets\n\n[The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) by Joel Spolsky](http://www.joelonsoftware.com/articles/Unicode.html)\n\n## ASCII\n\n{% img right /technology/ascii-table.gif %}\n* the American Standard Code for Information Interchange, is a 7-bit character set. Thus it defines 27 or 128 different characters whose numeric values range from to 127.\n* All Java programs can be expressed in pure ASCII. Non-ASCII Unicode characters are encoded as Unicode escapes; that is, written as a backslash ( \\), followed by a u, followed by four hexadecimal digits; for example, \\u00A9.\n\n\n## ISO Latin-1\n\nISO Latin-1 is an eight-bit character set that's a strict super-set of ASCII. It defines 28 or 256 different characters whose numeric values range from to 255. The first 128 characters—that is, those numbers with the high-order bit equal to zero—correspond exactly to the ASCII character set. Thus 65 is ASCII A and ISO Latin-1 A; 66 is ASCII B and ISO Latin-1 B; and so on. Where ISO Latin-1 and ASCII diverge is in the characters between 128 and 255 (characters with high bit equal to one). ASCII does not define these characters. ISO Latin-1 uses them for various accented letters like ü needed for non-English languages written in a Roman script, additional punctuation marks and symbols like ©, and additional control characters. \n\n## Unicode\n\n* Unicode is a 2-byte, 16-bit character set with 216 or 65,536 different possible characters. (Only about 40,000 are used in practice, the rest being reserved for future expansion.) Unicode can handle most of the world's living languages and a number of dead ones as well.\n* Java streams do not do a good job of reading Unicode text. (This is why readers and writers were added in Java 1.1.) Streams generally read a byte at a time, but each Unicode character occupies two bytes. Thus, to read a Unicode character, you multiply the first byte read by 256, add it to the second byte read, and cast the result to a char. For example:\n``` java\n int b1 = in.read();\n int b2 = in.read();\n char c = (char) (b1*256 + b2);\n ```\n\n## UTF-8\n\n* Unicode is a relatively inefficient encoding when most of your text consists of ASCII characters. Every character requires the same number of bytes—two—even though some characters are used much more frequently than others. A more efficient encoding would use fewer bits for the more common characters. This is what UTF-8 does. \n* In UTF-8 the ASCII alphabet is encoded using a single byte, just as in ASCII. The next 1,919 characters are encoded in two bytes. The remaining Unicode characters are encoded in three bytes. However, since these three-byte characters are relatively uncommon, especially in English text, the savings achieved by encoding ASCII in a single byte more than makes up for it.\n* Java's .class files use UTF-8 internally to store string literals. Data input streams and data output streams also read and write strings in UTF-8. However, this is all hidden from direct view of the programmer, unless perhaps you're trying to write a Java compiler or parse output of a data stream without using the DataInputStream class.\n\n## Character set in Java \nJava understands several dozen different character sets for a variety of languages, ranging from ASCII to the Shift Japanese Input System (SJIS) to Unicode. Internally, Java uses the Unicode character set. Unicode is a two-byte extension of the one-byte ISO Latin-1 character set, which in turn is an eight-bit superset of the seven-bit ASCII character set.\n\n# Miscellaneous\n* http://www.ashishpaliwal.com/blog/2008/10/nio-frameworks-in-java/\n* Apache MINA\n* xSockets\n* Grizzly\n* Netty Non-blocking I/O Framework: http://www.manning.com/maurer/netty_meap_ch1.pdf\n\n# Bibliography\n* Oracle Certified Professional Java SE 7 (Chapter 8 & 9)\n* OReilly - Java IO\n* OReilly - Java NIO\n* Apress - Pro Java 7 NIO.2\n* http://docs.oracle.com/javase/tutorial/essential/io/"
  },
  {
    "id": 18,
    "title": "JMX",
    "url": "/technology/java-jmx.html",
    "content": "[TOC]\n\n# Overview\n\nJMX Spec implementors\n\n* Sun's reference implementation - lib/jmxri.jar (JMX reference implementation Java class package) and lib/jmxtools.jar (JMX toolkit) \n* Sun's Java Dynamic Management Kit\n* IBM Tivoli's JMX implementation\n* AdventNet Agent Toolkit\n\n# JMX Architecture\n\n> http://docs.oracle.com/javase/6/docs/technotes/guides/management/overview.html\n\n{% img /technology/jmx-architecture.png %}\n\n# Java VM Instrumentation\n\nTechnology that enables to monitor and manage applications running in a JVM locally or remotely.\n\n## JMX Components\n\n* Managemement Application - JConsole\n* JMX API - The java.lang.mangement package provides the interface for monitoring and managing the VM.\n* Managed Resource - your application to be instrumented\n* MBean Interface - Interface to which mgmt. app connects to.\n* MBean or Managed Bean - Implementation of the MBean interface. This object interacts with your app to get/set attributes or invoke methods. \n* MBean Server - container where MBeans are registered using a unique name.\n\n## MBean\n\n* MBeans are Java objects that represent resources to be managed. An MBean has a management interface consisting of the following.\n  * Named and typed attributes that can be read and written.\n  * Named and typed operations that can be invoked.\n  * Typed notifications that can be emitted by the MBean.\n* Platform MBean - is an MBean for monitoring and managing the Java VM and other components of the Java Runtime Environment (JRE). Each MXBean encapsulates a part of VM functionality such as the class loading system, just-in-time (JIT) compilation system, garbage collector, and so on.\n* Types of MBean\n  * Standard\n  * Dynamic\n  * Open\n  * Model\n  * MXBean\n\n## Standard MBean\n\nStandard MBeans are the simplest MBeans. Here are what you need to do to manage a Java object using a standard MBean.\n\n1. Create an interface named after your Java class plus the suffix MBean. For example, if the Java class whose objects you want to manage is called Car, the interface must be called CarMBean.\n* Modify your Java class so that it implements the interface you’ve created.\n* Create an agent. The agent class must contain an MBean server.\n* Create an ObjectName for your MBean.\n* Instantiate the MBean server.\n* Register your MBean with the MBean server.\n\nStandard MBeans are easy to write, but they require that your classes be modified. While this is okay in some projects, in others (especially when there are many classes involved) this is not acceptable. Fortunately, other types of MBeans allow you to manage objects without modifying classes.\n\n## MXBean\n\nThe name of this interface must end with MXBean (as opposed to MBean with standard MBeans), however the prefix does not have to match the name of the manageable class. This is to say your manageable class may be called Car and your MXBean interface may be named CarImpl.\n\nAlternatively, if you don’t want to follow the naming convention for MXBeans, i.e. you don’t want your interface name to end with MXBean, you can simply apply the @MXBean annotation to your interface definition.\n\nhttp://docs.oracle.com/javase/6/docs/api/javax/management/MXBean.html\n\nWhy MXBean? MXBean is a new type of MBean that provides a simple way to code an MBean that only references a predefined set of types. In this way, you can be sure that your MBean will be usable by any client, including remote clients, without any requirement that the client have access to model-specific classes representing the types of your MBeans. The platform MBeans introduced below are all MXBeans.\n\n# MBean Server or JMX Agent\n\nAn MBean Server is a repository of MBeans. Each MBean is registered with a unique name within the MBean server. Usually the only access to the MBeans is through the MBean server. In other words, code does not access an MBean directly, but rather accesses the MBean by name through the MBean server.\n\n## Platform MBean Server\n\nThe platform MBean Server can be shared by different managed components running within the same Java VM. You can access the platform MBean Server with the method `ManagementFactory.getPlatformMBeanServer()`. The first call to this method, creates the platform MBean server and registers the platform MXBeans using their unique object names. Subsequently, it returns the initially created platform MBeanServer instance.\n\nMXBeans that are created and destroyed dynamically (for example, memory pools and managers) will automatically be registered and unregistered in the platform MBean server. If the system property `javax.management.builder.initial` is set, the platform MBean server will be created by the specified `MBeanServerBuilder`.\n\nYou can use the platform MBean server to register other MBeans besides the platform MXBeans. This enables all MBeans to be published through the same MBean server and makes network publishing and discovery easier.\n\n## Creating & Registering MBean\n\nThere are 2 ways to do this\nOne is to construct a Java object that will be the MBean, then use the `registerMBean` method to register it in the MBean Server. This method is simpler for local use, but cannot be used remotely.\n\nThe other is to create and register the MBean in a single operation using one of the createMBean methods. This method can be used remotely, but sometimes requires attention to class loading issues.\nAn MBean can perform actions when it is registered in or unregistered from an MBean Server if it implements the MBeanRegistration interface.\n\n### Local\n\nBefore Java SE 6, JMX agent is enabled by passing the system property `-Dcom.sun.management.jmxremote`. Any application that is started on the Java SE 6 platform will support the Attach API, and so will automatically be made available for local monitoring and management when needed.\n\n### Remote\n\nTo enable a JVM for remote monitoring, pass in `-Dcom.sun.management.jmxremote.port=portNum`. Password authentication for remote monitoring is enabled by default. To disable, `com.sun.management.jmxremote.authenticate=false`.\n\n## Attach API\n\nWhat if a VM is not enabled for monitoring? Attach API comes to rescue. It is an extension that provides a mechanism to attach to a VM and load its tool agent into that virtual machine. For example, a management console might have a management agent which it uses to obtain management information from instrumented objects in a virtual machine. If the management console is required to manage an application that is running in a virtual machine that does not include the management agent, then this API can be used to attach to the target virtual machine and load the agent.\n\nhttp://docs.oracle.com/javase/6/docs/jdk/api/attach/spec/index.html - com.sun.tools.attach.\n\n# Management Tools\n\n## JConsole\n\n* has plug-in support that allows you to build your own plug-ins to run with JConsole, for example, to add a custom tab for accessing your applications' MBeans.\n* Dynamic attach capability, allowing you to connect JConsole to any application that supports the Attach API, that was added to the Java SE platform, version 6.\n* The HotSpot Diagnostic MBean, which provides an API to request heap dump at runtime and also change the setting of certain VM options.\n\n``` java To enable JMX in a VM\n-Dcom.sun.management.jmxremote\n-Dcom.sun.management.jmxremote.port=3333\n-Dcom.sun.management.jmxremote.ssl=false\n-Dcom.sun.management.jmxremote.authenticate=false\n```\n\n# Groovy & JMX\n\nhttp://marxsoftware.blogspot.com/2013/03/monitoring-key-jvm-characteristics-groovy-jmx.html\n\n\n\n# Bibliography\n\n* Books\n  * JMX in Action\n* http://docs.oracle.com/javase/6/docs/technotes/guides/management/overview.html\n* [Java theory and practice: Instrumenting applications with JMX - Brian Goetz](http://www.ibm.com/developerworks/java/library/j-jtp09196/index.html?ca=drs)\n* http://marxsoftware.blogspot.com/search/label/JMX\n* http://www.jolokia.org/\n* http://www.wilsonmar.com/jmx_java.htm\n* Examples on programmatic access of JMX - http://docs.oracle.com/cd/E19340-01/820-6766/index.html\n* http://www.javaworld.com/community/print/1186\n* https://weblogs.java.net/blog/emcmanus/archive/2006/02/what_is_an_mxbe.html\n* http://download.java.net/jdk8/docs/technotes/guides/jmx/tutorial/essential.html#wp1053098\n* http://rterp.wordpress.com/tag/mxbean/\n* http://www.adam-bien.com/roller/abien/entry/singleton_the_simplest_possible_jmx\n* https://weblogs.java.net/blog/emcmanus/archive/2005/10/adding_descript.html\n* [Platform MBean Server](http://www.ibm.com/developerworks/java/library/j-java6perfmon/) provided with J2SE 5 and Java SE 6, including all the useful JMX utility classes introduced with J2SE 5 and Java SE 6\n* [MXBeans](http://docs.oracle.com/javase/6/docs/technotes/guides/management/mxbeans.html)\n* Web Services Connector as defined by JSR-262\n* [Spring framework support for JMX](http://docs.spring.io/spring/docs/2.5.x/reference/jmx.html)\n* Ability for all types of MBeans, not just Model MBeans, to have Descriptors\n* [JMX best practices](http://marxsoftware.blogspot.com/2008/01/jmx-best-practices.html) and lessons learned are not as prevalent (though some are mentioned in these books) as they are now simply due to lack of time to learn these -lessons and observe and collect these best practices. \n* https://weblogs.java.net/blog/2006/05/04/mustang-jconsole"
  },
  {
    "id": 19,
    "title": "JNDI",
    "url": "/technology/java-jndi.html",
    "content": "[TOC]\n\n\n# Overview\n\n* A naming service associates names with distributed objects, files, and devices so that they can be located on the network using simple names instead of cryptic network address. An example of a naming service is the DNS, which converts an Internet hostname like www.google.com into a network address that browsers use to connect to web servers.\n* Naming services allow printers, distributed objects, and JMS administered objects to be bound to names and organized in a hierarchy similar to a filesystem.\n* A directory service is a more sophisticated kind of naming service.\n\n# JNDI\n\n* JNDI (Java Naming & Directory Interface) is a standard Java extension that provides a uniform API for accessing a variety of naming & directory services.\n* JNDI lets you write code that can access different directory and naming services like LDAP, NDS, CORBA Naming Service, and proprietary naming services provided by JMS servers.\n* JNDI is both virtual and dynamic. \n  * It is virtual because it allows one naming service to be linked to another. Using JNDI, you can drill down through directories to files, printers, JMS administered objects, and other resources following virtual links between naming services. The user doesn’t know or care where the directories are actually located. As an administrator, you can create virtual directories that span a variety of different services over many different physical locations.\n  * JNDI is dynamic because it allows the JNDI drivers for specific types of naming and directory services to be loaded dynamically at runtime. A driver maps a specific kind of naming or directory service into the standard JNDI class interfaces. Drivers have been created for LDAP, Novell NetWare NDS, Sun Solaris NIS+, CORBA CosNaming, and many other types of naming and directory services, including proprietary ones. Dynamically loading JNDI drivers (service providers) makes it possible for a client to navigate across arbitrary directory services without knowing in advance what kinds of services it is likely to find.\n\n\n``` java Sample jndi.properties\n java.naming.factory.initial = org.apache.activemq.jndi.ActiveMQInitialContextFactory\n java.naming.provider.url = tcp://localhost:61616\n java.naming.security.principal=system\n java.naming.security.credentials=manager\n\n connectionFactoryNames = TopicCF\n topic.topic1 = jms.topic1\n ```"
  },
  {
    "id": 20,
    "title": "Java Specialist Newsletters",
    "url": "/technology/java-newsletters.html",
    "content": "[TOC]\n\n\n# Best Practices\n* [Issue 039] Why I don't read your code comments ...\n* [Issue 050] Commenting out your code?\n* [Issue 116] Closing Database Statements Don't Repeat Yourself. The mantra of the good Java programmer. But database code often leads to this antipattern. Here is a neat simple solution from the Jakarta Commons DbUtils project.\n* [Issue 051] Java Import Statement Cleanup\n\n# Collections\n* [Issue 015] Implementing a SoftReference based HashMap\n* [Issue 016] Blocking Queue\n* [Issue 024] Self-tuning FIFO Queues\n* [Issue 027] Circular Array List\n* [Issue 031] Hash, hash, away it goes! When I first started using Java in 1997, I needed very large hash tables for matching records as quickly as possible. We ran into trouble when some of the keys were mutable and ended up disappearing from the table, and then reappearing again later.\n* [Issue 040] Visiting your Collection's Elements\n* [Issue 054] HashMap requires a better hashCode() - JDK 1.4 Part II\n* [Issue 054b] Follow-up to JDK 1.4 HashMap hashCode() mystery\n* [Issue 073] LinkedHashMap is Actually Quite Useful\n* [Issue 111] What is faster - LinkedList of ArrayList?\n* [Issue 133] Safely and Quickly Converting EJB3 Collections When we query the database using EJB3, the Query object returns an untyped collection. In this newsletter we look at several approaches for safely converting this to a typed collection.\n* [Issue 178] WalkingCollection We look at how we could internalize the iteration into a collection by introducing a Processor interface that is applied to each element. This allows us to manage concurrency from within the collection.\n* [Issue 178b] WalkingCollection Generics Generics can be used to further improve the WalkingCollection, shown in our previous newsletter.\n* [Issue 193] Memory Usage of Maps In this newsletter we measure the memory requirements of various types of hash maps available in Java. Maps usually need to be threadsafe, but non-blocking is not always the most important requirement.\n* [Issue 212] Creating Sets from Maps Maps and Sets in Java have some similarities. In this newsletter we show a nice little trick for converting a map class into a set.\\n[issue 211] Unicode Redux (2 of 2) We continue our discussion on Unicode by looking at how we can compare text that uses diacritical marks or special characters such as the German Umlaut.\n\n# Concurrency\n* [Issue 001] Deadlocks\n* [Issue 056] Shutting down threads cleanly\n* [Issue 061] Double-checked locking\n* [Issue 076] Asserting Locks\n* [Issue 093] Automatically Detecting Thread Deadlocks\n* [Issue 101] Causing Deadlocks in Swing Code\n* [Issue 101b] Causing Deadlocks in Swing Code (Follow-up)\n* [Issue 104] EDT Lockup Detection\n* [Issue 130] Deadlock Detection with new Locks Java level monitor deadlocks used to be hard to find. Then along came JDK 1.4 and showed them in CTRL+Break. In JDK 1.5, we saw the addition of the ThreadMXBean, which made it possible to continually monitor an application for deadlocks. However, the limitation was that the ThreadMXBean only worked for synchronized blocks, and not the new java.util.concurrent mechanisms. In this newsletter, we take a fresh look at the deadlock detector and show what needs to change to make it work under JDK 1.6. Also, we have a look at what asynchronous exceptions are, and how you can post them to another thread.\n* [Issue 146] The Secrets of Concurrency (Part 1) Learn how to write correct concurrent code by understanding the Secrets of Concurrency. This is the first part of a series of laws that help explain how we should be writing concurrent code in Java.\n* [Issue 147] The Law of the Distracted Spearfisherman Learn how to write correct concurrent code by understanding the Secrets of Concurrency. This is the second part of a series of laws that help explain how we should be writing concurrent code in Java. We look at how to debug a concurrent program by knowing what every thread in the system is doing.\n* [Issue 149] The Law of the Overstocked Haberdashery Learn how to write correct concurrent code by understanding the Secrets of Concurrency. This is the third part of a series of laws that help explain how we should be writing concurrent code in Java. In this section, we look at why we should avoid creating unnecessary threads, even if they are not doing anything.\n* [Issue 150] The Law of the Blind Spot In this fourth law of concurrency, we look at the problem with visibility of shared variable updates. Quite often, \"clever\" code that tries to avoid locking in order to remove contention, makes assumptions that may result in serious errors.\n* [Issue 151] The Law of the Leaked Memo In this fifth law of concurrency, we look at a deadly law where a field value is written early.\n* [Issue 154] ResubmittingScheduledPoolExecutor Timers in Java have suffered from the typical Command Pattern characteristics. Exceptions could stop the timer altogether and even with the new ScheduledPoolExecutor, a task that fails is cancelled. In this newsletter we explore how we could reschedule periodic tasks automatically.\n* [Issue 160] The Law of the Uneaten Lutefisk Imagine a very stubborn viking father insisting that his equally stubborn child eat its lutefisk before going to sleep. In real life one of the \"threads\" eventually will give up, but in Java, the threads become deadlocked, with neither giving an inch. In this newsletter we discover how we can sometimes escape from such deadlocked situations in Java and learn why the stop() function should never ever ever be called.\n* [Issue 165] Starvation with ReadWriteLocks In this newsletter we examine what happens when a ReadWriteLock is swamped with too many reader or writer threads. If we are not careful, we can cause starvation of the minority in some versions of Java.\n* [Issue 172] Wonky Dating The DateFormat produces some seemingly unpredictable results parsing the date 2009-01-28-09:11:12 as \"Sun Nov 30 22:07:51 CET 2008\". In this newsletter we examine why and also show how DateFormat reacts to concurrent access.\n* [Issue 176] The Law of the Xerox Copier Concurrency is easier when we work with immutable objects. In this newsletter, we define another concurrency law, The Law of the Xerox Copier, which explains how we can work with immutable objects by returning copies from methods that would ordinarily modify the state.\n* [Issue 184] Deadlocks through Cyclic Dependencies A common approach to ensuring serialization consistency in thread safe classes such as Vector, Hashtable or Throwable is to include a synchronized writeObject() method. This can result in a deadlock when the object graph contain a cyclic dependency and we serialize from two threads. Whilst unlikely, it has happened in production.\n* [Issue 188] Interlocker - Interleaving Threads In this newsletter, we explore a question of how to call a method interleaved from two threads. We show the merits of lock-free busy wait, versus explicit locking. We also discuss an \"unbreakable hard spin\" that can cause the JVM to hang up.\n* [Issue 190] Automatically Unlocking with Java 7 In this newsletter we explore my favourite new Java 7 feature \"try-with-resource\" and see how we can use this mechanism to automatically unlock Java 5 locks.\n* [Issue 190b] Automatically Unlocking with Java 7 -- Follow-up In this newsletter we discuss why we unfortunately will not be able to use the try-with-resource mechanism to automatically unlock in Java 7.\n* [Issue 192] Implicit Escape of \"this\" We should never allow references to our objects to escape before all the final fields have been set, otherwise we can cause race conditions. In this newsletter we explore how this is possible to do.\n* [Issue 192b] How Does \"this\" Escape? A quick follow-up to the previous newsletter, to show how the ThisEscape class is compiled, causing the \"this\" pointer to leak.\n* [Issue 194] trySynchronize Did you know that it possible to \"try\" to synchronize a monitor? In this newsletter we demonstrate how this can be used to avoid deadlocks and to keep the wine coming.\n* [Issue 200] On Learning Concurrency Every Java programmer I have met knows that they should know more about concurrency. But it is a topic that is quite hard to learn. In this newsletter I give some tips on how you can become proficient in concurrency.\n* [Issue 201] Fork/Join With Fibonacci and Karatsuba The new Java 7 Fork/Join Framework allows us to define our algorithms using recursion and then to easily parallelize them. In this newsletter we describe how that works using a fast Fibonacci algorithm that uses the sum of the squares rather than brute force. We also present a faster algorithm for multiplying two large BigInteger numbers, using the Fork/Join Framework and the Karatsuba algorithm.\n* [Issue 206] Striped Executor Service We present a new type of ExecutorService that allows users to \"stripe\" their execution in such a way that all tasks belonging to one stripe are executed in-order.\n \n# Database\n* [Issue 047] Lack of Streaming leads to Screaming\n* [Issue 118] A Simple Database Viewer A simple database viewer written in Java Swing that reads the metadata and shows you all the tables and contents of the tables, written in under 100 lines of Java code, including comments.\n* [Issue 136] Sneaking in JDBC Drivers In this newsletter, we look at a technique of how we can replace an existing database driver with our own one. This could be used to migrate an application to a new database where you only have the compiled classes. Or it could be used to insert a monitoring JDBC connection that measures the length of database queries.\n\n# Design Patterns\n* [Issue 005] Dynamic Proxies - Short Tutorial\n* [Issue 034] Generic Types with Dynamic Decorators\n* [Issue 052] J2EE Singleton\n* [Issue 074] GoF Factory Method in writing GUIs\n* [Issue 108] Object Adapter based on Dynamic Proxy\n* [Issue 109] Strategy Pattern of HashCode Equality\n* [Issue 123] Strategy Pattern with Generics The Strategy Pattern is elegant in its simplicity. With this pattern, we should try to convert intrinsic state to extrinsic, to allow sharing of strategy objects. It gets tricky when each strategy object needs a different set of information in order to do its work. In this newsletter, we look at how we can use Java 5 Generics to pass the correct subtype of the context into each strategy object.\n* [Issue 180] Generating Static Proxy Classes - 1/2 In this newsletter, we have a look at how we can create new classes in memory and then inject them into any class loader. This will form the basis of a system to generate virtual proxies statically.\n* [Issue 181] Generating Static Proxy Classes - 2/2 In this newsletter, we show how the Generator described in our previous issue can be used to create virtual proxy classes statically, that is, by generating code instead of using dynamic proxies.\n \n# Enums\n* [Issue 107] Making Enumerations Iterable\n* [Issue 113] Enum Inversion Problem A problem that I encountered when I first started using enums was how to serialize them to some persistent store. My initial approach was to write the ordinal to the database. In this newsletter, I explore some ideas of a more robust approach. It will also show you some applications of Java generics.\n* [Issue 141] Hacking Enums Enums are implemented as constant flyweights. You cannot construct them. You cannot clone them. You cannot make copies with serialization. But here is a way we can make new ones in Java 5.\n* [Issue 161] Of Hacking Enums and Modifying \"final static\" Fields The developers of the Java language tried their best to stop us from constructing our own enum instances. However, for testing purposes, it can be useful to temporarily add new enum instances to the system. In this newsletter we show how we can do this using the classes in sun.reflect. In addition, we use a similar technique to modify static final fields, which we need to do if we want the switch statements to still work with our new enums.\n\n# Exceptions\n* [Issue 032] Exceptional Constructors - Resurrecting the dead\n* [Issue 033] Making Exceptions Unchecked\n* [Issue 081] Catching Exceptions in GUI Code\n* [Issue 089] Catching Uncaught Exceptions in JDK 1.5\n* [Issue 208] Throwing Exceptions from Fields How can you set a field at point of declaration if its constructor throws a checked exception?\n* [Issue 120] Exceptions From Constructors What do you do when an object cannot be properly constructed? In this newsletter, we look at a few options that are used and discuss what would be best. Based on the experiences of writing the Sun Certified Programmer for Java 5 exam.\n* [Issue 129] Fast Exceptions in RIFE One of the tricks that Java allows us to employ is to change the control flow of the application using exceptions. This is generally strongly discouraged, since it makes the code hard to decipher. In addition, exceptions are notoriously bad at performance. Here is a trick used in RIFE to make this work faster.\n* [Issue 138] Better SQLExceptions in Java 6 Java 6 has support for JDBC 4, which, amongst other things, gives you better feedback of what went wrong with your database query. In this newsletter we demonstrate how this can be used.\n* [Issue 162] Exceptions in Java In this article, we look at exception handling in Java. We start with the history of exceptions, looking back at the precursor of Java, a language called Oak. We see reasons why Thread.stop() should not be used and discover the mystery of the RuntimeException name. We then look at some best practices that you can use for your coding, followed by some worst practices, in the form of exception anti-patterns.\n* [Issue 171] Throwing ConcurrentModificationException Early One of the hardest exceptions to get rid of in a system is th ConcurrentModificationException, which typically occurs when a thread modifies a collection whilst another is busy iterating. In this newsletter we show how we can fail on the modifying, rather than the iterating thread.\n* [Issue 187] Cost of Causing Exceptions Many years ago, when hordes of C++ programmers ventured to the greener pastures of Java, some strange myths were introduced into the language. It was said that a \"try\" was cheaper than an \"if\" - when nothing went wrong.\n* [Issue 196] Uncaught AWT Exceptions in Java 7 Java 7 removes the Swing Event Dispatch Thread (EDT) hack that allowed us to specify an uncaught exception handler for the EDT using a system property sun.awt.exception.handler.\n \n# GC & Memory\n* [Issue 060] Nulling variables and garbage collection\n* [Issue 078] MemoryCounter for Java 1.4\n* [Issue 092] OutOfMemoryError Warning System\n* [Issue 098] References\n* [Issue 115] Young vs. Old Generation GC A few weeks ago, I tried to demonstrate the effects of old vs. new generation GC. The results surprised me and reemphasized how important GC is to your overall program performance.\n* [Issue 173] Java Memory Puzzle In this newsletter we show you a puzzle, where a simple request causes memory to be released, that otherwise could not. Solution will be shown in the next newsletter.\n* [Issue 174] Java Memory Puzzle Explained In this newsletter, we reveal the answer to the puzzle from last month and explain the reasons why the first class sometimes fails and why the second always succeeds. Remember this for your next job interview ...\n* [Issue 179] Escape Analysis Escape analysis can make your code run 110 times faster - if you are a really really bad programmer to begin with :-) In this newsletter we look at some of the places where escape analysis can potentially help us.\n* [Issue 191] Delaying Garbage Collection Costs The garbage collector can cause our program to slow down at inappropriate times. In this newsletter we look at how we can delay the GC to never run and thus produce reliable results. Then, instead of actually collecting the dead objects, we simply shut down and start again.\n\n# I/O\n* [Issue 020] Serializing Objects Into Database\n* [Issue 023] Socket Wheel to handle many clients\n* [Issue 046] \"The compiler team is writing useless code again ...\"\n* [Issue 058] Counting bytes on Sockets\n* [Issue 088] Resetting ObjectOutputStream\n* [Issue 166] Serialization Cache Java's serialization mechanism is optimized for immutable objects. Writing objects without resetting the stream causes a memory leak. Writing a changed object twice results in only the first state being written. However, resetting the stream also loses the optimization stored in the stream.\n* [Issue 183] Serialization Size of Lists What has a larger serializable size, ArrayList or LinkedList? In this newsletter we examine what the difference is and also why Vector is a poor candidate for a list in a serializable class.\n\n# Logging\n* [Issue 003] Logging part 1\n* [Issue 004] Logging part 2\n* [Issue 177] Logging Part 3 of 3 After almost nine years of silence, we come back to bring the logging series to an end, looking at best practices and what performance measurements to log.\n\n# Performance\n* [Issue 042] Speed-kings of inverting booleans\n* [Issue 064] Disassembling Java Classes\n* [Issue 070] Too many dimensions are bad for you\n* [Issue 070b] Multi-Dimensional Arrays - Creation Performance\n* [Issue 090] Autoboxing Yourself in JDK 1.5\n* [Issue 105] Performance Surprises in Tiger\n* [Issue 195] Performance Puzzler With a Stack Trace In this newsletter, we present a little performance puzzler, written by Kirk Pepperdine. What is happening with this system? There is only one explanation and it can be discovered by just looking at the stack trace.\n* [Issue 202] Distributed Performance Tuning In this newsletter, it is up to you to figure out how we improved the performance of our previous Fibonacci newsletter by 25%.\n* [Issue 134] DRY Performance As developers we often hear that performance often comes at the price of good design. However when we have our performance tuning hats on, we often find that good design is essential to help achieve good performance. In this article we will explore one example of where a good design choice has been essential in an effort to improve performance.\n* [Issue 157] Polymorphism Performance Mysteries Late binding is supposed to be a bottleneck in applications - this was one of the criticisms of early Java. The HotSpot Compiler is however rather good at inlining methods that are being called through polymorphism, provided that we do not have very many implementation subclasses.\n* [Issue 158] Polymorphism Performance Mysteries Explained In this newsletter, we reveal some of the polymorphism mysteries in the JDK. The HotSpot Server Compiler can distinguish between mono-morphism, bi-morphism and poly-morphism. The bi-morphism is a special case which executes faster than poly-morphism. Mono-morphism can be inlined by the compiler in certain circumstances, thus not costing anything at all.\n\n# Misc\n* [Issue 035] Doclets Find Bad Code\n* [Issue 038a] Counting Objects Clandestinely\n* [Issue 038b] Counting Objects Clandestinely - Follow-up\n* [Issue 049] Doclet for finding missing comments\n* [Issue 053] Charting unknown waters in JDK 1.4 Part I\n* [Issue 055] Once upon an Oak ...\n* [Issue 057] A Tribute to my Dad, Hans Rudolf Kabutz\n* [Issue 059] When arguments get out of hand...\n* [Issue 059b] Follow-up to Loooong Strings\n* [Issue 063] Revisiting Stack Trace Decoding\n* [Issue 069] Treating Types Equally - or - Life's Not Fair!\n* [Issue 069b] Results of last survey\n* [Issue 072] Java and Dilbert\n* [Issue 077] \"Wonderfully disgusting hack\"\n* [Issue 080] Many Public Classes in One File\n* [Issue 083] End of Year Puzzle\n* [Issue 083b] End of Year Puzzle Follow-up\n\n# OOPS & Basics\n* [Issue 002] Anonymous Inner Classes\n* [Issue 006] Implementation code inside interfaces\n* [Issue 008] boolean comparisons\n* [Issue 009] Depth-first Polymorphism\n* [Issue 014] Insane Strings\n* [Issue 017a] Switching on Object Handles\n* [Issue 017b] Follow-up\n* [Issue 018] Class names don't identify a class\n* [Issue 021] Non-virtual Methods in Java\n* [Issue 025] Final Newsletter\n* [Issue 028] Multicasting in Java\n* [Issue 036] Using Unicode Variable Names\n* [Issue 062] The link to the outer class\n* [Issue 062b] Follow-up and Happy New Year!\n* [Issue 067] BASIC Java\n* [Issue 068] Appending Strings\n* [Issue 071] Overloading considered Harmful\n* [Issue 079] Generic toString()\n* [Issue 086] Initialising Fields before Superconstructor call\n* [Issue 086b] Initialising Fields before Superconstructor call (Follow-up)\n* [Issue 094] Java Field Initialisation\n* [Issue 095] Self-reloading XML Property Files\n* [Issue 095b] Follow-up: Self-reloading XML Property Files\n* [Issue 096] Java 5 - \"final\" is not final anymore\n* [Issue 110] Break to Labeled Statement\n* [Issue 127] Casting like a Tiger Java 5 adds a new way of casting that does not show compiler warnings or errors. Yet another way to shoot yourself in the foot?\n* [Issue 203] GOTO in Java It is possible to use the break statement to jump out to the end of a labelled scope, resulting in some strange looking code, almost like the GOTO statement in C.\n* [Issue 210] Calling Methods from a Constructor In this newsletter we investigate what can go wrong when we call methods from constructors, showing examples from the JDK, Glassfish, Spring Framework and some other well known frameworks..\n\n\n\n# Systems\n* [Issue 011] Hooking into the shutdown call\n* [Issue 022] Classloaders Revisited: \"Hotdeploy\"\n* [Issue 026] Package Versioning\n* [Issue 029] Determining Memory Usage in Java\n* [Issue 037] Checking that your classpath is valid\n* [Issue 043] Arrgh, someone wants to kill me!\n* [Issue 087] sun.reflect.Reflection\n* [Issue 091] Controlling Machines Remotely with Java\n\n \n# UI\n* [Issue 007] java.awt.EventQueue\n* [Issue 010] Writing GUI Layout Managers\n* [Issue 012] Setting focus to second component of modal dialog\n* [Issue 013a] Serializing GUI Components Across Network\n* [Issue 013b] Follow-up\n* [Issue 019] Finding Lost Frames\n* [Issue 030] What do you Prefer?\n* [Issue 041] Placing components on each other\n* [Issue 045] Multi-line cells in the JTable\n* [Issue 065] Wait, Cursor, Wait!\n* [Issue 075] An Automatic Wait Cursor: WaitCursorEventQueue\n* [Issue 082] TristateCheckBox based on the Swing JCheckBox\n* [Issue 106] Multi-line cells in JTable in JDK 1.4+\n* [Issue 143] Maths Tutor in GWT Google Web Toolkit (GWT) allows ordinary Java Programmers to produce highly responsive web user interfaces, without needing to become experts in JavaScript. Here we demonstrate a little maths game for practicing your arithmetic. Included is an Easter egg.\n* [Issue 148] Snappy JSliders in Swing Recent versions of Swing do a good job of mimicking the underlying platform, with a few caveats. For example, the JSlider only snaps onto the correct tick once you let go of the mouse. Here I present a fix for this problem with a non-intrusive one-liner that we can add to the application code.\n\n\n# Web Services\n* [Issue 084] Ego Tripping with Webservices\n\n# Book Reviews\n*  [Issue 044] Review: Object-Oriented Implementation of Numerical Methods In our first book review, we look at an interesting book that talks about implementing numerical methods in Java. Although not primarily a Java book, it gives us some insight as to the performance of Java versus other languages like C or Smalltalk.\n*  [Issue 048] Review: The Secrets of Consulting How much do your customers love you? How should you give and receive advice? In this excellent book, we learn why it is so important to understand your customer. I use the principles daily in my work with code reviews, performance tuning and dealing with customers or clients.\n*  [Issue 066] Book Review: Java Performance Tuning by Jack Shirazi In this book, Jack outlines the process used to make Java systems run faster. He gives lots of tips on how to find your bottlenecks and then also gives specific tricks to make your code just that bit faster. A must-have for Java programmers who care about the speed of their programs.\n*  [Issue 085] Book Review: Pragmatic Programmer One of my favourite software development books, this one takes a good hard look at how to be a programmer in the real world. Surprisingly thin for a book with this much substance, I refer to the ideas in here all the time. The pragmatic bunch have built an entire industry around their software pragmatism.\n*  [Issue 112] Book Review: Head First Design Patterns This book is a fantastic introduction to Design Patterns, probably the best available. In this newsletter, I look at some of the winning formulae used in the book, and explain why they work. I also give some tips of where I disagree with the book and some additional information that will be useful to you.\n*  [Issue 119] Book Review: \"Wicked Cool\" Java The book \"Wicked Cool Java\" contains a myriad of interesting libraries, both from the JDK and various open source projects. In this review, we look at two of these, the java.util.Scanner and javax.sql.WebRowSet classes.\n*  [Issue 125] Book Review: Java Concurrency in Practice We review Java Concurrency in Practice by Brian Goetz. Brian's book is the most readable on the topic of concurrency in Java, and deals with this difficult subject with a wonderful hands-on approach. It is interesting, useful, and relevant to the problems facing Java developers today.\n*  [Issue 140] Book Review: Java Generics and Collections Java Generics and Collections is the \"companion book\" to The Java Specialists' Newsletter. A well written book that explains generics really nicely, including some difficult concepts. In addition, they cover all the new collection classes up to Java 6 Mustang.\n*  [Issue 144] Book Review: Java Puzzlers Experienced Java programmers will love the Java Puzzlers book by Josh Bloch and Neal Gafter, both well known Java personalities. In this newsletter, we look at two of the puzzles as a teazer for the book.\n*  [Issue 163] Book Review: Effective Java 2nd Edition Joshua Bloch has at long last published an updated version of Effective Java. An essential guide for professional Java programmers who are interested in producing high quality code, this book is also very readable. In this newsletter we describe some of the nuggets found in the book.\n*  [Issue 185] Book Review: Java: The Good Parts In his latest book, Jim Waldo describes several Java features that he believes make Java \"good\". A nice easy read, and I even learned a few new things from it.\n*  [Issue 204] Book Review: The Well-Grounded Java Developer Ben Evans and Martijn Verburg explain to us in their new book what it takes to be a well-grounded Java developer. The book contains a section on the new Java 7 features and also vital techniques that we use for producing robust and performant systems.\n* \n\n* [Issue 097] Mapping Objects to XML Files using Java 5 Annotations\n* [Issue 099] Orientating Components Right to Left\n* [Issue 100] Java Programmers aren't Born\n* [Issue 102] Mangling Integers\n* [Issue 103] New for/in loop gymnastics\n* [Issue 114] Compile-time String Constant Quiz When we change libraries, we need to do a full recompile of our code, in case any constants were inlined by the compiler. Find out which constants are inlined in this latest newsletter.\n* [Issue 117] Reflectively Calling Inner Class Methods Sometimes frameworks use reflection to call methods. Depending how they find the correct method to call, we may end up with IllegalAccessExceptions. The naive approach of clazz.getMethod(name) is not correct when we send instances of non-public classes.\n* [Issue 121] How Deep is Your Hierarchy? Someone asked me yesterday what the maximum inheritance depth is in Java. I guessed a value of 65535, but for practical purposes, not more than 5. When I asked performance guru Kirk Pepperdine to estimate, he shot back with 63. In this newsletter, we look at the limitations in the JVM and examine some existing classes.\n* [Issue 122] Copying Files from the Internet Sometimes you need to download files using HTTP from a machine that you cannot run a browser on. In this simple Java program we show you how this is done. We include information of your progress for those who are impatient, and look at how the volatile keyword can be used.\n* [Issue 124] Copying Arrays Fast In this newsletter we look at the difference in performance between cloning and copying an array of bytes. Beware of the Microbenchmark! We also show how misleading such a test can be, but explain why the cloning is so much slower for small arrays.\n* [Issue 126] Proxy equals() When we make proxies that wrap objects, we have to remember to write an appropriate equals() method. Instead of comparing on object level, we need to either compare on interface level or use a workaround to achieve the comparisons on the object level, described in this newsletter.\n* [Issue 128] SuDoKu Madness In this Java Specialists' Newsletter, we look at a simple Java program that solves SuDoKu puzzles.\n* [Issue 131] Sending Emails from Java In this newsletter, we show how simple it is to send emails from Java. This should obviously not be used for sending unsolicited emails, but will nevertheless illustrate why we are flooded with SPAM.\n* [Issue 132] Thread Dump JSP in Java 5 Sometimes it is useful to have a look at what the threads are doing in a light weight fashion in order to discover tricky bugs and bottlenecks. Ideally this should not disturb the performance of the running system. In addition, it should be universally usable and cost nothing. Have a look at how we do it in this newsletter.\n* [Issue 135] Are you really Multi-Core? With Java 5, we can measure CPU cycles per thread. Here is a small program that runs several CPU intensive tasks in separate threads and then compares the elapsed time to the total CPU time of the threads. The factor should give you some indication of the CPU based acceleration that the multi cores are giving you.\n* [Issue 137] Creating Loggers DRY-ly A common idiom for logging is to create a logger in each class that is based on the class name. The name of the class is then duplicated in the class, both in the class definition and in the logger field definition, since the class is for some reason not available from a static context. Read how to solve that problem.\n* [Issue 139] Mustang ServiceLoader Mustang introduced a ServiceLoader than can be used to load JDBC drivers (amongst others) simply by including a jar file in your classpath. In this newsletter, we look at how we can use this mechanism to define and load our own services.\n* [Issue 142] Instrumentation Memory Counter Memory usage of Java objects has been a mystery for many years. In this newsletter, we use the new instrumentation API to predict more accurately how much memory an object uses. Based on earlier newsletters, but revised for Java 5 and 6.\n* [Issue 145] TristateCheckBox Revisited The Tristate Checkbox is widely used to represent an undetermined state of a check box. In this newsletter, we present a new version of this popular control, retrofitted to Java 5 and 6.\n* [Issue 152] The Law of the Corrupt Politician Corruption has a habit of creeping into system that do not have adequate controls over their threads. In this law, we look at how we can detect data races and some ideas to avoid and fix them.\n* [Issue 153] Timeout on Console Input In this newsletter, we look at how we can read from the console input stream, timing out if we do not get a response by some timeout.\n* [Issue 155] The Law of the Micromanager In good Dilbert style, we want to avoid having Pointy-Haired-Bosses (PHBs) in our code. Commonly called micromanagers, they can make a system work extremely inefficiently. My prediction is that in the next few years, as the number of cores increases per CPU, lock contention is going to be the biggest performance problem facing companies.\n* [Issue 156] The Law of Cretan Driving The Law of Cretan Driving looks at what happens when we keep on breaking the rules. Eventually, we might experience a lot of pain when we migrate to a new architecture or Java Virtual Machine. Even if we decide not to obey them, we need to know what they are. In this newsletter, we point you to some essential reading for every Java Specialist.\n* [Issue 159] The Law of Sudden Riches We all expect faster hardware to make our code execute faster and better. In this newsletter we examine why this is not always true. Sometimes the code breaks on faster servers or executes slower than on worse hardware.\n* [Issue 164] Why 0x61c88647? Prior to Java 1.4, ThreadLocals caused thread contention, rendering them useless for performant code. In the new design, each thread contains its own ThreadLocalMap, thus improving throughput. However, we still face the possibility of memory leaks due to values not being cleared out of the ThreadLocalMap with long running threads.\n* [Issue 167] Annotation Processing Tool In this newsletter we answer the question: \"How do we force all subclasses to contain a public no-args constructor?\" The Annotation Processing Tool allows us to check conditions like this at compile time, rather than only at runtime.\n* [Issue 168] The Delegator In this newsletter we show the reflection plumbing needed for writing a socket monitor that sniffs all the bytes being sent or received over all the Java sockets. The Delegator is used to invoke corresponding methods through some elegant guesswork.\n* [Issue 169] Monitoring Sockets In this newsletter, we show two approaches for listening to bytes on sockets. The first uses the Delegator from our previous newsletter, whereas the second uses AspectJ to intercept the call to Socket.getInput/OutputStream. We also write an MBean to publish this information in JConsole.\n* [Issue 170] Discovering Objects with Non-trivial Finalizers It is well known that implementing a non-trivial finalize() method can cause GC and performance issues, plus some subtle concurrency bugs. In this newsletter, we show how we can find all objects with a non-trivial finalize() method, even if they are not currently eligible for finalization.\n* [Issue 175] Creating Objects Without Calling Constructors De-Serialization creates objects without calling constructors. We can use the same mechanism to create objects at will, without ever calling their constructors.\n* [Issue 182] Remote Screenshots In this newsletter, we describe how we can generate remote screen shots as compressed, scaled JPGs to build a more efficient remote control mechanism.\n* [Issue 186] Iterator Quiz Most of the northern hemisphere is on holiday, so here is a quick quiz for those poor souls left behind manning the email desk. How can we prevent a ConcurrentModificationException in the iterator?\n* [Issue 189] Fun and Games with Java Lego NXT 2.0 It is almost Christmas time, which gives us an excuse to invest in all sorts of toys. I found that the most ridiculously priced ones are those that promise to have an added benefit besides fun. \"Educational\", \"Good for hand-eye coordination\", etc. In this Java newsletter we look at one of these \"toys\", the Lego Mindstorms NXT 2.0\n* [Issue 197] What is the Meaning of Life? In this newsletter we try to calculate the meaning of life, with surprising results.\n* [Issue 198] Pushing the Limits in Java's Random What is the largest double that could in theory be produced by Math.random()? In this newsletter, we look at ways to calculate this based on the 48-bit random generator available in standard Java. We also prove why in a single-threaded program, (int)(Random.nextDouble() + 1) can never be rounded up to 2.\n* [Issue 199] Hacking Java Surreptitiously Surreptitious: stealthy, furtive, well hidden, covert. In this newsletter we will show two Java puzzles written by Wouter Coekaerts that require a surreptitious solution. You cannot do anything to upset the security manager.\n* [Issue 205] How to Make Your Own Rules Rule Based Programming, a declarative programming paradigm, is based on logical patterns to select data and associate it with processing instructions. This is a more indirect method than the sequential execution steps of an imperative programming language.\n* [Issue 207] Final Parameters and Local Variables The trend of marking parameters and local variables as \"final\" does not really enhance your code, nor does it make it more secure.\n* [Issue 209] Unicode Redux (1 of 2) Unicode is the most important computing industry standard for representation and handling of text, no matter which of the world's writing systems is used. This newsletter discusses some selected features of Unicode, and how they might be dealt with in Java."
  },
  {
    "id": 21,
    "title": "Java Performance",
    "url": "/technology/java-performance.html",
    "content": "[TOC]\n\n\n\n# Memory\n\nAny Java object occupies at least 16 bytes, 12 out of which are occupied by a Java object header. Besides that, all Java objects are aligned by 8 bytes boundary. It means that, for example, an object containing 2 fields: int and byte will occupy not 17 (12 + 4 + 1), but 24 bytes (17 aligned by 8 bytes).\n\nEach Object reference occupies 4 bytes if the Java heap is under 32G and `XX:+UseCompressedOops` is turned on (it is turned on by default in the recent Oracle JVM versions). Otherwise, Object references occupy 8 bytes.\n\n* http://java-performance.info/memory-introspection-using-sun-misc-unsafe-and-reflection/\n* http://java-performance.info/overview-of-memory-saving-techniques-java/\n* [Top Java Memory Problems - Part 1](http://apmblog.compuware.com/2011/04/20/the-top-java-memory-problems-part-1/)\n* [Garbage Collection](http://docs.oracle.com/javase/6/docs/technotes/guides/management/jconsole.html#gddzt)\n\nUnderstand the implications of moving b/w 32-bit and 64-bit JVMs especially in terms of memory usage and allocation.\n\n## JVM Architecture\n\n{% img right /technology/jvm-architecture.png %}\n\n[Understanding JVM Internals](http://www.cubrid.org/blog/dev-platform/understanding-jvm-internals/)\n\n### Class loader subsystem\n\nResponsible for loading classes and interfaces\n\n### Execution engine\n\nResponsible for the execution of the instructions specified in the classes.\n\n### Native interface\n\ninteracts with the native libraries.\n\n### Runtime data areas\n\nMechanism to hold all kinds of data items such as instructions, object data, local variable data, return values & intermediate results. How runtime data are stored in the runtime data areas depends on the implementation of the JVM. Some implementation may enjoy the availability of memory and some others may not. The abstract nature of runtime data area specification allows the implementation of JVM in different machines easier. Some runtime data areas are shared among all the threads in the application, while some others are too specific to an active thread.\n\n#### Runtime data areas shared among all threads\n\n* **Method area**: holds the details of each class loaded by the class loader subsystem. \n* **Heap**: holds every object being created by the threads during execution\n\n#### Thread-specific runtime data areas\n\n* **Program counter register**: points to the next instruction to be executed.\n* **Java stack**: hold the state of each method (java method, not a native method) invocations for the thread such as the local variables, method arguments, return values, intermediate results. Each entry in the Java stack is called “stack frames“. Whenever a method is invoked a new stack frame is added to the stack and corresponding frame is removed when its execution is completed.\n* **Native method stack**: holds the state of each native method call in an implementation dependent way.\n\n## Garbage Collection\n\n{% img /technology/java-gc1.png %}\n\n{% img right /technology/java-gc2.png %}\n\n* Definition: process of looking at heap memory, identifying which objects are in use and which are not, and deleting the unused objects.\n* [Tuning GC](http://www.oracle.com/technetwork/java/gc-tuning-5-138395.html)\n* [How to tune GC](http://architects.dzone.com/articles/how-tune-java-garbage)\n\n\n### Phases\n\n* Mark phase - garbage collector identifies which pieces of memory are in use and which are not. Unused memory is cleaned up.\n* Normal deletion removes unreferenced objects leaving referenced objects and pointers to free space.\n* Compact phase - To further improve performance, in addition to deleting unreferenced objects, you can also compact the remaining referenced objects. By moving referenced object together, this makes new memory allocation much easier and faster.\n\n### JVM Generations\n\n* Young Generation\n  * all new objects are allocated and aged. \n  * causes a minor GC when this fills up.\n  * relatively quicker to collect than other generations\n  * Stop the World event: All minor GCs are \"Stop the World\" events which means all the app threads are stopped until the GC completes.\n* Old Generation\n  * stores long surviving objects. \n  * a threshold is set for young generation objects and when the age is met, the objects gets moved to old generation.\n  * causes a major GC when this fills up. Also, a \"Stop the World\" event.\n* Permanent Generation\n  * stores metadata required by the JVM to describe the classes and methods used in the app. Java SE library classes and method may be stored here.\n  * class may get collected/unloaded if they are no longer needed. Causes a Full GC\n\n### Generational GC Process\n\n* 1st minor GC\n  * New objects are allocated in eden space. Both survivor spaces start out empty.\n  * When eden space fills up, a minor GC is triggered.\n  * referenced objects are moved to 1st survivor space (S0)\n  * Eden space is cleared.\n* 2nd minor GC\n  * When eden space fills up, a minor GC is triggered.\n  * referenced objects are moved to 2nd survivor space (S1). \n  * In addition, objects from 1st survivor space (S0) have their age incremented and get moved to S1.\n  * Eden & S0 space is cleared.\n* 3rd minor GC\n  * When eden space fills up, a minor GC is triggered.\n  * referenced objects are moved to S0.  \n  * In addition, objects from S1 have their age incremented and get moved to S0.\n  * Plus, objects that reached the threshold age are moved to old generation.\n  * Eden & S1 space are cleared.\n* 1st major GC\n  * When tenure space fills up, a major GC is triggered. It cleans up and compacts that space.\n\n### Garbage Collection Algorithms\n\n* The Serial GC\n  * default collector for client style machines in Java SE 5 & 6.\n  * Both minor & major GCs are done serially using a single virtual CPU.\n  * Uses a mark-compact collection method.\n  * Option: `-XX:+UserSerialGC`.\n  * Usages: \n  * For longer apps with no low pause time requirements\n  * For apps which run on machine that hosts more JVMs than available processors.In such environment, GC of one app shouldn't affect all other JVMs.\n* The Parallel GC\n  * uses multiple threads  to perform the young generation GC.\n  * By default, on a host with 'N' CPUs, the parallel GC uses N GC threads in the collection. The number of GC threads can be controlled: `-XX:ParallelGCThreads=<num>`\n  * Parallel GC is also called a throughput collector.\n  * Usages:\n  * apps where high throughput is required and long pauses are accepted.\n  * 2 flavors of Parallel GC\n  * Option: `-XX:+UseParallelGC` - does multi-threaded young generation GC, single-threaded old generation collection and compaction.\n  * Option: `-XX:+UseParallelOldGC` - does multi-threaded young, multi-thread old generation collection and compaction. (HotSpot does compaction only in the old generation)\n* The Concurrent Mark Sweep (CMS) Collector\n  * Also called Concurrent Low Pause Collector.\n  * For younger generation, uses the same algorithm as Parallel GC\n  * For older generation, it minimizes the pauses by doing GC concurrently with the application threads.\n  * Does not copy or compact the live objects. If fragmentation becomes an issue, allocate larger heap.\n  * Option: `-XX:+UseConcMarkSweepGC`\n* The G1 collector\n  * Also called Garbage First Collector.\n  * Replacement for CMS collector.\n  * G1 is a parallel, concurrent, and incrementally compacting low-pause collector that has a different layout from other collectors above.\n  * More details here\n  * Option: `-XX:+UserG1GC`\n\n## Reference Types\n\n### WeakReference\n\nWeak reference objects, which do not prevent their referents from being made finalizable, finalized, and then reclaimed. Weak references are most often used to implement canonicalizing mappings.\n\nSuppose that the garbage collector determines at a certain point in time that an object is weakly reachable. At that time it will atomically clear all weak references to that object and all weak references to any other weakly-reachable objects from which that object is reachable through a chain of strong and soft references. At the same time it will declare all of the formerly weakly-reachable objects to be finalizable. At the same time or at some later time it will enqueue those newly-cleared weak references that are registered with reference queues.\n\n### SoftReference\n\nSoft reference objects, which are cleared at the discretion of the garbage collector in response to memory demand. Soft references are most often used to implement memory-sensitive caches.\n\nSuppose that the garbage collector determines at a certain point in time that an object is softly reachable. At that time it may choose to clear atomically all soft references to that object and all soft references to any other softly-reachable objects from which that object is reachable through a chain of strong references. At the same time or at some later time it will enqueue those newly-cleared soft references that are registered with reference queues.\n\nAll soft references to softly-reachable objects are guaranteed to have been cleared before the virtual machine throws an OutOfMemoryError. Otherwise no constraints are placed upon the time at which a soft reference will be cleared or the order in which a set of such references to different objects will be cleared. Virtual machine implementations are, however, encouraged to bias against clearing recently-created or recently-used soft references.\n\nDirect instances of this class may be used to implement simple caches; this class or derived subclasses may also be used in larger data structures to implement more sophisticated caches. As long as the referent of a soft reference is strongly reachable, that is, is actually in use, the soft reference will not be cleared. Thus a sophisticated cache can, for example, prevent its most recently used entries from being discarded by keeping strong referents to those entries, leaving the remaining entries to be discarded at the discretion of the garbage collector.\n\n### PhantomReference\n\nPhantom reference objects, which are enqueued after the collector determines that their referents may otherwise be reclaimed. Phantom references are most often used for scheduling pre-mortem cleanup actions in a more flexible way than is possible with the Java finalization mechanism.\n\nIf the garbage collector determines at a certain point in time that the referent of a phantom reference is phantom reachable, then at that time or at some later time it will enqueue the reference.\n\nIn order to ensure that a reclaimable object remains so, the referent of a phantom reference may not be retrieved: The get method of a phantom reference always returns null.\n\nUnlike soft and weak references, phantom references are not automatically cleared by the garbage collector as they are enqueued. An object that is reachable via phantom references will remain so until all such references are cleared or themselves become unreachable. Automatically cleared references Soft and weak references are automatically cleared by the collector before being added to the queues with which they are registered, if any. Therefore soft and weak references need not be registered with a queue in order to be useful, while phantom references do. An object that is reachable via phantom references will remain so until all such references are cleared or themselves become unreachable\n\n\n---\n\n# Performance Metrics\n\n* Responsiveness\n  * Refers to how quickly an app responds with a requested piece of data. e.g., how quickly a website returns a page.\n  * The focus is on responding in short period of time and long pause times are not acceptable. \n* Throughput\n  * focus is on maximizing the amount of work done by an app in a specific period of time. e.g., no. of transactions in a given time\n  * The focus is on high throughput over longer periods of time and long pause times are acceptable. Quick response is not a consideration.\n\n# Profiling\n\n* What is profiling?\n  * Measurement of program behavior\n  * Gathering of statistics about program execution\n* What can profiling tell you?\n  * How your program is spending time\n    * Which methods were called? How often?\n    * How long did those methods take to return?\n  * How your program is allocating space\n    * Which objects were created? How many?\n    * How much memory are those objects using?\n* Difference between Profiling & Benchmarking\n  * Profiling\n    * Aims to identify how an application executes\n    * Does not accurately measure execution time\n  * Benchmarking\n    * Aims to accurately measure execution time\n    * Does not identify ways to improve code\n* Types\n  * Sample-based: sample relevant statistics at intervals during execution\n    * Less overhead\n    * Less accuracy\n  * Instrumentation-based: modify application execution to generate detailed traces\n    * More overhead\n    * More accuracy\n\n# Benchmarking\n\n* https://code.google.com/p/caliper/wiki/JavaMicrobenchmarks\n* http://www.ibm.com/developerworks/java/library/j-benchmark1/index.html\n* https://code.google.com/p/javamelody/ - To capture SQL calls\n* [CodeHale](https://github.com/dropwizard/metrics) <span style=\"color:red\">TODO</span>\n\n* Benchmarking issues\n  * What are you trying to test?\n  * Optimization requires warm-up\n  * Timing API accuracy\n  * GC latency\n* The right way\n  * Simulate production (dataset, hardware, etc)\n  * Run for an extended period of time\n  * Warm up HotSpot™ with 10,000 iterations of benchmark code\n  * Calculate scores based on average execution time\n  * Identify outliers\n* Never micro-benchmark. E.g.,\n\n```java\nlong start = System.nanoTime();\nfor (int i = 0; i < count; i++)\nMath.sqrt(1234);\nlong stop = System.nanoTime();\nSystem.out.println(\"time \" + (stop - start)/1000);\n```\n\n# JVM Profiling Tools\n\n## HPROF\n\nCommand-line tool for heap and CPU profiling\nNot the most convenient or usable tool\nProcess to be profiled must be started with flags\nInterface is purely text-based\nA reasonable instructional tool\nHeap and CPU profiling\nSample- and instrumentation-based approaches\n\n```java HPROF (heap=sites)\njavac -J-agentlib:hprof=heap=sites Hello.java\n\nTRACE 301926: java.util.zip.ZipEntry.<init>(ZipEntry.java:101) java.util.zip.ZipFile+3.nextElement(ZipFile.java:417) com.sun.tools.javac.jvm.ClassReader.openArchive(ClassReader.java:1374) com.sun.tools.javac.jvm.ClassReader.list(ClassReader.java:1631)\nTRACE 301927: com.sun.tools.javac.util.List.<init>(List.java:42) com.sun.tools.javac.util.List.<init>(List.java:50) com.sun.tools.javac.util.ListBuffer.append(ListBuffer.java:94) com.sun.tools.javac.jvm.ClassReader.openArchive(ClassReader.java:1374)\n \nSITES BEGIN (ordered by live bytes) Wed Oct 4 13:13:42 2006\npercent live alloc'ed stack class rank self accum bytes objs bytes objs trace name\n1 44.13% 44.13% 1117360 13967 1117360 13967 301926 java.util.zip.ZipEntry\n2 8.83% 52.95% 223472 13967 223472 13967 301927 com.sun.tools.javac.util.List\n3 5.18% 58.13% 131088 1 131088 1 300996 byte[]\n4 5.18% 63.31% 131088 1 131088 1 300995 com.sun.tools.javac.util.Name[]\n```\n\n```java HPROF (cpu=samples)\njavac -J-agentlib:hprof=cpu=samples Hello.java\n\nCPU SAMPLES BEGIN (total = 462) Wed Oct 4 13:33:07 2006\nrank self accum count trace method\n1 49.57% 49.57% 229 300187 java.util.zip.ZipFile.getNextEntry\n2 6.93% 56.49% 32 300190 java.util.zip.ZipEntry.initFields\n3 4.76% 61.26% 22 300122 java.lang.ClassLoader.defineClass2\n4 2.81% 64.07% 13 300188 java.util.zip.ZipFile.freeEntry\n5 1.95% 66.02% 9 300129 java.util.Vector.addElement\n6 1.73% 67.75% 8 300124 java.util.zip.ZipFile.getEntry\n7 1.52% 69.26% 7 300125 java.lang.ClassLoader.findBootstrapClass\n```\n\n```java HPROF (cpu=times)\njavac -J-agentlib:hprof=cpu=times Hello.java\nCPU TIME (ms) BEGIN (total = 2082665289) Wed oct 4 13:43:42 2006\nrank self accum count trace method\n1 3.70% 3.70% 1 311243 com.sun.tools.javac.Main.compile\n2 3.64% 7.34% 1 311242 com.sun.tools.javac.main.Main.compile\n3 3.64% 10.97% 1 311241 com.sun.tools.javac.main.Main.compile\n4 3.11% 14.08% 1 311173 com.sun.tools.javac.main.JavaCompiler.compile\n5 2.54% 16.62% 8 306183 com.sun.tools.javac.jvm.ClassReader.listAll\n6 2.53% 19.15% 36 306182 com.sun.tools.javac.jvm.ClassReader.list\n7 2.03% 21.18% 1 307195 com.sun.tools.javac.comp.Enter.main\n```\n\n## VisualVM\n\n* http://java.dzone.com/announcements/visualvm-12-great-java\n* JVM diagnostics\n* CPU and heap profiling\n* JMX console (with MBeans plugin)\n* Integrates a number of tools for JVM diagnostics\n  * jmap, jhat, jstack, jstat, and jinfo\n  * JConsole\n  * Netbeans profiler (JFluid)\n* Requires Java 6\n  * Included with Java 6 Update 7+\n  * Available as a separate download for lower versions\n* Runs locally or remotely (except profiler)\n\n## MAT\n\n* Detailed heap analysis\n* Memory leak identification\n* Memory usage optimization\n* Eclipse Memory Analyzer\n  * Integrated into Eclipse 3.5 Galileo\n  * Plugin for earlier versions of Eclipse\n  * Standalone RCP app\n* Good performance characteristics\n  * Loads heap dump files incrementally\n  * Generated indexes\n* Feature-rich (if not intuitive) user interface\n  * Well, it is an Eclipse application after all\n  * Multitude of pre-canned reports\n\n## BTrace\n\n* Targeted, programmable profiling\n* Live tracing and debugging\n* Dynamic tracing tool for Java\n  * Declare probe points: locations at or events on which to trace\n  * Program trace actions to execute when a probe fires\n* Key differentiators:\n  * Targeted nature incurs minimal performance overhead\n  * Programmability enables correlation of metrics to application state and method parameters\n  * Restricted programming model “guarantees” safety\n* BTrace scripts cannot:\n  * Create objects or arrays\n  * Throw or catch exceptions\n  * Call arbitrary static or instance methods\n  * Assign to static or instance variables of the target program\n  * Contain synchronized blocks or methods\n  * Loop (for, while, or do…while)\n  * Assert\n  * Extend arbitrary classes or implement arbitrary interfaces\n  * Have outer, inner, nested, or local classes\n\nApache JMeter - http://jmeter.apache.org/\n\n\n## Tools shipped with Java\n\n* jmap\n  * Prints heap memory details of a given process, core, or remote debug server\n  * Usage:\n  * `jmap –histo:live <pid>`\n  * `jmap –dump:live,format=b <pid>`\n  * TIP: prefer JMX-triggered heap dumps\n  * JConsole or VisualVM with MBeans plugin\n  * Safer than jmap\n* jhat\n  * Parses heap dumps and launches server for heap browsing and query\n  * Usage: `jhat <binary heap dump file>`\n  * TIP: prefer Eclipse MAT for heap analysis\n  * Vastly better performance\n  * Vastly better usability\n* jstack\n  * Prints stack traces of executing threads for a given process, core file, or remote debug server\n  * Usage: `jstack [-l] <pid>`\n  * The [-l] option (Java 6+) includes information on java.util.concurrent locks in addition to monitors\n  * TIP: on *nix systems, prefer kill –QUIT (or kill –3)\n  * Safer than jstack\n  * Multiple calls will quickly provide insight into execution\n* jstat\n  * Displays performance statistics for the targeted process\n  * Class loader\n  * HotSpot™ compiler\n  * Garbage collector\n  * Usage: `jstat [output options] <pid> [interval]`\n  * TIP: a reasonable way to view individual statistics…\n  * …if the command line is all that’s available\n  * Otherwise, JConsole and VisualVM provide far more context\n* jps\n  * Lists all java processes on the given server\n  * Usage: `jps [<hostname>]`\n* jinfo\n  * Prints system properties and JVM startup options for the given process, core, or remote debug server\n  * Usage: `jinfo <pid>`\n\n## HP JTune\n\n\n## HP JMeter\n\n# Bibliography\n\n* Books\n  * Java - The Good Parts\n  * Inside the Java Virtual Machine - Bill Venners\n* http://www.codinghorror.com/blog/2008/12/hardware-is-cheap-programmers-are-expensive.html\n* http://www.infoq.com/articles/9_Fallacies_Java_Performance?utm_source=infoq&utm_medium=popular_links_homepage\n* http://www.javacodegeeks.com/2012/09/visualvm-monitoring-remote-jvm-over-ssh.html\n* http://www.javacodegeeks.com/resources#Profilers\n* http://blog.javabenchmark.org/2013/03/write-your-own-profiler-with-jee6.html\n* http://hype-free.blogspot.com/2010/01/choosing-java-profiler.html\n* http://psy-lob-saw.blogspot.com/2013/04/writing-java-micro-benchmarks-with-jmh.html\n* [The Value and Perils of Performance Benchmarks in the Wake of TechEmpower’s Web Framework Benchmark](http://theholyjava.wordpress.com/2013/04/01/the-value-and-perils-of-performance-benchmarks-in-the-wake-of-techempowers-web-framework-benchmark/)\n* Programmers Need To Learn Statistics Or I Will Kill Them All\n* 5 things you didn't know about Java Performance - [Part 1](http://www.ibm.com/developerworks/java/library/j-5things7/index.html), [Part 2](http://www.ibm.com/developerworks/java/library/j-5things8/index.html)\n"
  },
  {
    "id": 22,
    "title": "Java Testing",
    "url": "/technology/java-testing.html",
    "content": "[TOC]\n\n# Unit Testing\n\n## Unit Testing Concepts\n\n* Characterization test - http://www.artima.com/weblogs/viewpost.jsp?thread=198296\n* Characterization Testing static methods using different techniques - http://martinfowler.com/articles/modernMockingTools.html\n\n## JUnit\n\n### Method Level Annotations\n\n* `@BeforeClass` - Marks the method to execute before the test case class begins\n* `@AfterClass` - Marks the method to execute after the test case class completes\n* `@Before` - Marks the method to execute before the test case begins\n* `@After` - Marks the method to execute after the test case completes\n* `@Test` - Marks the method as a test case\n* `@Test(exception = NullPointerException.class)` - Marks the method to expect the given exception\n* `@Test(timeout=1)` - Marks the maximum time in milliseconds the test case can take to run\n* `@Ignore(\"Comment\")` - Mark a method to ignore from testing\n\n### Class Level Annotations\n\n* Runner - is a class which runs tests. JUnit provides a bunch of runners out-of-the-box:\n  * JUnit4 - starts the test case as a Junit4 test case\n  * Parameterized - runs the same test method with different parameters\n  * Suite - executes all the @Test annotated methods in a class\n* `@RunWith(runner.class)` - Custom runner classes can be provided with this annotation\n* `@SuiteClasses(value={foo1.class, foo2.class})`\n  * Suite is a container to combine more than one test cases for grouping and invocation\n  * When there are 2 test methods in a class, JUnit4 uses a Suite by default.\n  * Runner invokes the Suite. Ordering or execution is up to the Suite implementation.\n\n### Parameterized Tests \n\n* `Parameterized.class` is a Runner class provided by JUnit4\n* Same test method is tested with different parameters returned by the method defined by `@Parameters`.\n* Signature of parmeters method should be `@Parameters public static Collection`. Collection elements should be arrays of same length\n* Variables used in the test method should be defined as instance variables in the test class and there should be public constructor setting all these instance variables.\n\n``` java Example\n@RunWith(value = Parameterized.class)\npublic class ParameterizedTest {\n  private double expected, valueOne, valueTwo;\n\n\n  @Parameterized.Parameters\n  public static Collection<Integer[]> getTestParameters() {\n    return Arrays.asList(new Integer[][]{\n      {2, 1, 1}, //expected, valueOne, valueTwo\n      {3, 2, 1}, //expected, valueOne, valueTwo\n      {4, 3, 1}, //expected, valueOne, valueTwo\n    });\n  }\n\n  public ParameterizedTest(double expected, double valueOne, double valueTwo) {\n    this.expected = expected; this.valueOne = valueOne; this.valueTwo = valueTwo;\n  }\n\n  @Test\n  public void sum() {\n    Assert.assertEquals(expected, new Calculator().add(valueOne, valueTwo), 0);\n  }\n\n  private class Calculator{\n    double add(double i, double j){ return i+j; }\n  }\n}\n```\n\nParameterized.class is a Runner class provided by JUnit4\nSame test method is tested with different parameters returned by the method defined by@Parameters.\nSignature of parmeters method should be@Parameters public static Collection. Collection elements should be arrays of same length\nVariables used in the test method should be defined as instance variables in the test class and there should be public constructor setting all these instance variables.\n\n## Mockito\n\n* On mock object, all methods that return value returns null by default\n* Mockito follows `Arrange - Act - Assert` unlike other mock frameworks which follow `Expect-Run-Verify` pattern.\n* What is not possible in Mockito compared to others?\n  * Testing static methods (check PowerMockito)\n  * Mocking final classes\n\n### Examples\n\n``` java Example of Verify\nimport org.junit.Test;\nimport java.util.List;\nimport static org.junit.Assert.*\nimport static org.mockito.Mockito.*;\n \npublic class MockitoTest {\n    @Test public void testVerify() {\n        List<String> mockedList = mock(List.class);\n        mockedList.add(\"once\");\n        mockedList.add(\"twice\");\n        mockedList.add(\"twice\");\n        mockedList.add(\"three times\");\n        mockedList.add(\"three times\");\n        mockedList.add(\"three times\");\n \n        //following two verifications work exactly the same - times(1) is used by default\n        verify(mockedList).add(\"once\");\n        verify(mockedList, times(1)).add(\"once\");\n \n        //exact number of invocations verification\n        verify(mockedList, times(2)).add(\"twice\");\n        verify(mockedList, times(3)).add(\"three times\");\n \n        //verification using never(). never() is an alias to times(0)\n        verify(mockedList, never()).add(\"never happened\");\n \n        //verification using atLeast()/atMost()\n        verify(mockedList, atLeastOnce()).add(\"three times\");\n        verify(mockedList, atLeast(2)).add(\"three times\");\n        verify(mockedList, atMost(5)).add(\"three times\");\n    }\n}\n```\n\n``` java Example of Stubbing\n@Test public void stubbing() {\n        //Arrange - Act - Assert Pattern\n        Iterator i = mock(Iterator.class);\n        //when next() method is called, return \"Hello\" first and on 2nd invocation return \"World\"\n        when(i.next()).thenReturn(\"Hello\").thenReturn(\"World\"); //Arrange\n        String result = i.next() + \" \" + i.next(); //Act\n        assertThat(\"Hello World\", is(result)); //Assert\n    }\n```\n\n``` java Example of Stubbing void methods\n@Test(expected = IOException.class)\n    public void voidMethodCalls() throws IOException {\n        OutputStream stream = mock(OutputStream.class);\n        doThrow(new IOException()).when(stream).close(); //when close() method is called throw exception\n        stream.close();\n    }\n}\n```\n\n``` java Example of Argument Matchers\n@Test(expected = NullPointerException.class)\n    public void throwException() {\n        Comparable c = mock(Comparable.class);\n        when(c.compareTo(\"Test\")).thenReturn(1);\n        when(c.compareTo(null)).thenThrow(new NullPointerException(\"Null....\"));//when input is null, throw NPE\n        assertThat(1, is(c.compareTo(\"Test\")));\n        assertThat(0, is(c.compareTo(\"Something\")));\n        assertThat(0, is(c.compareTo(null))); //throws NPE\n \n        when(c.compareTo(anyString())).thenReturn(100);//regardless of the input, return 100. anyString() is called Argument Matchers\n        assertThat(100, is(c.compareTo(\"Test\")));\n    }\n}\n```\n\nTo learn more about Argument Matchers: http://docs.mockito.googlecode.com/hg/latest/org/mockito/Matchers.html\n\n# Hamcrest\n\nHamcrest is a Google library shipped with JUnit 4.x to make the assertions simpler.\n\n| Method | Description |\n| ------ | ----------- | \n| `anything` | Matches absolutely anything. Useful in some cases where you want to make the assert statement more readable. | \n| `is` | Is used only to improve the readability of your statements. | \n| `allOf` | Checks to see if all contained matchers match (just like the && operator). | \n| `anyOf` | Checks to see if any of the contained matchers match (like the || operator). | \n| `not` | Traverses the meaning of the contained matchers (just like the ! operator in Java). | \n| `instanceOf,isCompatibleType` | Match whether objects are of compatible type (are instances of one another). | \n| `sameInstance` | Tests object identity.\n| `notNullValue,nullValue` | Tests for null values (or non-null values).\n| `hasProperty` | Tests whether a JavaBean has a certain property.\n| `hasEntry,hasKey,hasValue` | Tests whether a given Map has a given entry, key, or value.\n| `hasItem,hasItems` | Tests a given collection for the presence of an item or items.\n| `closeTo,greaterThan,greaterThanOrEqual,lessThan,lessThanOrEqual` | Test whether given numbers are close to, greater than, greater than or equal to, less than, or less than or equal to a given value.\n| `equalToIgnoringCase` | Tests whether a given string equals another one, ignoring the case.\n| `equalToIgnoringWhiteSpace` | Tests whether a given string equals another one, by ignoring the white spaces.\n| `containsString,endsWith,startWith` | Test whether the given string contains, starts with, or ends with a certain string\n\n``` java Examples of Hamcrest functions\nimport org.junit.Test;\nimport java.util.Arrays;\nimport java.util.List;\nimport static org.hamcrest.CoreMatchers.*;\nimport static org.junit.Assert.assertThat;\n\npublic class HamcrestTest {\n    @Test public void simpleAssertions(){\n        List<Integer> nums = Arrays.asList(1, 2, 3, 4, 5);\n        assertThat(nums.size(), is(5)); //Assert equals\n        assertThat(nums.size(), is(equalTo(5)));//Assert equals\n        assertThat(nums, allOf(notNullValue(), instanceOf(List.class)));//AND operation\n        assertThat(nums, anyOf(nullValue(), instanceOf(List.class)));//OR operation\n        assertThat(nums, not(equalTo(Arrays.asList(1))));//NOT operation\n    }\n}\n```\n\n# Spock Framework\n\nSpock is a testing and specification framework for Java and Groovy applications.\n\n* Specification - compare to TestCase/GroovyTestCase. Instructs JUnit to run Sputnik (custom JUnitRunner)\n* Every member field in test class is reinitialized for every test unless marked as @Shared.\n* Feature - compare to test method or @Test\n \n``` groovy Fixture Methods\n def setup(){} //run before every feature method\n def cleanup(){} //run after every feature method\n def setupSpec(){} //run before the first feature method\n def cleanupSpec(){} //run after the first feature method\n```\n\n``` groovy 2 ways of setup using DSL keywords- setup or given\nsetup: OR given: \"setup and init of...\" //must be first and only. label is optional\ndef stack = new Stack()\ndef elem = \"push me\"\n\nwhen/then blocks\nwhen: //stimulus\nstack.push(elem)\n\nthen: //response\n!stack.empty //leverages Groovy truthy feature. Implicitly asserts the collection is not null and not empty\nstack.size() == 1\nstack.peek() == elem\n```\n\n``` groovy Example 1: checking for an exception thrown\nwhen:\nstack.pop()\n\nthen:\nthrown(EmptyStackException)\nstack.empty\n```\n\n``` groovy Example 2: ensuring no exception is thrown\nwhen: \nstack.pop()\n \n then:\n EmptyStackException e = thrown()\n e.cause == null\n ```\n\n``` groovy Example 3:\n when: \n stack.pop()\n \n then:\n notThrown(EmptyStackException)\n```\n\n# Bibliography\n\n* xUnit Patterns\n* BDD () - Behavior Driven Development - http://jdave.org/\n* Functional Testing tool - Apache JMeter - http://jmeter.apache.org/\n* http://tedyoung.me/2011/01/23/junit-runtime-tests-custom-runners/\n* http://stackoverflow.com/questions/13489388/how-junit-rule-works\n* http://www.mkyong.com/unittest/junit-4-tutorial-6-parameterized-test/\n* http://stackoverflow.com/questions/4055022/mark-unit-test-as-an-expected-failure-in-junit/8092927#8092927\n* http://java.dzone.com/articles/dry-use-junit-rule-instead"
  },
  {
    "id": 23,
    "title": "Java Web Technologies",
    "url": "/technology/java-web.html",
    "content": "[TOC]\n\n# Servlets\n\n{% img right /technology/servlet-class-diagram.png %}\n\n## Servlet Life Cycle\n\n* Load the servlet class\n* `GenericServlet.init()` - invoked only once in servlet's lifecycle\n* `GenericServlet.service()` - for each request, this method is invoked in a separate thread\n* `GenericServlet.destroy()` - invoked only once in servlet's lifecycle\n\n## Servlet Key/Value Stores\n\n### ServletConfig\n\n* used to access deploy-time configurations from web.xml.\n* 1 per servlet.\n* Key and value should be strings\n* How to access: `this.getServletConfig();`\n\n``` xml Servlet Config\n<web-app>\n   <servlet>\n       ...\n       <init-param>\n          <param-name>key</param-name>\n          <param-value>value</param-value>\n       </init-param>\n   </servlet>\n</web-app>\n```\n\n### ServletContext\n\n* used to access deploy-time configurations from web.xml\n* 1 per web app\n* Key and value should be strings\n* How to access: `this.getServletConfig().getServletContext();`\n\n``` xml Servlet Context\n<web-app>\n   <servlet>\n       ...\n   </servlet>\n\n   <context-param>\n      <param-name>key</param-name>\n      <param-value>value</param-value>\n   </context-param>\n</web-app>\n```\n\n### HttpRequest\t \n\n* Parameters (thread-safe)\n  * set by client request.\n  * servlet can set new parameters\n* Attributes (thread-safe)\n  * used by servlet to set additional key-value pairs before forwarding the request.\n\n### HttpSession\n\n* Parameters\n* Attributes\n* sessionId is set by the servlet on cookie in a response\n\n## Listeners\n\n* `ServletContextListener` - callback interface that is invoked after the ServletContext is initialized.\n\n``` xml\n<listener>\n     <listener-class>com.test.Foo<listener-class>\n</listener>\n```\n\n* `ServletContextAttributeListener`\n* `ServletRequestAttributeListener`\n* `HttpSessionListener`\n* `HttpSessionBindingListener`\n* `HttpSessionActivationListener`\n\n## Redirect Vs Forwarding / Request Dispatch\n\n### Request Redirect\t \n\n* client requests url1 to server -> server redirects to a new url -> request makes a round trip back to client -> browser sends a new request to the new url\n* url in the client browser is changed to the new url\n* redirect is visible to the client\n\n###  Request Forwarding / Request Dispatch\n\n* client request url1 to server -> server redirects to a new url directly without round trip\n* url in the client browser is not changed\n* redirect is not visible to the client\n\n## Deployment Descriptor (web.xml)\n\n3 names of a servlet\n\n* File path name: path to an actual class file. e.g., /classes/registration/SignUpServlet.class\n* Deployment name: a logical internal name that doesn't have to be the same as the class name. e.g., EnrollServlet\n* Public URL name: the name the client knows about from HTML link.\n\n``` xml web.xml\n <servlet>\n <!-- end user nevers sees the 2 names below -->\n <servlet-name>Internal Name</servlet-name>\n <servlet-class>com.mfi.Servlet1</servlet-class>\n <!-- loads and initializes the servlet when the server starts. If multiple servlets are configured, they are loaded as per the number priority number provided -->\n <load-on-startup>1</load-on-startup>\n </servlet>\n\n <servlet-mapping>\n <servlet-name>Internal Name</servlet-name>\n <!-- this is the name the client sees.-->\n <url-pattern>/public1</url-pattern>\n </servlet-mapping>\n```\n\n## Servlet chaining / inter-servlet communication \n\nCalling another servlet from inside a servlet. Achieved by using RequestDispatcher.forward(req, res) and RequestDispatcher.include(req, res). \n\n# JSP\n\nJSP\n\n* Scriplets - `<% %>`. `<% out.println(\"Hello\"); %>`\n* Expressions - `<%= %>` - no semicolons needed. `<%= Counter.getCount()%>`\n* Comments\n  * `<%-- JSP comment: visible only to developer --%>`\n  * `<!-- HTML comment: visible to client -->`\n* Declarations - `<%! %>` - to declare methods and instance variables \n* Directives\n  * Directives give special instructions to the container on page translation time.\n  * Types\n    * page directives - `<%@ page import=\"java.util.Date, java.util.List\" %>`\n    * include directives - To include external JSP/HTML files into another JSP. `<%@ include file=\"x.html\" %>`\n    * taglib directives - to include custom tag libraries. `<%@ taglib tagdir=\"/WEB-INF/lib\" prefix=\"c\" %>`\n* Implicit Objects\n  * `out - JspWriter`\n  * `request - HttpServletRequest`\n  * `response - HttpServletResponse`\n  * `session - HttpSession`\n  * `application - ServletContext`\n  * `config - ServletConfig`\n  * `exception - JspException`\n  * `pageContext - PageContext`\n  * `page - Object`\n* Scopes\n  * `app` - application\n  * `request` - request\n  * `session` - session\n  * `page` - pageContext\n\n## EL - Expression Language\n\n* EL was introduced non-Java web developers\n* `${applicationScope.mail}` is equivalent to `<%= application.getAttribute(\"mail\")%>`\n* To enable or disable scripting. `<scripting-invalid>true/false</scripting-invalid>` in web.xml\n* To enable or disable EL. `<el-ignored>true/false</el-ignored>` in web.xml or using page directive `<%@ page isELIgnore=\"true\" %>`\n\n## Lifecycle methods of JSP\n\n* JSP page (extends) `javax.servlet.jsp.HttpJspPage` extends `javax.servlet.jsp.JspPage` extends `javax.servlet.Servlet`\n* The generated servlet class thus implements all the methods of these three interfaces. \n* The `JspPage` interface declares only two methods - `jspInit()` and `jspDestroy()` that must be implemented by all JSP pages regardless of the client-server protocol. However the JSP specification has provided the `HttpJspPage` interface specifically for the JSP pages serving HTTP requests. This interface declares one method `_jspService()`. \n* The `jspInit()` - The container calls the jspInit() to initialize the servlet instance.It is called before any other method, and is called only once for a servlet instance. \n* The `_jspservice()` - The container calls the _jspservice() for each request, passing it the request and the response objects. Should not be overridden.\n* The `jspDestroy()` - The container calls this when it decides take the instance out of service. It is the last method called n the servlet instance.\n\n## Custom Tags\n\nInclude Action Element - <jsp:include page=\"x.html\" />\n\nDifference between include directive and include custom tag?\n\n### Include directive \n\n* At JSP page translation time, the content of the file given in the include directive is ‘pasted’ as it is, in the place where the JSP include directive is used. Then the source JSP page is converted into a java servlet class. The included file can be a static resource or a JSP page. Generally JSP include directive is used to include header banners and footers. The JSP compilation procedure is that, the source JSP page gets compiled only if that page has changed. If there is a change in the included JSP file, the source JSP file will not be compiled and therefore the modification will not get reflected in the output.\n* Only one servlet is executed at run time. \n* Scriptlet variables declared in the parent page can be accessed in the included page (remember, they are the same page). \n* The included page does not need to able to be compiled as a standalone JSP. It can be a code fragment or plain text. The included page will never be compiled as a standalone. The included page can also have any extension, though .jspf has become a conventionally used extension. \n* One drawback on older containers is that changes to the include pages may not take effect until the parent page is updated. Recent versions of Tomcat will check the include pages for updates and force a recompile of the parent if they're updated.\n\n### Include Action\n\n* The jsp:include action element is like a function call. At runtime, the included file will be ‘executed’ and the result content will be included with the soure JSP page. When the included JSP page is called, both the request and response objects are passed as parameters. If there is a need to pass additional parameters, then jsp:param element can be used. If the resource is static, its content is inserted into the calling JSP file, since there is no processing needed.\n* Each included page is executed as a separate servlet at run time. \n* Pages can conditionally be included at run time. This is often useful for templating frameworks that build pages out of includes. The parent page can determine which page, if any, to include according to some run-time condition. \n* The values of scriptlet variables need to be explicitly passed to the include page.\n* The included page must be able to be run on its own. Request.getSession() request.getSession(true) only creates a session if one does not exist. request.getSession(false) retrieves a session only if it already exists. \n\n## Custom tag libs\n\n* Your tag class should implement `Tag` interface or extend from `TagSupport` or `BodyTagSupport` class.\n* Implement `doStartTag()` method - If your tag does not have a body, then this method should return SKIP_BODY constant. Otherwise return EVAL_BODY_INCLUDE which in turn would call 'doEndTag()' method.\n* To make use of what's inside the body of the tag, implement `doEndTag()`. After processing the body content, if you want to continue processing the rest of the page, return EVAL_PAGE, else SKIP_PAGE.\n* If your tag has an attribute 'attr1', then add the method `setAttr1()` to your tag class.\n* To evaluate the contents of the body, your class should extend from `BodyTagSupport` class, and override 'doAfterBody()' method. This method normally returns SKIP_BODY meaning that no further body processing should be performed, else it returns EVAL_BODY_TAG to evaluate and handle the body again.\n\n## Filters\n\n* Filter - can intercept and process requests before and after servlet execution. e.g., of **Intercepting Filter pattern**. Filters can be chained.\n* Request Filters can \n  * perform security checks\n  * reformat request headers or bodies\n  * audit or log requests\n* Response Filters can\n  * compress the response stream\n  * append or alter the response\n  * create a different response altogether\n\n``` java Filter interface\npublic interface Filter {\n   public void init(FilterConfig config);\n   public void doFilter(ServletRequest req, ServletResponse resp, FilterChain chain) throws ServletException, IOException;\n   public void destroy();\n}\n```\n\n``` xml Filter settings in web.xml\n<filter>\n   <filter-name>FilterName</filter-name>\n   <filter-class>com.test.Foo<filter-class>\n   <init-param>\n      <param-name>name</param-name>\n      <param-value>value</param-value>\n   <init-param>\n</filter>\n\n<filter-mapping>\n   <filter-name>FilterName</filter-name>\n   <servlet-name>YourServletName<servlet-name> or <url-mapping>/*.do</url-mapping>\n</filter-mapping>\n```\n\n* Starting Servlet 2.4 version, filters can be applied to request dispatchers - forwards and redirects.\n\n## Wrappers\n\nWrapper classes in Servlet API\n\n* ServletRequestWrapper\n* HttpServletRequestWrapper\n* ServletResponseWrapper\n* HttpServletResponseWrapper\n\nWhenever you want to create a custom request or response object, just subclass one of the convenience request or response \"wrapper\" classes\n\n# Spring MVC\n\n{% img right /technology/mvc-model.png %}\n\n## MVC Model 1 & 2\n\n* Model 1 works well for GUI apps. Model 2 works well for web apps.\n* Front Controller is the extra thing in Model 2. \n* --(incoming request)--> Front Controller --(delegates request)--> Controller --(handles request, creates model)--> Front Controller --(model)--> View Template --(renders response, returns control)--> Front Controller --(returns response)-->\n* Front Controller is implemented as \n  * `javax.servlet.Servlet`\n  * `ActionServlet` in Struts\n  * `FacesServlet` in JSF\n  * `DispatcherServlet` in Spring MVC\n\n## Web MVC Application Layer\n\nLayering leads to separation of concerns, easy testability, clean architecture.\n\n### User Interface (Presentation)\n\n* presents the application to the user rendering the response as requested by the client. e.g., HTML, XML, PDF, etc. \n* In Spring it is represented by a generic interface 'View' and it has no dependencies on a particular view technology like JSP, Velocity, Tiles, etc.\n\n### Web (Presentation)\n* Thin layer; no business logic; \n* In Spring it is represented by 'Controller' interface or classes with @Controller annotation.\n* Responsible for (1) page navigation logic via Spring Web Flow, etc. (2) integrating service layer and HTTP.\n* Converts HTTP request into service layer calls, and then transforms result from server into response for the user interface.\n* Contains cookies, HTTP headers, HTTP sessions; responsible to manage these consistently and transparently.\n* 2 types of web layer implementations:\n  * (a) request-repsonse frameworks. e.g., Struts and Spring MVC. They operate on ServletRequest and ServletResponse objects and is not hiddent from the users.\n  * (b) component-based frameworks. e.g., JSF, Tapestry. Hides the Servlet API from the user and offers a component-based programming model.\n\n### Service layer\n\n* only business logic (transactional boundary, security, etc.). \n* No persistence or presentation logic. \n* Coarse-API layer - funciton should represent a single unit of work that either succeeds of fails. User can user different clients (web, web service, desktop app, JMS) but the business logic is same.\n* Services should be stateless and a good practice to keep it Singleton.\n* Keeping the service layer clean also allows us to reuse the same services for different channels. For example, it enables us to add a web service or JMS-driven solution\n\n### Data Access\n\nInterface-based layer abstracts persistence framework (JDO, JDBC, JPA, etc.) No business logic.\n\n### Domain \n\n(cuts across all layers) - Domain class names are nouns. Contains both state and behavior. In anemic domain model, it holds only state and no behavior.\n\nCommunication should be top-to-bottom except Domain layer. Data access shouldn't access Service layer. Circular dependencies is a sign of bad design. A rule of thumb is that, if a layer has too many dependencies with other layers, we might want to introduce another layer that incorporates all the dependencies. On the other hand, if we see a single layer throughout different layers, we might want to reconsider this layer and make it an aspect of the application (Spring AOP). \n\n## Definitions\n\n### ModelMap \n\n### View \n\n* Out-of-the-box - JSP, JSTL, Tiles, Velocity, FreeMaker, etc.\n* Special - redirect: and forward:\n\n### ModelAndView \n\nAn aggregator/container class which holds both a ModelMap and a View instance.\n\n### Controller\n\n* RequestMapping is defined both at class-level and method-level\n* Types of mapping requests\n  * by path - `@RequestMapping(\"/welcome\")`\n  * by HTTP method - `@RequestMapping(\"/welcome\", method=RequestMethod.GET)`\n  * by presence/value of query parameter - `@RequestMapping(\"find=ByMake\", \"form\")`\n  * by presence/value of request header  - `@RequestMapping(\"/welcome\", header=\"accept=text/*\")`\n* Types of controller method return types (http://docs.spring.io/spring/docs/3.0.x/spring-framework-reference/html/mvc.html)\n  * void\n  * String \n  * logical view name (\"car\") \n  * physical view name (`/WEB-INF/jsp/car.jsp`)\n  * special view names (`redirect:/cars/7`)\n  * ModelAndView\n  * Model / Map / ModelMap\n  * View\n  * `@ResponseBody` / `@ModelAttribute`\n\n``` java Sample Controller \npublic class ItemController implements Controller {\n...\n}\n```\n\n``` java Sample Controller - Declarative Style\n@Controller\n public class ItemController {\n\n     @RequestMapping(value=\"viewItem.htm\", method=RequestMethod.GET)\n     public Item viewItem(@RequestParam Long id){\n         return itemservice.get(id);\n     }   \n}\n``` \n\n* Additional annotations at controller level\n  * `@ModelAttribute`\n    * method parameter level - maps a model attribute to the specific method parameter\n    * method level - provides the reference data to the model\n  * `@SessionAttributes` - class level: list the names or types of model attributes which should be stroed in the session.\n  * `@RequestHeader` - method parameter level - maps request header parameters to method parameters\n  * `@CookieValue` - method parameter level - gets the JSESSIONID of the cookie\n  * `@RequestBody` / `@ResponseBody`\n\n#### FormController\n\n* Override onSubmit() method to provide custom handling function\n* Override formBackingObject() method to provide default values when the form is first rendered.\n\n``` xml \n<bean name=\"/foo.htm\" class=\"com.FooFormController\">\n    <property name=\"commandName\" value=\"...\"/>\n    <property name=\"commandClass\" value=\"...\"/>\n    <property name=\"validator\" value=\"com.FooValidator\"/>\n    <property name=\"successView\" value=\"baz.html\"/>\n</bean>\n```\n\n``` java Form Controller\nclass FooFormController extends SimpleFormController{\n    void onSubmit(Object obj){\n        return new ModelAndView(new RedirectView(getSuccessView())));\n    }\n}\n\nclass FooValidator implements Validator{\n}\n```\n\n#### MultiActionController\n\n* allows multiple request types to be handled by the same class. For example, when mapped *Foo.htm to FooController which extends MultiActionController. \n* Based on the request type, different methods on implementing class will be invoked; which method to invoke is decided by MethodNameResolver implementation which can be injected.\n* `InternalPathMethodNameResolver` - maps file name in url to method name. e.g, requesting addFoo.htm and deleteFoo.htm would invoke methods addFoo() and deleteFoo() respectively. \n* `PropertiesMethodNameResolver` - maps url to method name based on a pre-configured map as follows.\n\n``` xml PropertiesMethodNameResolver \n<bean class=\"org.springframework.web.servlet.mvc.multiaction.PropertiesMethodNameResolver\">\n   <property name=\"mappings\">\n      <value>\n         /multiaction/add.dev=add\n         /multiaction/remove.dev=remove\n         /multiaction/listAll.dev=listAll\n      </value>\n   </property>\n</bean>\n```\n\n* `ParameterNameMethodNameResolver` - maps a request parameter value to method name. e.g., `/Foo.html?action=add` invokes method add() after configuring 'action' as the parameter to look for.\n\n``` xml ParameterNameMethodNameResolver\n<bean class=\"org.springframework.web.servlet.mvc.multiaction.ParameterMethodNameResolver\">\n   <property name=\"paramName\" value=\"action\" />\n</bean>\n```\n\n### HandlerMapping\n\n* Maps incoming request to a handler/controller\n* Default mapping classes\n  * `BeanNameUrlHandlerMapping` - maps url to bean name in app context xml.\n  * `DefaultAnnotationHandlerMapping` - maps url to classes with `@Controller` and `@RequestMapping` annotations.\n* `SimpleUrlHandlerMapping` - maps url to a bean name in the app context.\n\n### HandlerInterceptor\n\n* intercepting requests before handed over to handlers to implement special functions like security, monitoring, etc.\n* This interface defines three methods: \n  * `preHandle()` is called before the actual handler is executed; \n  * `postHandle()` - is called after the handler is executed; \n  * `afterProcessing()` - is called after the complete request has finished. \n\n### HandlerExecutionChain \n???\n\n### HandlerAdapter\n\nis the glue between the dispatcher servlet and the handler. It removes the actual execution logic from the dispatcher servlet, which makes the dispatcher servlet infinitely extensible. It executes the Handler identified from the HandlerMapping. It takes a Handler as input and returns ModelAndView. If there is no view in the returned ModelAndView, RequestToViewNameTranslator is consulted to generate a view name based on the incoming request.\n\n### Resolvers\n\n#### ViewResolver\n\nUrlBasedViewResolver - controller returns \"cars\", resolver resolves it to \"/WEB-INF/jsp/cars.jsp\"\n \n``` xml UrlBasedViewResolver\n<bean id=\"viewResolver\" class=\"org.springframework....UrlBasedViewResolver\">\n   <property name=\"viewClass\" value=\"org.springframework...JstlView\"/>\n   <property name=\"prefix\" value=\"/WEB-INF/jsp\"/>\n   <property name=\"suffix\" value=\".jsp\"/>\n</bean>\n```\n\n#### HandlerExceptionResolver\n\n\n## DispatcherServlet Bootstrapping\n\n4 ways to bootstrap a DispatcherServlet in a ServletContainer like Tomcat\n\n1. `web.xml`\n2. `web-fragment.xml` (since Servlet 3.0 spec)\n3. `javax.servlet.ServletContextInitializer` (since Servlet 3.0 spec)\n\n``` java ServletContainerInitializer \npublic class BookstoreServletContainerInitializer implements ServletContainerInitializer {\n   @Override\n   public void onStartup(Set<Class<?>> classes, ServletContext servletContext) throws ServletException {\n      ServletRegistration.Dynamic registration = servletContext.addServlet(\"dispatcher\", DispatcherServlet.class);\n      registration.setLoadOnStartup(1);\n      registration.addMapping(\"/*\");\n   }\n}\n```\n\n4. Spring's WebApplicationInitializer\n\nSpring has an in-built implementation of ServletContextInitializer which scans classpath for WebApplicationInitializer implementations and invokes `onStartup()` on them.\n\n``` java WebApplicationInitializer\npublic class BookstoreWebApplicationInitializer implements WebApplicationInitializer {}\n   @Override\n   public void onStartup(ServletContext servletContext) throws ServletException {\n      ServletRegistration.Dynamic registration = servletContext.addServlet(\"dispatcher\", DispatcherServlet.class);\n      registration.addMapping(\"/*\");\n      registration.setLoadOnStartup(1);\n   }\n}\n```\n\nBy default, the dispatcher servlet loads a file named [servletname]-servlet.xml from the WEB-INF directory.\n\n### How to configure DispatcherServlet and ContextLoaderListener in Java?\n\nIn web, DispatcherServlet and ContextLoaderListener components bootstrap and configure an application context.\n\n* Steps to create `DispatcherServlet` in Java\n  * Spring 3.0 container automatically detects a FooWebAppInitializer class that extends WebApplicationInitializer.\n  * FooWebAppInitializer overrides onStartUp(ServletContext) method.\n  * Create new WebApplicationContext - new AnnotationConfigWebApplicationContext();\n  * Create new DispatcherServlet - new DispatcherServlet(webappContext);\n  * Add dispatcher servlet to ServletContext - servletContext.addServlet(\"dispatcher\", dispatcherServlet);\n* Steps to create `ContextLoaderListener` in Java \n  * Spring 3.0 container automatically detects a FooWebAppInitializer class that extends WebApplicationInitializer.\n  * FooWebAppInitializer overrides onStartUp(ServletContext) method.\n  * Create new WebApplicationContext - new AnnotationConfigWebApplicationContext();\n  * Create new ContextLoaderListener - new ContextLoaderListener(webappContext);\n  * Add listener to ServletContext - servletContext.addListener(contextLoaderListener);\n\n### DispatcherServlet Request Processing Flow\n\n{% img right /technology/springmvc-flow.png %}\n\n* DispatcherServlet receives request.\n* Before dispatching\n  * Determines and exposes java.util.Locale of the current request using LocaleResolver.\n  * Prepares and exposes current request in RequestContextHolder.\n  * Constructs FlashMap using FlashMapManager. Map contains attributes from previous request when a redirect is made.\n  * Request is checked if it is a multipart HTTP request. If so, request is wrapped in MultipartHttpServletRequest via MultipartResolver.\n* Dispatching\n  * DispatcherServlet consults 1 or more HandlerMapping implementations to determine the handler to handle the request. \n  * Check HandlerMapping\n    * If found, HandlerMapping returns an HandlerExecutionChain which holds references to Handler and HandlerInterceptor[](optional). \n    * If no handler found, http 404 response is sent.\n  * Check HandlerApapter\n    * Servlet tries to find a HandlerAdapter, \n    * If not found, ServletException is thrown.\n    * If found and if 1 or more HandlerInterceptor are defined, preHandle and postHandle methods in the interceptor are executed before and after the Handler execution.\n    * If a view is selected, DispatcherServlet checks if the view reference is a String or View.\n      * If a String is found, ViewResolvers are consulted to resolve it to a View implementation.\n      * If not resolved, ServletException is thrown.\n  * Handling Exceptions\n    * If an exception is thrown during request handling, DispatcherServlet consults HandlerExceptionResolver to handle thrown exceptions. \n    * It resolves an exception to a view to show to the user. \n    * If an exception is unresolved, it is rethrown and handled by the servlet container which throws HTTP 500 error.\n* After dispatching\n  * DispatcherServlet uses the event mechanism in the Spring Framework to fire a RequestHandledEvent. ApplicationListener can be to receive and log these events.\n\n# FAQs\n\n* Servlets\n  * Why is http stateless protocol? HttpServletRequest & HttpServletResponse? HttpSession? GET is idempotent, but POST is not.\n  * What is a cookie? Is there any security breach involved cos of using cookies? \n\n# Bibliography\n\n* Pro Spring MVC with WebFlows\n"
  },
  {
    "id": 24,
    "title": "Java Fundamentals",
    "url": "/technology/java.html",
    "content": "[TOC]\n\n# Fundamentals\n\n## Data Types\n\n### Floating Point Arithmetic\n\n* Java follows Binary Floating-point arithmetic standard\n  * \"float\" - 4 bytes of storage, and have 23 binary digits of precision\n  * \"double\" - 8 bytes of storage, and have 52 binary digits of precision.\n* `float f = 3.0f;` <-- single precision floating-point number constant\n* `double d = 3.0d;`<-- double precision floating-point number constant\n* Not A Number(NaN) is produced if a floating point operation has some input parameters that cause the operation to produce some undefined result. Example, `0.0 / 0.0`, `Math.sqrt(-2.0)`\n* `float pi=3.14f;` <-- suffix 'f' is required, since in Java real constants are by default double.\n\n* When to use and not use BigDecimal? <span style=\"color:red\">TODO</span>\n\n* Where primitives are stored?\n  * Local variables -> stack. \n  * Instance and static variables -> heap. \n  * Don't forget that for reference type variables, the value of a variable is a reference, not the object. (Arrays are reference types too - so if you have an int[], the values will be on the heap.)\n  * Since Java 6, a smart VM may be able to detect if a particular reference type variable refers to an object which can never \"escape\" the current method. If that's the case, it could potentially inline the whole object on the stack. (Read more on Escape Analysis)\n\n## Cloning\n\n* Deep copy & shallow copy\n* Cloneable interface\n* Pitfalls of Cloning\n  * Implementation can get really complex, but still leading to unsuccessful copying\n  * Cloning does not call constructor to make a copy. As a result, it is your responsibility, as a writer of the clone method, to make sure all the members have been properly set. Here is an example of where things could go wrong. Consider a class keeping track of the total number of objects of that type, using a static int member. In the constructors you would increase the count. However, if you clone the object, since no constructor is called, the count will not truly reflect the number of objects!\n  * Problem involving 'final' objects. In the below example, both the copies of 'Dog' will have all the 3 names, though it is not intended. The problem here is that, clone() is shallow copy, and the same List<String> is used for both objects\n\n```java\npublic class Dog implements Cloneable {\n   public final List<String> names = new ArrayList<String>();\n   public int age;\n   public int weight;\n   public Dog clone() {\n       try {\n           return (Dog) super.clone();\n       } catch (CloneNotSupportedException e) {\n           throw new Error(\"Is too\");\n       }\n   }\n   public static void main(){\n      Dog bowser = new Dog();\n      bowser.names.add(\"Fido\");\n      Dog bobBarker = bowser.clone();\n      bowser.names.add(\"Bowser\");\n      bobBarker.names.add(\"Bob Barker\");\n   }\n}\n```\n\n## Date\n\n* Java date – timezone – database timezone support?\n* http://www.date4j.net/\n* jodatime <span style=\"color:red\">TODO</span>\n* TimeZone uncertainity - http://martinfowler.com/bliki/TimeZoneUncertainty.html <span style=\"color:red\">TODO</span>\n* http://c2.com/cgi/wiki/wiki?JavaUtilDate\n* Date & Time - GregorianCalendar, TimeZone\n* Issues with Java Date API <span style=\"color:red\">TODO</span>\n\n\n## Finalization\n`java.lang.System.runFinalization()` - Runs the finalization methods of any objects pending finalization. Calling this method suggests that the Java Virtual Machine expend effort toward running the finalize methods of objects that have been found to be discarded but whose finalize methods have not yet been run. When control returns from the method call, the Java Virtual Machine has made a best effort to complete all outstanding finalizations.\n\n## Mutability\nAn immutable object is one whose externally visible state cannot change after it is instantiated.eg., String, Integer, BigDecimal, etc. For all immutable objects, it’s better to hide constructors and use factories.\n\n* Why Hashtable keys needs to be immutable objects?\n  * If you use mutable object as Hashtable key and if the object's state changes, then the Hashtable implementation would get confused since the hashcode would have changed.\n\n## UUID\n  <span style=\"color:red\">TODO</span>\n\n# OOPS Concepts\n\n## Access Modifiers\n\n* **public**\n  * can be applied to class (both inner & outer), method, field.\n  * A public method in a class is accessible to the outside world only if the class is declared as public. If the class does not specify any access modifier, then the public method is accessible only within the containing package.\n* **private**\n  * can only be applied inner class, method and field.\n* **protected**\n  * can be applied to inner class, method, field.\n* **default**\n  * can be applied to class(both inner & outer), method, field.\n  * One significant difference between these two access modifiers arises when we talk about a subclass belonging to another package than its superclass. In this case, protected members are accessible in the subclass, whereas default members are not.\n\n## Overloading\n\n* The signature of a method is made up of the method name, number of arguments, and types of arguments. You can overload methods with same name but with different signatures.\n* Overloading is an example of static polymorphism - meaning different forms of the method is resolved at compile-time.\n* Method & Constructor Overloading\n* **Overload resolution** - set of rules used by compiler to resolve which method to call. For resolving a method call, it first looks for the exact match—the method definition with exactly same number of parameters and types of parameters. If it can’t find an exact match, it looks for the closest match by using upcasts. The compiler throws error if there are no matches or ambiguous matches.\n\n## Overriding\n\n* You can invoke methods from the base class reference; however, the actual method invocation depends on the dynamic type of the object pointed to by the base class reference. The type of the base class reference is known as the **static type** of the object and the actual object pointed by the reference at runtime is known as the **dynamic type** of the object. \n* When the compiler sees the invocation of a method from a base class reference and if the method is an overridable method (a non-static and non-final method), the compiler defers determining the exact method to be called to runtime (late binding). At runtime, based on the actual dynamic type of the object, an appropriate method is invoked. This mechanism is known as **dynamic method resolution** or **dynamic method invocation**.\n* A static method is resolved statically. Inside the static method, a virtual method is invoked, which is resolved dynamically.\n* Things to watch while overriding\n  * Should have the same argument list types (or compatible types) as the base version.\n  * Should have the same return type. But from Java 5 onwards, the return type can be a subclass–covariant return types.\n  * Should not have a more restrictive access modifier than the base version. But it may have a less restrictive access modifier.\n  * Should not throw new or broader checked exceptions. But it may throw fewer or narrower checked exceptions, or any unchecked exception.\n * **Covariant Return Types** - copy() method is overridden in line 8 returning Shape, due to which explicit downcasting is needed on line 13. Since Java 5, overridden methods can return a sub-class covariant type to avoid this (returning Circle in this case). \n\n```java\nabstract class Shape {\n\t// other methods...\n\tpublic abstract Shape copy();\n}\n\nclass Circle extends Shape {\n\t// other methods...\n\tpublic Circle(int x, int y, int radius) { /* initialize fields here */ }\n\n\tpublic Shape copy() { /* return a copy of this object */ }\n\n\tclass Test {\n\t\tpublic static void main(String []args) {\n\t\tCircle c1 = new Circle(10, 20, 30);\n\t\tCircle c2 = (Circle)c1.copy();\n\t}\n}\n```\n\n* `@Override` - In order to overcome the subtle problems of overloading, Java 5 introduced @Override annotation. This explicitly expresses to the Java compiler the intention of the programmer to use method overriding. In case the compiler is not satisfied with your overridden method, it will issue a complaint. Also, the annotation makes you understand that you are overriding a method.\n* abstract method inside an interface - what does that mean? <span style=\"color:red\">TODO</span>\n\n## final keyword\n\n* Final class - is a non-inheritable class. \n* In general, OOP suggests that a class should be open for extension but closed for modification (Open/Closed Principle). However, it is useful for important reasons\n* To prevent a behavior change by subclassing. e.g. java.lang.System, java.lang.String\n* Improved performance (moderate)- All method calls of a final class can be resolved at compile time itself. As there is no possibility of overriding the methods, it is not necessary to resolve the actual call at runtime for final classes, which translates to improved performance. For the same reason, final classes encourage the inlining of methods. If the calls are to be resolved at runtime, they cannot be inlined.\n* Final methods are non-overrideable\n* Final variables are constants - The value of a final parameter cannot be changed once assigned. Here, it is important to note that the “value” is implicitly understood for primitive types. However, the “value” for an object refers to the object reference, not its state. Therefore, you can change the internal state of the passed final object, but you cannot change the reference itself.\n\n## static keyword\n* static variable\n  * is called class variable since it is associated with its class rather than the object.\n  * is initialized when the class is loaded first.\n  * A local variable (within a block or method) cannot be declared as static.\n* static method\n  * invoked by using class names. It is not recommended to use instance variables to call a static method.\n  * cannot access instance variables and methods. It can only access static variables and can call only static methods. In contrast, an instance method (non-static) may call a static method or access a static variable.\n  * cannot use the this keyword in its body since it is associated with a class and not an instance. Only instance methods have an implicit reference associated with them; hence class methods do not have a this reference associated with them.\n  * cannot be overridden. Because, based on the instance type, the method call is resolved with runtime polymorphism. Since static methods are associated with a class (and not with an instance), you cannot override static methods, and runtime polymorphism is not possible with static methods.\n  * cannot use the super keyword in its body. Why? You use the super keyword for invoking the base class method from the overriding method in the derived class. Since you cannot override static methods, you cannot use the super keyword in its body.\n* static block\n  * will be executed by JVM when it loads the class into memory.\n* static class - only an inner class can be defined static.\n\n## Nested classes\n\n* Nested class is a class defined inside the body of another class (or interface).\n* Types\n  * Static nested classes\n    * can access static members on the outer class.\n    * The outer class can also access the members (even private members) of the nested class through an object of nested class. If you don’t declare an instance of the nested class, the outer class cannot access nested class elements directly.\n    * A class or an interface defined inside an interface is implicitly static.\n  * Inner classes\n    * Every inner class is associated with an instance of the outer class.\n    * The accessibility (public, protected, etc.) of the inner class is defined by the outer class.\n    * Outer & inner classes can access members of each other regardless of the access specifiers.\n    * You can access members of an outer class within an inner class without creating an instance; but this is not the case with an outer class.\n    * Limitation: cannot declare static members in an inner class. \n  * Local inner classes\n    * Unlike static nested classes and inner classes, local inner classes are not members of an outer class; they are just local to the method or code in which they are defined.\n    * Since you cannot declare a local variable static, you also cannot declare a local class static.\n    * Since you cannot define methods in interfaces, you cannot have local classes or interfaces inside an interface. Nor can you create local interfaces\n    * can acces the method arguments and all the variables defined in the body of the code only if they are declared final.\n  * Anonymous classes\n    * Same as local inner class without a name. \n    * cannot have explicit constructors since there is no name.\n    * can acces the method arguments and all the variables defined in the body of the code only if they are declared final.\n\n\n<table>\n\t<thead>\n\t\t<tr>\n\t\t\t<th>           </th>\n\t\t\t<th> Static </th>\n\t\t\t<th> Non-static </th>\n\t\t\t<th> Anonymous </th>\n\t\t</tr>\n\t\t</thead>\n\t\t<tbody>\n\t\t<tr>\n\t\t\t<td> <strong>Non-local</strong> </td>\n\t\t\t<td style=\"vertical-align: top\"> Static nested class\n<pre>\nclass Outer{\n   static class Inner{}\n}\n\nclass Outer{\n   static interface Inner{}\n}\n\ninterface Outer{\n   static class Inner{}\n}\n\ninterface Outer{\n   static interface Inner{}\n}\n</pre>\n\t\t\t</td>\n\t\t\t<td style=\"vertical-align: top\"> Inner class \n<pre>\nclass Outer{\n   class InnerClass{\n   }\n}\n\nclass Outer{\n   interface Inner{}\n}\n</pre>\n\t\t\t</td>\n\t\t\t<td> Not possible </td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td> <strong>Local</strong>     </td>\n\t\t\t<td> Not possible        </td>\n\t\t\t<td style=\"vertical-align: top\"> Local inner class \n<pre>\nclass Outer{\n   void foo(final Object arg){\n      class LocalInner{\n      }\n   }\n}\n</pre>\n\t\t\t</td>\n\t\t\t<td style=\"vertical-align: top\"> Anonymous inner class \n<pre>\nclass Outer{\n   Object foo(){\n      return new Object(){ \n         public String toString(){ \n            return \"anonymous\";\n         }\n      }\n   }\n}\n</pre>\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n## Enums\n\n* A constructor in an enum class can only be specified as private.\n* are implicitly declared public, static, and final, which means you cannot extend them.\n* An enum implicitly inherits from java.lang.Enum and get converted internally to classes. Further, enum constants are instances of the enumeration class for which the constant is declared as a member.\n* cannot use the new operator on enum data types, even inside the enum class.\n* Enumeration constants cannot be cloned.\n\n## Interfaces\n\n* cannot declare static methods.\n* All fields are implicitly considered to be declared as public, static & final.\n* only public methods and variables are allowed in an interface. No protected or private.\n* All methods declared in an interface are implicitly considered to be abstract. You can also explicitly use the abstract qualifier for the method."
  },
  {
    "id": 25,
    "title": "Logging & Monitoring",
    "url": "/technology/architecture/logging-and-monitoring.html",
    "content": "[TOC]\n\n* Metric identity name: k-tuple\n* Metrics values\n  * counters, gauges, percentiles, nominal, ordinal, interval, ratio, derived\n* How can we monitor?\n  * Resolution: how frequent to collect the metrics? every 6-10secs?\n  * Latency: how long before we act on them?\n  * Diversity: are we collecting different metrics?\n\n# Monitoring Components\n\nhttps://www.usenix.org/sites/default/files/conference/protected-files/dickson.pdf \n\n1. Sensing/Measurement: Creation of metrics\n  * various systems gather data at various speeds.\n  * various systems have various concepts of a unit of a metric identity\n  * no consistent interface\n  * e.g., `top`, `np`, `netstats`, `sar`, `nagios`.\n* Storage\n* Collection\n* Analysis\n* Alerting/Escalation\n* Visualization - should be actionable items. Avoid pie charts for disk usage metrics. Think of visual graphs which can predict the disk size after 6 months.\n* Configuration\n* Configuration and Storage are cross-cutting concerns.\n\n#Monitoring Tools\n\n1. sar\n* trace\n* [MRTG](http://oss.oetiker.ch/mrtg/)\n  * acronym for Multi Router Traffic Grapher\n  * free software for monitoring and measuring the traffic load on network links.\n  * gets its data via SNMP agents every few minutes\n  * results are plotted in graphs\n  * has alerting mechanism\n* [RRDTool](http://oss.oetiker.ch/rrdtool/)\n  * acronym for Round-Robin Database Tool \n  * aims to handle time-series data like n/w bandwidth, CPU load, etc. \n  * The data are stored in a round-robin circular buffer/database, thus the system storage footprint remains constant over time. \n  * It has tools to display the data in graphical format.\n* [Nagios](http://www.nagios.com/)\n* [Ganglia](http://ganglia.info/)\n  * a scalable distributed system monitor tool for high performance computing systems such as clusters and grids.\n  * typically used with Nagios. \n* [Cacti](http://www.cacti.net/) (mrtg++) \n  * Network Graphing solution designed to harness the power of RRDTool's storage and graph functionality\n* [Sensu](http://www.sensuapp.org/) \n  * open source monitoring framework\n* LogStash\n  * Redis for storage\n  * RabbitMQ, grok\n  * Typical implementation: logstash + redis + elasticsearch\n* Splunk\n* [FluentD](http://www.fluentd.org/)\n  * an open-source tool to collect events and logs and store as JSON\n  * built on CRuby.\n  * plugins enables to store the massive data for Log Search (like ElasticSearch), Analytics and Archiving (MongoDB, S3, Hadoop)\n* [GrayLog2](http://www.graylog2.com/)\n  * an open source data analytics system \n  * search logs, create charts, create alerts\n  * leverages Java and ElasticSearch. Communication via REST API\n* [OpenTSDB](http://opentsdb.net/)\n  * pure storage solution\n  * a free distributed time-series database written on top of HBase.\n  * was written to store, index and serve metrics collected at a large scale, and make it easily accessible and graphable.\n* D3.js - Pure visualization solution\n* [Statsd](https://github.com/etsy/statsd/)\n  * listens to anything and everything\n  * written in node.js. There are alternative implementations in groovy, C, etc.\n  * listens to statistics (counters and timers) and sends aggregates to backend services like Graphite\n* [Graphite](http://graphite.wikidot.com/)\n  * this open-source tool written on Python does 2 things: store numeric time-series data and render graphs of this data on demand\n  * does not collect data.\n  * 3 components\n    * carbon - a [Twisted](https://twistedmatrix.com/trac/) daemon that listens for time-series data\n    * whisper - a simple database library for storing time-series data\n    * graphite-webapp - A [Django](https://www.djangoproject.com/) webapp that renders graphs on-demand using [Cairo](http://www.cairographics.com/).\n* [Shinken](http://www.shinken-monitoring.org/)\n  * open-source Nagios like tool, redesigned and rewritten from scratch.\n  * Nagios + Graphite + Configuration\n* [Kibana](http://www.elasticsearch.org/overview/kibana/)\n  * web interface for viewing logstash records stored in elasticsearch\n* [ElasticSearch](http://www.elasticsearch.org/)\n* Zenoss\n* Shippers\n  * lumberjack\n  * beaver\n  * syslog\n  * woodchuck\n* AppDynamics\n* New Relic\n* Other tools\n  * monigusto\n  * collectd\n  * jmxtrans\n  * tasseo\n  * gdash\n  * librato\n\n\n## Splunk\n\n* is a time-series indexer - a product that takes care of the three Vs very well.\n* 3 main functionalities\n    * **Data collection** \n      * from static source \n      * from real-time source\n      * from log files, rolling log files\n      * from databases\n    * from script results\n  * **Data indexing** - index of above data\n  * **Search and Analysis** - Using Splunk Processing Language to search and extract results in the form of charts, events, etc.\n* Splunk breaks down log file entries into different events based on the associated timestamp. If no timestamp is found, then all the lines in the log file is considered as a single event.\n\n### Components \n\n1. Search Head\n2. Forwarders\n\n### Queries\n\n* Top browsers: `sourcetype=\"access_combined_wcookie\" | top useragent`\n* Bottom 3 browsers: `sourcetype=access_combined_wcookie | rare useragent limit=3`\n* Top 5 IP address: `sourcetype=\"access_combined_wcookie\" | top clientip limit=5`\n* Top Referers without percent field: `sourcetype=access_combined_wcookie referer != *MyGizmo* | top referer | fields - percent`\n* Count of 404 errors grouped by `source: sourcetype=access_combined_wcookie status=404 | stats count by source`\n* Top purchases by product: `sourcetype=access* | timechart count(eval(action=\"purchase\")) by productId usenull=f`\n* Pages views and purchases: `sourcetype=access_* | timechart per_hour(eval(method=\"GET\")) AS Views, per_hour(eval(action=\"purchase\")) AS Purchases`\n* Geo location of IPs (Google Maps): `sourcetype=access* | geoip clientip`\n\n### Analytics\n\n* also known as Business Intelligence / Data Mining / OLAP\n* Traditional analytics are based on 'Early Structure Binding', where you need to know beforehand what questions are going to be asked of the data.\n  * The typical development steps can be summarized as follows:\n    * Decide what questions to ask\n    * Design the data schema\n    * Normalize the data\n    * Write database insertion code\n    * Create the queries\n    * Feed the results into an analytics tool\n* Late Structure Binding, which has these simple steps:\n  * Write data (or events) to log files\n  * Collect the log files\n  * Create searches, graphs, and reports using Splunk\n* Operational Intelligence refers to the information collected and processed \n* Semantic logging as data or events that are written to log files explicitly for the purpose of gathering analytics.\n\n# Java Logging\n\n## slf4j\n\n* Meta logging Frameworks - http://www.slf4j.org\n* NDC, MDC statements - http://stackoverflow.com/questions/7404435/conditional-logging-with-log4j?\n* What are the classloader issues that plague JCL?\n* what is meant by 'static binding approach' in sl4j?\n* Marker objects\n* NOPLogger?\n\n## logback\n"
  },
  {
    "id": 26,
    "title": "Messaging",
    "url": "/technology/messaging.html",
    "content": "[TOC]\n\n\n# Overview\n\n* Messaging is primarily used to solve scalibility & reliability issues\n* plays key role in heterogenous integration of system built on myriad of technologies like Java, .Net, Mainframe, etc.\n* can process requests asynchronously\n* provides high degree of decoupling between components, systems, etc.\n\n* Some of the messaging  techniques and technologies developed: \n  * MDB(Message Driven Bean from EJB spec)\n  * Spring Messaging Framework\n  * EDA (Event Driven Architecture)\n  * SOA (Service-Oriented Architecture)\n  * RESTful JMS interfaces\n  * ESB (Enterprise Service Bus).\n\n\n* Messaging middleware vendors: IBM's WebSphere MQ, TIBCO Rendezvous, SonicMQ, Microsoft Message Queuing (MSMQ) , Opensource ActiveMQ\n* Terminologies\n  * Message Broker: responsible for delivering messages from one messaging client to other clients.\n  * Queue Depth: number of messages in the queue\n\n## Advantages of Messaging\n\n* Heterogeneous system integration\n* Reduce system bottlenecks\n* Increase scalability\n* Architecture flexibility and agility\n* Enterprise middleware products ensure that messages are properly distributed among applications, provide fault tolerance, load balancing, scalability, and transactional support.\n* offer a degree of reliability, flexibility, extensibility and modularity that a traditional RPC or distributed object system simply cannot.\n\n## Messaging Architecture Styles\n\n### Service-Oriented Architecture (SOA)\n\nan architecture style that defines business services that are abstracted from the corresponding enterprise service implementations.\n\n### Enterprise Service Bus (ESB)\n\n* SOA has given rise to a new breed of middleware called ESB.\n* In the early days of SOA, most ESBs were implemented as message brokers, whereby components within the messaging layer were used to perform some sort of intelligent routing or message transformation before delivering the message. These earlier message brokers have evolved into sophisticated commercial and open source ESB products that use messaging at their core. Although some ESB products support a traditional non-JMS HTTP transport (web services), most enterprise-wide production implementations still leverage messaging as the protocol for communication.\n* Messaging is an excellent means of building the abstraction layer within SOA needed to fully abstract a business service from its underlying implementation. Through messaging, the business service does not need to be concerned about where the corresponding implementation service is, what language it is written in, what platform it is deployed in, or even the name of the implementation service.\n\n### Event-Driven Architecture (EDA)\n\n* an architecture style that is built on the premise that the orchestration of processes and events is dynamic and very complex, and therefore not feasible to control or implement through a central orchestration component. When an action takes place in a system, that process sends an event to the entire system stating that an action took place (an event). That event may then kick off other processes, which in turn may kick off additional processes, all decoupled from each other.\n* Example of EDA include insurance domain and benefits domain. Getting married or changing jobs triggers events in the system that quality for certain changes to health and retirement benefits.\n* Messaging is at the heart of EDA systems. Not surprisingly, most architectures based on EDA leverage the pub/sub model as a means of broadcasting the events within a system.\n* Heterogeneous Platform Integration\n* Messaging plays a key role in being able to make these heterogeneous platforms communicate with one another, whether it be Java EE and Microsoft .NET, Java EE and CICS, or Java EE and Tuxedo C++.\n* Some platforms, such as .NET, may require an external messaging bridge to convert a JMS message into an MSMQ message (depending on the messaging provider you are using). For example, ActiveMQ provides a messaging bridge for converting MSMQ to JMS (and vice versa). This lower-level platform integration has given rise to a broader scope of integration, known as Enterprise Application Integration.\n \n### Enterprise Application Integration (EAI)\n\n* Organizations have a strong desire to integrate both legacy and new applications so that they can share information and cooperate in larger enterprise-wide operations. The integration of these applications is generally called Enterprise Application Integration (EAI).\n* Data and events can be exchanged in the form of messages via topics or queues, which provide an abstraction that decouples participating applications.\n\n\n\n# EMS (Enterprise Messaging System)\n\n{% img right /technology/ems-architecture.png %}\n\n* EMS (Enterprise Message Systems) or MOM (Message Oriented Middleware): Application-to-application messaging systems, when used in business systems, are generally referred to as EMS or MOM.\n* Clients send messages to the messaging server, which then distributes them to one or more recipients. Client is the business app or component that uses the JMS API.\n* Key feature of messaging is delivering message asynchronously. Client app can send a message and forget about it.\n* **Message-Oriented Middleware** architectures  \n  * vary in their implementation from a centralized architecture that depends on a message server to perform routing, to a decentralized architecture that distributes the server processing out to client machines. Some models use a hybrid approach.\n  * vary in the protocol used at the network transport layer including TCP/IP, HTTP, SSL, and IP multicast. \n\n## Architecture styles\n\n* **Centralized architecture**: relies on message server or broker that is responsible for delivering messages from one client to other - decouples sender from receivers - clients only see the server and not other clients which allows to add/remove without affecting the whole system - central server may be a cluster of distributed servers operating as a single logical unit - Uses TCP/IP as protocol.\n* **Decentralized architecture**: no centralized server - some of the server functionality (persistence, transactions, security) is embedded as part of the client while the message routing is delegated to the network layer - Uses IP multicast at network level\n\n## Messaging Models or Domains\n\n| | Point-to-Point (p2p) | Publish-and-Subscribe (pub-sub) | \n| - | ------------- | -------------- |\n| Virtual Channel | Queue | Topic | \n| Actors | Senders & Receivers | Publishers & Subscribers | \n| Message receivers | Though many receivers may listen on a queue, only one receiver gets the same message.\t Same message can be sent to multiple subscribers (this is referred to as broadcasting). There are 2 types of subscribers <br/> * Non-durable - temporary subscriptions that receive messages only when they are actively listening on the topic <br/> * Durable - will receive a copy of every message published, even if they are offline when the message is published. | \n| Message notification | Pull-based or polling-based | Push-model. Clients are automatically notified when a message is available.\n| Message delivery | Supports both synchronous(request/reply) & asynchronous (fire-and-forget) | Supports both | \n| Coupling | More coupled with client | Decoupled from clients | \n| Used for | Load balancing\t |  |  \n| Browser | Queue browser allows to view message in a queue before delivery. | Not available\n\n# JMS\n\n* JMS is a vendor-agnostic Java API that can be used with many different enterprise messaging vendors - Not a messaging system itself.\n* API Overview\n  * can be broken down into 3 parts\n    * General API - used to send/receive messages from either a queue or a topic \n    * **Point-to-point API** - used solely for messaging with queues\n    * **Publish-subscribe API** - used soleley for messaging with topics\n  * `ConnectionFactory` & `Destination` must be obtained from the provider using JNDI (per the JMS spec). Other interfaces are created through factory methods. e.g., `ConnectionFactory --creates--> Connection --creates--> Session --creates--> Message, MessageProducer, MessageReceiver`\n  * Unlike JDBC, in JMS, `Session` object holds the transactional unit of work for messaging instead of `Connection`.\n\n* JMS Client: business app that uses the JMS API\n* JMS Provider: 3rd party messaging vendor that implemented the JMS API\n* JMS Administered Objects: are JMS objects that are created and configured by the system administrator. It includes JMS ConnectionFactory and Destination objects such as topics and queues.\n\n{% img right /technology/jms-api.png %}\n\n| General API | Point-to-Point API | Pub-Sub API | \n| ----------- | ------------------ | ----------- | \n| ConnectionFactory | QueueConnectionFactory | TopicConnectionFactory | \n| Destination | Queue | Topic |\n| Connection | QueueConnection | TopicConnection | \n| Session | QueueSession | TopicSession | \n| Message | Message | Message | \n| MessageProducer | QueueSender | TopicPublisher | \n| MessageConsumer | QueueReceiver | TopicSubscriber |\n\n\n## JMS Programming Step-By-Step\n\n### Step 1: Define jndi.properties\n\n``` properties jndi.properties\njava.naming.factory.initial = org.apache.activemq.jndi.ActiveMQInitialContextFactory\njava.naming.provider.url = tcp://localhost:61616\njava.naming.security.principal=system\njava.naming.security.credentials=manager\n\nconnectionFactoryNames = TopicCF\ntopic.topic1 = jms.topic1\n```\n\nThe jndi.properties file also contains the JNDI connection information for the JMS provider. You will need to set the initial context factory class, provider URL, username, and password needed to connect to the JMS server. Each vendor will have a different context factory class and URL name for connecting to the server. You will need to consult the documentation of your specific JMS provider or Java EE container to obtain\nthese values. \n\n### Step 2: Obtaining a JNDI connection\n\nA directory service provides JMS clients with access to ConnectionFactory and Destination (topics and queues) objects. ConnectionFactory and Destination objects are the only things in JMS that cannot be obtained using the JMS API—unlike connections, sessions, producers, consumers, and messages, which are manufactured using the factory pattern within the JMS API. JNDI provides a convenient, location-transparent, configurable, and portable mechanism for obtaining ConnectionFactory and Destination objects, also called JMS-administered objects because they are established\nand configured by a system administrator.\n\nJMS servers will either work with a separate directory service like LDAP or provide their own directory service that supports the JNDI API.\n\nCreating a connection to a JNDI naming service requires that a javax.naming.InitialContext object be created. An InitialContext is the starting point for any JNDI lookup—it’s similar in concept to the root of a filesystem. The InitialContext provides a network connection to the directory service that acts as a root for accessing JMS administered objects. \n\n``` java\n// Obtain a JNDI connection using the jndi.properties file\nInitialContext ctx = new InitialContext();\n```\n\nAlternately, InitialContext can be initialized with properties object as follows:\n\n``` java\nProperties env = new Properties();\nenv.put(Context.SECURITY_PRINCIPAL, \"system\");\nenv.put(Context.SECURITY_CREDENTIALS, \"manager\");\nenv.put(Context.INITIAL_CONTEXT_FACTORY, \"org.apache.activemq.jndi.ActiveMQInitialContextFactory\");\nenv.put(Context.PROVIDER_URL, \"tcp://localhost:61616\");\n\nInitialContext ctx = new InitialContext(env);\n```\n\n# Messaging Technologies\n\n## RabbitMQ\n\nRabbitMQ is one of the leading implementation of the AMQP protocol (along with Apache Qpid). Therefore, it implements a broker architecture, meaning that messages are queued on a central node before being sent to clients. This approach makes RabbitMQ very easy to use and deploy, because advanced scenarios like routing, load balancing or persistent message queuing are supported in just a few lines of code. However, it also makes it less scalable and “slower” because the central node adds latency and message envelopes are quite big.\n\n## ZeroMQ\n\nZeroMQ is a very lightweight messaging system specially designed for high throughput/low latency scenarios like the one you can find in the financial world. Zmq supports many advanced messaging scenarios but contrary to RabbitMQ, you’ll have to implement most of them yourself by combining various pieces of the framework (e.g : sockets and devices). Zmq is very flexible but you’ll have to study the 80 pages or so of the guide (which I recommend reading for anybody writing distributed system, even if you don’t use Zmq) before being able to do anything more complicated than sending messages between 2 peers.\n\n## ActiveMQ\n\nActiveMQ is in the middle ground. Like Zmq, it can be deployed with both broker and P2P topologies. Like RabbitMQ, it’s easier to implement advanced scenarios but usually at the cost of raw performance. It’s the Swiss army knife of messaging\n\nActiveMQ (http://activemq.apache.org)\n\n# Bibliography\n\n* Java Message Service - O'Reilly\n\n"
  },
  {
    "id": 27,
    "title": "NoSQL",
    "url": "/technology/nosql.html",
    "content": "[TOC]\n\n# Key-Value Stores\n\n* Known databases: Riak, Redis, memcached, memcachedb, membase, Voldemort\n* Not performant for complex queries and aggregate operations\n\n## Riak\n\n* Riak is a distributed key-value database where values can be anything—from plain text, JSON, or XML to images or video clips—all accessible through a simple HTTP interface\n* is a distributed, datareplicating, enhanced key-value store without a single point of failure\n* Implementation of Amazon's Dynamo\n* Embraces web constructs of HTTP and REST from ground up\n* supports advanced querying via mapreduce.\n* Riak is a great choice for datacenters like Amazon that must serve many requests with low latency. If every millisecond spent waiting is a potential customer loss, Riak is hard to beat.\n* Riak breaks up classes of keys into buckets to avoid key collisions.\n* Riak stores everything as a binary-encoded value.\n* Links are metadata that associate one key to other keys. Links are uni-directional. What makes Links special in Riak is link walking (and a more powerful variant, linked mapreduce queries)\n* URL Pattern: `http://SERVER:PORT/riak/BUCKET/KEY`. \n\n### Architecture\n* Riak server architecture removes single points of failure (all nodes are peers) and allows you to grow or shrink the cluster at will. This is important when dealing with large-scale deployments, since it allows your database to remain available even if several nodes fail or are otherwise unresponsive.\n* Distributing data across several servers is saddled with an inherent problem. If you want your database to continue running when a network partition occurs (meaning, some messages were lost), it means you must make a tradeoff. Either you can remain available to server requests or you can refuse requests and ensure the consistency of your data. It is not possible to create a distributed database that is fully consistent, available, and partition tolerant. You can have only two (partition tolerant and consistent, partition tolerant and available, or consistent and available but not distributed). This is known as the **CAP theorem** (Consistency, Availability, Partition tolerance).\n* Riak takes advantage of this fact by allowing you to trade availability for consistency on a per-request basis.\n* **Riak Ring** - Riak divides its server configuration into partitions denoted by a 160-bit number (that’s 2^160). The Riak team likes to represent this massive integer as a circle, which they call the ring. When a key is hashed to a partition, the ring helps direct which Riak servers store the value.\n\n### MapReduce\n* Mapreduce runs in an inverse manner. Rather than grabbing data from the database and running it on a client (or app server), mapreduce is a pattern to pass an algorithm to all of the database nodes, which are then each responsible for returning a result.\n* It’s faster to send the algorithm to the data and then send the data to the algorithm.\n\n### Clustering\n* Riak allows us to control reads and writes into the cluster by altering three values: \n  * N is the number of nodes a write ultimately replicates to, in other words, the number of copies in the cluster. \n  * W is the number of nodes that must be successfully written to before a successful response. If W is less than N, a write will be considered successful even while Riak is still copying the value in background. \n  * R is the number of nodes required to read a value successfully. If R is greater than the number of copies available, the request will fail. If R=1, there is a potential chance to read stale values. If R=N, then if any of those N nodes become unavailable, read requests would fail. \n* ** Conflict Resolution **\n  * Riak uses vector clocks. A vector clock is a token that distributed systems like Riak use to keep the order of conflicting key-value updates intact. Timestamps cannot be used since the clocks across servers may not be synchronized.\n\n### Downsides/Limitations/Trade-offs\n* lacks robust support for ad hoc queries, and key-value stores, by design, have trouble linking values together (in other words, they have no foreign keys).\n* If you require simple queryability, complex data structures, or a rigid schema or if you have no need to scale horizontally with your servers, Riak is probably not your best choice.\n\n## Redis\n\n* provides for complex datatypes like sorted sets and hashes, as well as basic message patterns like publish-subscribe and blocking queues.\n* by caching writes in memory before committing to disk, Redis gains amazing performance in exchange for increased risk of data loss in the case of a hardware failure. good fit for caching noncritical data and for acting as a message broker.\n\n# Column-oriented Databases\n\n## Overview\n\n* Known databases: HBase, Cassandra, Hypertable\n* Large data stored across machines, less data relationships\n* adding columns is quite inexpensive\n* Each row can have a different set of columns, or none at all, allowing tables to remain sparse without incurring a storage cost for null values.\n\n## HBase\n\n* Using Google’s BigTable paper as a blueprint, HBase is built on Hadoop (a mapreduce engine) and designed for scaling horizontally on clusters of commodity hardware.\n* supports versioning and compression.\n* HBase is a column-oriented database that prides itself on consistency and scaling out.\n* A table in HBase is basically a big map. Well, more accurately, it’s a map of maps.\n* Unlike a relational database, in HBase a column is specific to the row that contains it. When we start adding rows, we’ll add columns to store data at the same time.\n* HBase stores an integer timestamp for all data values, representing time in milliseconds since the epoch (00:00:00 UTC on January 1, 1970). When a new value is written to the same cell, the old value hangs around, indexed by its timestamp. This is a pretty awesome feature. Most databases require you to specifically handle historical data yourself, but in HBase, versioning is baked right in!\n* A Bloom filter is a really cool data structure that efficiently answers the question, “Have I ever seen this thing before?”. HBase supports using Bloom filters to determine whether a particular column exists for a given row key (BLOOMFILTER=>'ROWCOL') or just whether a given row key exists at all (BLOOMFILTER=>'ROW'). The number of columns within a column family and the number of rows are both potentially unbounded. Bloom filters offer a fast way of determining whether data exists before incurring an expensive disk read.\n* In HBase, rows are kept in order, sorted by the row key. A region is a chunk of rows, identified by the starting key (inclusive) and ending key (exclusive). Regions never overlap, and each is assigned to a specific region server in the cluster.\n\n### Why use HBase?\nScalability, built-in features like versioning, compression, garbage collection of expired data, in-memory tables. Strong consistency guarantees makes it easier to transition from relational world.\n\n### Where to use?\n* Best used for online analytical processing systems - though individual queries are slower compared to other dbs, it works really well with enormous datasets. Big companies use this to back logging and search systems. Used by Facebook a principal component of its new messaging infrastructure. Twitter uses HBase extensively, ranging from data generation (for applications such as people search) to storing monitoring/performance data\n  \n### Architecture\n* HBase is designed to be fault tolerant. Hardware failures may be uncommon for individual machines, but in a large cluster, node failure is the norm. By using write-ahead logging and distributed configuration, HBase can quickly recover from individual server failures.\n* HBase supports three running modes:\n  * Stand-alone mode is a single machine acting alone.\n  * Pseudodistributed mode is a single node pretending to be a cluster.\n  * Fully distributed mode is a cluster of nodes working together.\n\n### Downsides\n  * Although HBase is designed to scale out, it doesn’t scale down.\n  * Solving small problems isn’t what HBase is about, and nonexpert documentation is tough to come by, which steepens the learning curve.\n  * HBase is almost never deployed alone. Rather, it’s part of an ecosystem of scale-ready pieces. These include Hadoop (an implementation of Google’s MapReduce), the Hadoop distributed file system (HDFS), and Zookeeper (a headless service that aids internode coordination). This ecosystem is both a strength and a weakness; it simultaneously affords a great deal of architectural sturdiness but also encumbers the administrator with the burden of maintaining it.\n  * One noteworthy characteristic of HBase is that it doesn’t offer any sorting or indexing capabilities aside from the row keys. Rows are kept in sorted order by their row keys, but no such sorting is done on any other field, such as column names and values. So, if you want to find rows by something other than their key, you need to scan the table or maintain your own index.\n  * There is no concept of data types. Everything is an uninterrupted array of bytes\n\n\n# Document-oriented Databases\n\n## MongoDB\n{% img right /technology/mongo-datatypes.png 500 500 %}\n\n* supports consistency. Supports ACID properties at single-document level only.\n* offers atomic read-write operations such as incrementing a value and deep querying of nested document structures.\n* Using JavaScript for its query language, MongoDB supports both simple queries and complex mapreduce jobs.\n* It is a document database, which allows data to persist in a nested state, and importantly, it can query that nested data in an ad hoc fashion. It enforces no schema.\n* Mongo is a JSON document database (though technically data is stored in a binary form of JSON known as BSON).\n* Every object/document has a unique incrementing numeric primary key called ObjectId. The ObjectId is always 12 bytes, composed of a timestamp, client machine ID, client process ID, and a 3-byte incremented counter.\n* In Mongo you can construct ad hoc queries by field values, ranges, or a combination of criteria.\n* MongoDB provides several of the best data structures for indexing, such as the classic B-tree, and other additions such as two-dimensional and spherical GeoSpatial indexes.\n* What makes Mongo special in the realm of document stores is its ability to scale across several servers, by replicating (copying data to other servers) or sharding collections (splitting a collection into pieces) and performing queries in parallel. Both promote availability.\n* Replica Sets\n  * Mongo was built to scale out, not to run stand-alone. It was built for data consistency and partition tolerance, but sharding data has a cost: if one part of a collection is lost, the whole thing is compromised. What good is querying against a collection of countries that contains only the western hemisphere? Mongo deals with this implicit sharding weakness in a simple manner: duplication. You should rarely run a single Mongo instance in production but rather replicate the stored data across multiple services.\n* GridFS??\n\n### Index Types\n* Unique Index - \n* Capped collection - max size of the collection is defined at the time of creation and cannot be altered; an existing regular collection can be converted to capped collection, but not vice versa. It behaves like a circular queue and maintains the insertion order; cannot be sharded.\n* Tailable cursors - like `tail -f` command, tailable cursors can be defined on capped collections.\n* TTL indexes - Time-to-Live indexes are customizable capped collections where time-out for each document is defined by the user.\n* Full-text indexes - give you the ability to search text quickly, as well as provide built-in support for multi-language stemming and stop words; only index string data; allows searching multiple fields with custom weightage specified (from default 1 to 1 billion); You can create a full-text index on all string fields in a document by creating an index on \"$**\"; \n\n\n#### Geo-spatial indexes\n* Types of Geospatial queries : intersection, within, and nearness; Geospatial queries using \"intersection\" and \"within\" functions do not require an index, whereas \"near\" function does.\n* 2dsphere index - \n  * for surface-of-the-earth-type maps; allows you to specify points, lines, and polygons in GeoJSON format. A point is given by a two-element array, representing [longitude, latitude]; A line by an array of Points; A polygon in the same way as lines but with different 'type'; Sample queries: restaurants in given coordinates, restaurants near given coordinates.\n* 2d index - for flat maps, video game maps and time series data; \"2d\" indexes assume a perfectly flat surface, instead of a sphere; can only store points; \n\n\n### Data modelling\n\n#### Embedded document model\n\n* **Pros**\n\n* Locality. Less disk seeks and hence faster.\n* Atomicity & Isolation during mutant operations.\n\n* **Cons**\n\n* Querying for all sub-documents with a matching condition would return the sub-document along with parent as well. Major drawback of this approach is that we get back much more data than we actually need.\n* For example, in a document like below, querying for all the comments by John would return all the books where John has commented, not just the comments. Also it is not possible to sort or limit the comments returned.\n\n```\n{\n  \"book\": \"Head First Java\",\n  \"text\": \"This is a book\",\n  \"comments\": [\n    {\"author\": \"John\", \"text\": \"...\"},\n    {\"author\": \"Jack\", \"text\": \"...\"},\n    {\"author\": \"John\", \"text\": \"...\"},\n  ]\n}\n```\n\n\n* Embedding carries significant penalties with it:\n  * The larger a document is, the more RAM it uses.\n  * Growing documents must eventually be copied to larger spaces. As you append to the large document, eventually MongoDB is  going to need to move the document to an area with more space available. This movement, when it happens, significantly  slows update performance\n  * MongoDB documents have a hard size limit of 16 MB.\n\n* When to use\n  * If your application’s query pattern is well-known and data tends to be accessed in only one way, an embedded approach works well.\n\n#### Referenced document model\n\n* Pros\n  * Flexibility\n  * Best fit for many-to-many relationships.\n* Cons\n  * No joins hence needs multiple network calls to retrieve complete data.\n  * There is no multi-document transaction in Mongodb. In other words, unlike SQL you cannot edit/delete multiple documents in a single transaction. If a business entity spans across multiple collections, you cannot alter that entity from different collections atomically.\n* When to use\n  * If your application may query data in many different ways, or you are not able to anticipate the patterns in which data may be queried, a more “normalized” approach may be better.\n  * Another factor that may weigh in favor of a more normalized model using document references is when you have one-to-many relationships with very high or unpredictable *arity*.\n\n\n\n### Advanced Concepts\n    \n#### Why no transactions?\n\n* MongoDB was designed from the ground up to be easy to scale to multiple distributed servers. Two of the biggest problems in distributed database design are distributed join operations and distributed transactions.\n* Both of these operations are complex to implement, and can yield poor performance or even downtime in the event that a server becomes unreachable. By “punting” on these problems and not supporting\n* joins or multidocument transactions at all, MongoDB has been able to implement an automatic sharding solution with much better scaling and performance characteristics than you’d normally be stuck with if you had to take relational joins and transactions into account.\n\n#### Write concern\n\n* MongoDB has a configurable write concern. This capability allows you to balance the importance of guaranteeing that all writes are fully recorded in the database with the speed of the insert. \n* For example, if you issue writes to MongoDB and do not require that the database issue any response, the write operations will return very fast (since the application needs to wait for a response from the database) but you cannot be certain that all writes succeeded. Conversely, if you require that MongoDB acknowledge every write operation, the database will not return as quickly but you can be certain that every item will be present in the database. \n* The proper write concern is often an application-specific decision, and depends on the reporting requirements and uses of your analytics application.\n\n**Insert acknowledgement**\n\nBy setting w=0, you do not require that MongoDB acknowledge receipt of the insert. `db.events.insert(event, w=0)`\n\n**Journal write acknowledgement**\nIf you want to ensure that MongoDB not only acknowledges receipt of a write operation but also commits the write operation to the on-disk journal before returning successfully to the application, you can use the j=True option: `db.events.insert(event, j=True)`.\n\nMongoDB uses an on-disk journal file to persist data before writing the updates back to the “regular” data files. Since journal writes are significantly slower than in-memory updates (which are, in turn, much slower than “regular” data file updates), MongoDB batches up journal writes into “group commits” that occur every 100 ms unless overridden in your server settings. What this means for the application developer is that, on average, any individual writes with j=True will take around 50 ms to complete, which is generally even more time than it would take to replicate the data to another server.\n\n**Replication acknowledgement**\nTo acknowledge that the data has replicated to two members of the replica set before returning: `db.events.insert(event, w=2)`.\n\n\n#### Aggregation Framework\n* a pipeline that processes a stream of documents through several building blocks: filtering, projecting, grouping, sorting, limiting, and skipping.\n* `aggregate()` function returns an array of result documents; cannot write to a collection;\n* **Pipeline Operations** - Each operator receives a stream of documents, does some type of transformation on these documents, and then passes on the results of the transformation. If it is the last pipeline operator, these results are returned to the client. Otherwise, the results are streamed to the next operator as input.\n\n#### Sharding\n* One of the central reasons for Mongo to exist is to safely and quickly handle very large datasets. The clearest method of achieving this is through horizontal sharding by value ranges—or just sharding for brevity. Rather than a single server hosting all values in a collection, some range of values are split (or in other words, sharded) onto other servers. For example, in our phone numbers collection, we may put all phone numbers less than 1-500-000-0000 onto Mongo server A and put numbers greater than or equal to 1-500-000-0001 onto a server B. Mongo makes this easier by autosharding, managing this division for you.\n* Diff b/w sharding and replication? Replication copies the exact copy of a data in multiple servers. Sharding stores different subset of data across multiple servers.\n* Shard - server participating in a sharded cluster.\n* mongos - routing process which sits in front of all the shards. Apps connect to this process.\n* Sharding is enabled at database level.\n* Shard key - when you enable sharding you choose a field or two that MongoDb uses to break up data. To even create a shard key, the field(s) must be indexed. Before sharding, the collection is essentially a single chunk. Sharding splits this into smaller chunks based on the shard key\n\n\n\n## CouchDb\n\n* Written in Erlang\n* With nearly incorruptible data files, CouchDB remains highly available even in the face of intermittent connectivity loss or hardware failure.\n* Like Mongo, CouchDB’s native query language is JavaScript. \n* Storage data format: JSON\n\n### Admin UI\n\n* Futon is a web-based interface to work with CouchDB and it provides support for editing the configuration information, creating databases, documents, design documents, etc. \n* URI: http://localhost:5984/_utils/index.html \n* How to create our first database? * Futon -> Overview -> Create database* . Multiple such databases can be created in this single instance of CouchDb.\n\n### How to access CouchDB programmatically?\n\nvia HTTP REST Interface\n Note: If the db is password protected, send requests with credentials as follows: `http://username:pass@remotehost:5984/dbname`\n\n* To check if the CouchDb is up and running: `curl http://localhost:5984`\n* To create a db: \n  * Request: `curl -X PUT http://localhost:5984/dbname`\n  * Response: `{\"ok\":true}`\n* To delete a db:\n  * Request: `curl -X DELETE http://localhost:5984/dbname`\n  * Response: `{\"ok\":true}`\n* To retrieve db information: \n  * Request: `curl -X GET http://localhost:5984/dbname`\n  * Response: `{\"db_name\":\"dbname\",\"doc_count\":0,\"doc_del_count\":0,\"update_seq\":0,\"purge_seq\":0,\"compact_running\":false,\"disk_size\":79,\"data_size\":0,\"instance_start_time\":\"1386975670043000\",\"disk_format_version\":6,\"committed_update_seq\":0}`\n* To create a new document: \n  * Request: `curl -H \"Content-type: application/json\" -X POST http://localhost:5984/dbname -d \"{\\\"title\\\": \\\"Lasagne\\\"}\"`\n  * Response: `{\"ok\":true,\"id\":\"d02bdee238b26628d1ce28f1c80313bb\",\"rev\":\"1-f07d272c69ca1ba91b94544ec8eda1b6\"}`\n  * Comments: 'id' is a unique document identifier and \"rev\" is the revision id of the document automatically generated.\n* To create a document with custom document id:\n  * Request: `curl -H \"Content-type: application/json\" -X PUT http://localhost:5984/dbname/pasat -d \"{\\\"title\\\": \\\"Pasat\\\"}\"`\n  * Response: `{\"ok\":true,\"id\":\"pasat\",\"rev\":\"1-91b034b589017f930d12f7fec23be727\"}`\n  * Comments: PUT method is used instead of POST. Custom document id is passed in the url.\n* To retrieve a document:\n  * Request: `curl -X GET http://localhost:5984/dbname/d02bdee238b26628d1ce28f1c80313bb`\n  * Response: `{\"_id\":\"d02bdee238b26628d1ce28f1c80313bb\",\"_rev\":\"1-f07d272c69ca1ba91b94544ec8eda1b6\",\"title\":\"Lasagne\"}`\n  * Comments: Document ID is passed in the request.\n* To update a document:\n  * Request: `curl -H \"Content-type: application/json\" -X PUT http://localhost:5984/dbname/pasat -d \"{\\\"title\\\": \\\"Fizal\\\", \\\"dob\\\": \\\"01/01/1980\\\", \\\"_rev\\\": \\\"1-91b034b589017f930d12f7fec23be727\\\"}\"`\n  * Response: `{\"ok\":true,\"id\":\"pasat\",\"rev\":\"2-a294dbbe4a308e8586be9acdc527e6dc\"}`\n  * Comments: Both doc id and rev id is needed to update a document. Updating the document means updating the entire document. You cannot add a field to an existing document. You can only write an entirely new version of the document into the database with the same document ID.\n* To delete a document:\n  * Request: `curl -H \"Content-type: application/json\" -X DELETE http://localhost:5984/dbname/pasat?rev=2-a294dbbe4a308e8586be9acdc527e6dc`\n  * Response: `{\"ok\":true,\"id\":\"pasat\",\"rev\":\"3-fc5a45ddd7178ee92532095c38d66489\"}`\n  * Comments: Both doc id and rev id is needed to delete a document. Note that a new revision is created after deleting the document for replication purposes. \n* To upload attachments to a document:\n  * Request:\n* To make a copy of a document:\n  * Request: `curl -X COPY ????`\n* To request a UUID:\n  * Request: `curl -X GET http://localhost:5984/_uuids`\n  * Response: `{\"uuids\":[\"d02bdee238b26628d1ce28f1c803304f\"]}`\n* To compact a database:\n\n### Other Administration Tasks\n\n* UI Set up\n  * To make Futon accessible outside of the localhost: Futon -> configurations -> Bind_Address - change the value to 0.0.0.0\n* User Set up\n  * After set up, CouchDb runs in 'Admin Party Mode' (anyone accessing has full admin rights). To create an admin user and password, click on 'Fix me' link at the bottom right corner in Futon. The new admin user id should be visible under http://localhost:5984/_utils/database.html?_users.\n  * About Authentication: Couch has a pluggable authentication mechanism. Futon exposes a user friendly cookie-auth which handles login and logout. \n* Database Set up\n  * How to create our first database? Futon -> Overview -> Create database\n* Replication Set up\n  * How to replicate contents from DbX to DbY? Futon -> Tools -> Replicator -> Select from and to databases, and check the 'Continuous' checkbox. If the target db requires authentication, specify the url as http://username:pass@remotehost:5984/DbY. \n\n# Graph Databases\n\n## Concepts\n\n### Types of technologies in Graph space\n1. **Graph Databases** - Technologies used primarily for transactional online graph persistence, typically accessed directly in real time from an application. They are the equivalent of “normal” OLTP databases in the relational world.\n  * Available Graph Dbs: Dex, FlockDB (Twitter), HyperGraphDb, InfiniteGraph, Neo4j, OrientDB, Titan, Microsoft Trinity.\n2. **Graph Compute Engines** - Technologies used primarily for offline graph analytics, typically performed as a series of batch steps. They are lik eother technologies for analysis of data in bulk, such as data mining and OLAP.\n  * Available Graph Compute Engines: \n    * In-memory/Single machine: Cassovary\n    * Distributed: Pegasus, Giraph\n    \n\nGraph databases either use a native graph storage or a non-native storage back-end (say a relational db). The benefit of a native graph storage is that its purpose-built stack is engineered for performance and scalability. The benefit of a non-native graph storage is the ease of use in production by the operation teams.\n\n### Advantages of Graph Databases\n* Performance - In relation dbs, join across multiple tables is complex and tend to slow down with higher volume. In graph db, it is pretty much remains constant.\n* Flexible data model: Adding new nodes, subgraphs and relations is lot easier and less intrusive than in relational model. No need to change the schema or the existing queries.\n* Schemas are both rigid and brittle. Modifying schema often for business requirements is not an easy change. Creating a generic schema would end up with sparsely populated tables with many nullable columns. Vertical schemas add computational complexity in querying.\n* Recursive questions such as *“which customers bought this product who also bought that product?”* is easy to write in graph model compared to relational.\n* Pattern matching queries - e.g.?\n* Geospatial queries - e.g.,?\n\n### Graph Data Models \n1. Property graph model\n  * A property graph has the following characteristics:\n  * It contains nodes and relationships\n  * Nodes contain properties (key-value pairs)\n  * Relationships are named and directed, and always have a start and end node\n  * Relationships can also contain properties\n* 2. RDF Triples - http://en.wikipedia.org/wiki/Resource_Description_Framework\n* 3. Hypergraphs\n  * Graph Query Languages: Cypher (Neo4j), SPARQL (RDF query language), Gremlin (Imperative, path-based language) \n\n* Graph Db Applications\n* Recommendation Engines - e.g.,?\n* Geospatial apps - e.g.,? Datastructure behind geospatial processing is R-tree. http://en.wikipedia.org/wiki/R-tree\n\n\n## Neo4j\n\nhttp://nosql.mypopescu.com/tagged/neo4j\n\nRDBMS is optimized for aggregated data. Neo4j is optimized for highly connected data.\n\n* Cypher\n  * Get all node names -->  `START n=node(*) RETURN n;`\n  * Get all nodes with rels --> `START n=node(*) MATCH n-[r?]-() RETURN n, r;`\n  * Delete all nodes --> `START n=node(*) MATCH n-[r?]-() DELETE n, r;`\n  * Query index --> `START n=node:TASK_NAME('TASK_NAME:(\"Task1\", \"Task2\", \"Task3\")') RETURN n;`\n\n\n# Bibliography\n\n* Seven Databases in Seven Weeks\n* Getting Started with CouchDb\n* MongoDb - The Definitive Guide\n* Graph Databases - O'Reilly\n* http://nosql.findthebest.com/\n* http://www.slideshare.net/samof76/distributed-keyvalue-stores-featuring-riak"
  },
  {
    "id": 28,
    "title": "OOPS",
    "url": "/technology/oops.html",
    "content": "## Abstraction \nhides internal implementation level details and exposes only the relevant details of the class to the users..\n\n## Encapsulation \n\ncombines data (fields) and logically-related operations (methods). Abstraction is achieved through encapsulation.\n\n## Inheritance\n\nOverriding\n\n## Polymorphism\n\nis the characteristic of being able to assign a different meaning or usage to something in different contexts - specifically, to allow an entity such as a variable, a function, or an object to have more than one form. There are several different kinds of polymorphism.\n\n* Compile-time polymorphism - The call for the same method behaves differently based on the provided arguments.\n  * Function Overloading - methods with the same name but with different numbers of arguments or types of arguments.\n  * Operator Overloading -same operator having different meanings in different context(eg. +)\n* Runtime polymorphism\n  * Overriding\n\n## Mixins / Metaclasses\n\n\n\n## Dynamic Typing & Duck Typing\n\n## Bibliography\n* http://www.infoq.com/presentations/It-Is-Possible-to-Do-OOP-in-Java\n* http://butunclebob.com/ArticleS.UncleBob.PrinciplesOfOod"
  },
  {
    "id": 29,
    "title": "Operating Systems",
    "url": "/technology/os.html",
    "content": "# UNIX\n\n## Frequently used commands\n\n* Find and copy files created today\n`find /home/clstest -ctime -1 -exec cp {} /home/mohammo/CSW \\;`\n* Suppress error message from 'find' command\n`find . -name \"*\" -print 2>/dev/null`\n* Tar & untar directories with permissions intact\n```\ntar -cvpf test.tar /home/mohammo/test\ntar -xvpf test.tar /home/mohammo/test\n```\n* Exclude certain files in 'find' command\n```\nfind . -name \"*\" -not -name \"*.jar\" -print\nfind . -name \"*\" -not \\( -name \"*.jar\" -o -name \"*.tar\" \\) -print\n```\n* Search and replace with no hassle of escaping characters\n`echo \"/home/mohammo\" | sed -e \"s#/home/mohammo#/home/test#/g\"`\n* Search for text but only display their file names\n`find . -name \"*\" -type f -exec grep -l \"searchtext\" {} \\; -print`\n* Set operations - Complement (A-B)- below command prints all entries in file1 that are not in file2\n`comm -23 file1 file2`\n* Sorting files\n```\n sort file1 file2 | uniq  //Union of unsorted files \n sort file1 file2 | uniq -d  //Intersection of unsorted files \n sort file1 file1 file2 | uniq -u //Difference of unsorted files \n sort file1 file2 | uniq -u  //Symmetric Difference of unsorted files \n```\n* When a JVM process is running in Unix/Windows, how do I check how much memory is being currently used by that JVM?\n\n## VI Tips\n\n> Note: Anything between [ and ] denotes a command executed from within vi.\n\n* `[ !wc % ]` - opens a command shell and runs 'wc' on the current file open in vi. `%` means current file & `!` is called 'Bang'. Bang works best with non-interactive commands\n* `[ qa ]` close all files open\n* `[ ga ]` Show character info \n* `[ ls ]` List buffers\n* `[ % ]` Bracket matching\n"
  },
  {
    "id": 30,
    "title": "Patterns",
    "url": "/technology/architecture/patterns.html",
    "content": "[TOC]\n\n# Design Patterns\n\n## Adapter\nAlso called 'Wrapper' pattern\n\n### Object Adapter\n### Class Adapter\n## Bridge\n## Builder\n## Chain of Responsibility\n## Circular Buffer\n## Command\n## Composite\n## Decorator\n## Factory\n\nBeware of the ambiguity in the names - Static Factory Method (in Effective Java) is not the same as Factory Method (in GoF)\n\n### Factory Idiom - Not a pattern\n\n* (+) Dynamically creates objects based on some input parameters. Client refers to the product via common interface.\n* (+) Creates objects without exposing the instantiation logic to the client.\n* (+) Since client refers to the product via a common interface, factory can change the product implementation anytime after go-live.\n\n**Implementation Variations**\n\n#### Type 1: Parameterized Factory Method\nClassical switch-case/if-condition based factory method that takes a parameter to decide the type of product to return\n* (+) New products can be added without changing the client code.\n* (-) Tight coupling between factory and product implementations. In other words, Factory class needs to change for every new product. It violates the Open Close Principle.\n* (-) Sub-classing means replacing all the factory class references everywhere in the code.\n\n```\npublic class Factory{\n   public Product getProduct(String type){\n      if(type==1){\n          return new Product1();\n      } else if(type==2){\n          return new Product2();\n      } ....\n   }\n}\n```\n\n#### Type 2: Dynamic Class Registration\nKeep the map of key and product type away from the factory. It could be a properties file or statically registered in common registry class. Factory can dynamically create an instance of the product either by Class.forName() or using reflection.\n* (+) Factory class is not changed every time a product is added\n* (-) Using reflection impacts the performance\n\n```\npublic class Factory{\n   private Map<String, Class<Product>> map = new HashMap<>();\n\n   public void register(String type, Class<Product> klass){\n      map.put(type, klass);\n   }\n\n   public Product getProduct(String type){\n      Class<Product> klass = map.get(type);\n\n      //Class.forName() or Reflection\n   }\n} \n```\n\n### Static Factory Method\n\n* Creates objects without exposing the instantiation logic to the client. Client refers to the product via common interface. \n* The ability of static factory methods to return the same instance from repeated invocations allows classes to maintain strict control over what instances exist at any time. Such classes are called Instance-controlled classes.\n\n* (+) Overloaded constructors with similar parameter list can be replaced with static factory methods with meaningful names. E.g., `BigInteger.probablePrime(int, int, Random)` is better than `new BigInteger(int, int, Random)`\n* (+) Unlike constructors, there is no need to create a new object every time the method is invoked. E.g.,`public static Boolean valueOf(boolean b) {return b ? Boolean.TRUE : Boolean.FALSE;}`\n* (+) Unlike constructors, they can return objects of any sub-type of their return type. Helps hiding implementation classes and exposing only the interface. E.g., Non-instantiable class `java.util.Collections` hides 32 different implementations of `Collection` interface.\n* (+) It will also enhance the software maintainability and performance since the class of the returned object can be varied from release to release.\n* (+) Reduces the verbosity of creating parameterized type instances. e.g., `Map<String, List<Integer>> m = HashMap.newInstance();` (Generic Type Inference)\n* (+) Used in building internal-DSLs along with method chaining\n* (-) Classes without public/protected constructors cannot be sub-classed\n* (-) Static Factory methods are not easily distinguishable from other static methods\n\n\n### Factory Method\n\nDefines an interface for creating an object, but lets subclasses decide which class to instantiate. Factory Method lets a class defer instantiation to subclasses.\n\n* (+) Creates objects without exposing the instantiation logic to the client.\n* (+) Since client refers to the product via a common interface, factory can change the product implementation anytime after go-live.\n* (+) Used in builder pattern using which internal-DSLs are possible\n\n|    |    |\n| -- | -- |\n| {% img /technology/architecture/FactoryMethod.png %}| {% img /technology/architecture/FactoryMethodExample.png %}|\n\n### Abstract Factory\n\n* Nothing but an additional layer of abstract on top of Factory method pattern\n* Provide an interface for creating families of related or dependent objects without specifying their concrete classes.\n* Unlike in Factory method pattern, Factory class in this pattern can have one or more factory methods.\n* Type of Factory class is not known to client at compile-time.\n\n> Read Oracle Certified Professional Java SE 7 - Programmer Exams - Page 135 for difference b/w Factory and Abstract Factory\n\n\n* (+) Addresses the concerns in both the factory method implementations.\n* (-) Factory cannot be a singleton\n* (-) Relatively difficult to implement\n* (-) A new factory has to be created for every new product\n\n {% img /technology/architecture/AbstractFactory.png %}\n\n## Flyweight\n## Interpretor\n## Iterator\n## Mediator\n## Memento\n## Observer\n## Prototype\n## Proxy\n### Dynamic Proxy\nMockito, Spring container\n#### Virtual Proxy\n#### Counting Proxy\n\n## Singleton\n\n* Why Singleton? Can I not achieve the same in a public static class & method?\n* All-static method class CANNOT implement an interface.\n* All-static method class makes itself extendable. Singleton class DOESN'T allow that.\n* Lazy loading singletons - http://crazybob.org/2007/01/lazy-loading-singletons.html\n\n**Implementation Variations**\n\n* **Early initialization**\n  * Type 1 - public static final field – Not serializable until all the instance fields are transient and override readResolve() method to return the singleton instance.\n  * Type 2 - private static final field & factory method – Same issues as above. At least gives flexibility to decide whether the class should be singleton or not.\n  * Type 3 - Enum – No serialization and reflection issues.\n* **Lazy initialization**\n  * public static synchronized getInstance() – Performance impact due to acquiring lock for every call\n  * DCL (Double-checked locking) – Broken except for 2 conditions\n    * Instance field is declared volatile – Works only from JDK 1.5 and above\n    * Class is immutable – All fields are final. Reading & Writing references to immutable objects are atomic.\n  * Use external container like Spring/Guice or custom factory to manage the number of instances created\n* **Issues with Singleton**\n  * Single threaded environment\n    * Hard to unit test the class – especially when it holds state like counter, etc.\n      * Work around: package protect constructor and reset state\n    * Potentially allows multiple version - Via Serialization or Reflection\n      * Work around: override readResolve() or use enum model\n    * Violates SRP (Single Responsibility Principle)\n      * Work around: Use external container like Spring or some kind of registry/factory to manage the number of instances created\n  * Multi threaded environment\n    * Double-checked locking anti-pattern\n      * Work around: use volatile field or make class immutable\n\n\n### Type 1 - Early init with public static final field\t\n<pre>\npublic class Singleton{\n   <span style=\"color:red\">public static final</span> Singleton INSTANCE = new Singleton();\n   private Singleton(){}\n}\n</pre>\n\n### Type 2 - Early init with private static field & factory method\n```\npublic class Singleton{\n   private static final Singleton INSTANCE = new Singleton();\n   private Singleton(){}\n\n   //static factory method\n   public static Singleton getInstance(){\n     return INSTANCE;\n   }\n}\n```\n\n### Type 3 - Early init via Enum\n<pre>\n public <span style=\"color:red\">enum</span> Singleton{\n    INSTANCE; //By default, public static final\n }\n</pre>\n\n### Type 4 - Lazy init - not thread-safe\n<pre>\npublic class Singleton{\n   private static Singleton instance;\n   private Singleton(){}\n\n   //static factory method\n   public static Singleton getInstance(){\n     <span style=\"color:red\">\n     if(instance==null){\n        instance = new Singleton();\n     }\n     return instance;\n     </span>\n   }\n}\n</pre>\n\n### Type 5 - Lazy init - Thread-safe but worst performing\n<pre>\n public class Singleton{\n   private static Singleton instance;\n   private Singleton(){}\n\n   //static factory method\n   public <span style=\"color:red\">synchronized</span> static Singleton getInstance(){\n     if(instance==null){\n        instance = new Singleton();\n     }\n     return instance;\n   }\n}\n</pre>\n\n###  Type 6 - Lazy init - Thread-safe via Double-checked lock (BROKEN)\n<pre>\n public class Singleton{\n   private static Singleton instance;\n   private Singleton(){}\n\n   public static Singleton getInstance(){\n   <span style=\"color:red\">\n     if(instance==null){ //check\n        synchronized(Singleton.class){ //lock\n           if(instance==null){//check</span>\n              instance = new Singleton();\n           }\n        }\n     }\n     return instance;\n   }\n}\n</pre>\n\n###  Type 7 - Lazy init - Thread-safe via DCL and volatile instance (works in Java 5+)\n<pre>\npublic class Singleton{\n   private static <span style=\"color:red\">volatile</span> Singleton instance;\n   private Singleton(){}\n\n   public static Singleton getInstance(){\n     if(instance==null){ //check\n        synchronized(Singleton.class){ //lock\n           if(instance==null){//check\n              instance = new Singleton();\n           }\n        }\n     }\n     return instance;\n   }\n}\n</pre>\n\n## State\n## Strategy\n## Reactor\n\n## Recycle Bin\nhttp://c2.com/cgi/wiki?RecycleBin\nYou can also find recycle bins in Java, such as in the thread pooling that you can configure using classes like ScheduledThreadPoolExecutor and ThreadPoolExecutor.\n\n## Template Method\n\n## TransferObject\n\n## ValueObject\n\n## Visitor\n\n# Anti Patterns\n\n> Excerpts from book 'Refactoring: Improving the Design of Existing Code')\n\n* Large class\n* Long parameter list\n* Divergent Change\n  * Occurs when one class is commonly changed in different ways for different reasons. If you look at a class and say, \"I have to change these four methods every time there is a new financial instrument,\" you likely have a situation in which two objects are better than one. That way each object is changed only as a result of one kind of change. Any change to handle a variation should change a single class, and all the typing in the new class should express the variation. To clean this up you identify everything that changes for a particular cause and use `Extract Class` to put them all together.\n* Shotgun Surgery\n  * Similar to divergent change but is the opposite. You whiff this when every time you make a kind of change, you have to make a lot of little changes to a lot of different classes. When the changes are all over the place, they are hard to find, and it's easy to miss an important change. In this case you want to use `Move Method` and `Move Field` to put all the changes into a single class. If no current class looks like a good candidate, create one. Divergent change is one class that suffers many kinds of changes, and shotgun surgery is one change that alters many classes.\n\n\n# Concurrency Patterns\n\n> Refer \"Software Architecture Design Patterns\" book\n\n## Active Object\n## Balking Pattern\n## Barrier\n## Consistent Lock Order\n## Critical Section\n## Disruptor\n## Guarded Suspension\n## Monitor Object\n## Producer/Consumer pattern\n## Read-Write Lock\n\n# Architectural Patterns\n\n## Active Record\n## Business Delegate\n## Data Access Object (DAO)\n## Dependency Injection or IOC\n\n(http://www.martinfowler.com/articles/injection.html) Decoupling the implementation dependencies from the application class to a plug-in model. Types of Dependency injections\n\n* Constructor injection\n* Setter injection\n* Interface injection\n\n## Facade\n\n### Session Facade\n\n### Wrapper Facade\n\n## Front Controller\n\n## Interceptor\n\n## Mock object\n\n\n\n## Model View Controller \nMVC & MVC2\n\n## Naked objects\n\n## Null object\n\n## Service Locator\n\n## Token Synchronization\n\n\n\n# Bibliography\n\n* Design Patterns\n  * http://c2.com/cgi/wiki?ExecuteAroundMethod \n  * http://c2.com/cgi/wiki?CodeSmell\n  * http://c2.com/cgi/wiki?LawOfDemeter\n  * http://c2.com/cgi/wiki?TooManyParameters\n  * http://c2.com/cgi/wiki?FeatureEnvySmell\n  * http://www.techjava.de/topics/2008/01/java-class-loading/"
  },
  {
    "id": 31,
    "title": "Presentation Skills",
    "url": "/softskills/presentation.html",
    "content": "# Excerpts from book: Presentation Zen\n\n* Creative\n* **Pecha Kucha** (means chatter) - 20 slides in 20 seconds per slide - Total 6 min 40 secs - if you can’t tell the essence of your story in less than seven minutes, then you probably shouldn't be presenting anyway.\n* Planning - jot down ideas on a piece of paper first\n* Fundamentals questions to answer during planning stage\n  * How much time do I have?\n  * What’s the venue like?\n  * What time of the day will I be speaking?\n  * Who is the audience?\n  * What is their background?\n  * What do they expect of me?\n  * Why was I asked to speak?\n  * What do I want them to do?\n  * What visual medium is most appropriate for this particular situation and audience?\n  * What is the fundamental purpose of my talk?\n  * What’s the story here?\n  * And this is the most fundamental question of all, stripped down to its essence: What is the core point?\n* Summarizing all the above, bottom line questions to answer are What is your point? Why does it matter?\n* No more than 6 or 7 words per slide\n\n\n# Excerpts from book: Speaking Powerpoint\n\n* 3 steps to prepare a presentation\n  1. Prepare story board - before even opening the powerpoint, answer the following first\n    * What information the reader needs?\n    * In what order my slides will be shown?\n    * What evidence do I need to support?\n  * Prepare slides. After step 1, each slide has a single message that supports the overall argument.\n  * Design the slides: Understand what needs to be highlighted in the slides.\n\n## Difference between ballroom-style and boardroom-style presentations\n\n###\t Ballroom-style\tpresentation\n\n* General advices\n  * 10 slides, 20 minutes, minimum of 30-point font\n  * 7 bullets per slide, 7 words per bullet\n  * Don't use bullets\n  * Use a story telling approach\n  * Use a stock photograph that bleeds off the edges of the slide\n* Easily distracted large audience who may not be motivated.\n* Less text in presentation. No printed handout slides.\n* Without the speaker, the slides make little sense.\n\n###\t Boardroom-style presentation\n* Motivated senior management audience\n* Reader requires more details including text and statistical data to study the slide up close.\n* It may be a \n  * reading deck - standalone at a computer screen\n  * discussion deck - printed and discussed in a team meeting\n  * briefing deck - presented to a roomful of decision-makers"
  },
  {
    "id": 32,
    "title": "Productivity",
    "url": "/softskills/productivity.html",
    "content": "## Excerpts from book: The Secret to Peak Productivity by Tamara Myles\n\n* Maslow's Pyramid\n  1. Physiological\n  2. Safety\n  3. Love and Belonging\n  4. Esteem\n  5. Self-actualization\n* Peak Productivity Pyramid System\n  1. Physical Organization\n  2. Electronic Organization\n  3. Time Management\n  4. Activity-Goal Alignment\n  5. Possibility\n* Peak productivity provides a framework, but it is an iterative process. One may need to revisit the previous steps to fine-tune according their current situation.\n\n### 1) Physical Organization\n\n* 3 TOs of Sorting Documents\n  * To Keep (e.g., bank statements, tax documents, etc.)\n  * To Toss (e.g., spam mails) - Either recycle or shred \n  * To Do (e.g., pay bills)\n* Pick the right tools for organizing. e.g., files, folders, magazine holders, etc.\n* Separate personal and business documents\n* Sort the 'To Keep' documents categorically or chronologically. \n* Don't use miscellaneous category in sorting.\n* Create a recurring event to sort and file documents\n\n### 2) Electronic Organization\n* Email management\n  * Check emails only at allotted times (3 or 4 times a day only)\n  * Unless an email takes less than a minute to reply, reply them in bulk at allotted times.\n\n### 3) Time Management\n\n* 3 Ps of time management\n  1. Plan\n    * Plan the week ahead on Sunday evenings \n    * Maintain a single calendar and a single TODO list\n  * Prioritize\n    * Prioritize tasks using Urgent/Important Matrix.\n  * Perform\n    * Focus on doing the right thing instead of doing everything right\n    * Follow the Pomodoro 25-minute rule.\n    * Avoid multitasking and distractions.\n    * Stop stealing time. e.g., checking emails during break.\n\n### 4) Activity-Goal Alignment\n\n* Define short term and long term goals\n* Measure the time spent towards the goal\n* Structure your weekly activities to work towards the goal\n* A vision without a plan is just a hallucination - Will Rogers\n* The indispensable first step to getting thing you want out of life is this: Decide what you want - Ben Stein\n* Define SMART Goals\n  1. Specific\n  * Measurable\n  * Attainable\n  * Relevant\n  * Timely\n* 6 steps of goal setting\nCommit\n  1. Understand - why is it important\n  * Create goals - Find partners to work with\n  * Break down goals into small tasks\n  * Schedule to work on the tasks\n  * Assess and Re-assess periodically if the goals are still important\n* Discipline and Attitude\n  * Discipline is the bridge between goals and accomplishments - Jim Rohn\n  * Books on discipline\n    * 7 habits of highly effective people - Stephen Covey\n    * Peak: How great companies get their mojo from Maslow\n    * Mindset: The new psychology of success\n  * Books on attitude\n    * Happiness at work\n    * The Happiness project\n    * Peak: How great companies get their mojo from Maslow\n    * The art of possibility\n"
  },
  {
    "id": 33,
    "title": "R Programming",
    "url": "/datascience/r.html",
    "content": "[TOC]\n\n## Data Types\n\n### Basic Data Types\nR has five basic or “atomic” classes of objects:\n\n1. **character**\n* **numeric** (real numbers) \n  * Numbers in R as numeric objects by default. (*Double precision real numbers*)\n  * `Inf` represents infinity. \n  * `NA` & `NaN` represents an undefined value and not a number.\n    * `is.na()` and `is.nan()` are used to test objects.\n    * `NA` values have a class also, so there are integer `NA`, character `NA`, etc.\n    * A `NaN` value is also `NA` but the converse is not true.\n  * Attributes of an object like length and other metadata can be access using the `attributes()` function.\n* **integer** -\n `1` is a numeric object. `1L` is an integer.\n* **complex**\n* **logical** (True/False)\n\n### Complex Data Types\n\n#### Vectors\nThe most basic object is a vector. \n*  A vector can only contain objects of the same class.\n* BUT: The one exception is a list, which is represented as a vector but can contain objects of\ndifferent classes (indeed, that’s usually why we use them)\n* Empty vectors can be created with the `vector()` function.\n* Vector examples\n```\n> x <- c(0.5, 0.6) ## numeric\n> x <- c(TRUE, FALSE) ## logical\n> x <- c(T, F) ## logical\n> x <- c(\"a\", \"b\", \"c\") ## character\n> x <- 9:29 ## integer\n> x <- c(1+0i, 2+4i) ## complex\n```\n\n* Lists are a special type of vector that can contain elements of different classes.\n```\n> x <- list(1, \"a\", TRUE, 1 + 4i) \n> # mixed types allowed, lists are recursive, lists are vectors\n> alist <- list(c(\"a\", \"b\", \"c\"), c(1,2,3,4), c(8e6, 5.2e9, -9.3e7))\n> alist[[1]] # return one column\n> alist[1] # extracts a list\n> alist[[3:2]] # gets 2nd element from 3rd vector of the list (5.2e9)\n> is.list(alist) #TRUE\n> is.vector(alist) #TRUE\n```\n\n* **Mixing Objects**  \nWhen different objects are mixed in a vector, *coercion* occurs so that every element in the vector is\nof the same class.\n```\n> y <- c(1.7, \"a\") ## character\n> y <- c(TRUE, 2) ## numeric\n> y <- c(\"a\", TRUE) ## character\n```\n\n* **Explicit Coercion**  \nObjects can be explicitly coerced from one class to another using the `as.*()` functions, if available.\n```\n> x <- 0:6\n> class(x)\n[1] \"integer\"\n> as.numeric(x)\n[1] 0 1 2 3 4 5 6\n> as.logical(x)\n[1] FALSE TRUE TRUE TRUE TRUE TRUE TRUE\n> as.character(x)\n[1] \"0\" \"1\" \"2\" \"3\" \"4\" \"5\" \"6\"\n```\n* **Nonsensical coercion results in NAs**\n```\n> x <- c(\"a\", \"b\", \"c\")\n> as.numeric(x)\n[1] NA NA NA\nWarning message:\nNAs introduced by coercion\n> as.logical(x)\n[1] NA NA NA\n> as.complex(x)\n[1] 0+0i 1+0i 2+0i 3+0i 4+0i 5+0i 6+0i\n```\n* **Matrices**\nMatrices are vectors with a *dimension* attribute. The dimension attribute is itself an integer vector of\nlength 2 (nrow, ncol).\n```\n> m <- matrix(nrow = 2, ncol = 3) \n> m\n [,1] [,2] [,3]\n[1,] NA NA NA\n[2,] NA NA NA\n> dim(m)\n[1] 2 3\n> attributes(m)\n$dim\n[1] 2 3\n```\n* **cbind-ing and rbind-ing**\nMatrices can be created by column-binding or row-binding with `cbind()` and `rbind()`.\n```\n> x <- 1:3\n> y <- 10:12\n> cbind(x, y)\n x y \n[1,] 1 10\n[2,] 2 11\n[3,] 3 12\n> rbind(x, y) \n [,1] [,2] [,3]\nx 1 2 3\ny 10 11 12\n```\n\n#### Factors\n* Factors are nothing but enumeration data types used to represent categorical data.\n* Can be ordered or unordered.\n* Factor can be thought of as an integer vector where each integer has a *label*. \n```\n> x <- factor(c(\"yes\", \"yes\", \"no\", \"yes\", \"no\")) \n> x\n[1] yes yes no yes no\nLevels: no yes\n> table(x) \nx\nno yes \n2 3\n> unclass(x)\n[1] 2 2 1 2 1\nattr(,\"levels\")\n[1] \"no\" \"yes\"\n```\n\n\n#### Data Frames\n* A special type of list where every list is of same length.\n* All columns in data frame must have names\n* * Unlike matrices, data frames can store different classes of objects in each column.\n* To create - `read.table()` or `read.csv()`\n* To convert to a matrix - `data.matrix()`\n```\n> read.table() # space is the default delimiter\n> read.csv() # by default expects a file header\n> read.csv2()\n> read.delim()\n> read.delim2()\n> x <- data.frame(foo = 1:4, bar = c(T, T, F, F)) \n> x\n foo bar\n1 1 TRUE\n2 2 TRUE\n3 3 FALSE\n4 4 FALSE\n> nrow(x)\n[1] 4\n> ncol(x)\n[1] 2\n```\n\n* `data.frame()` # create data frame or table e.g., `test.data.frame<-data.frame(id=c(1,2,3,4,5),name=c(\"a\",\"b\",\"c\",\"d\",\"e\"))`\n* `edit(framename)` # edit the content of the table\n* `str(frame)` # prints the structure and data types of the data frame\n* `names(framename)` – prints the column names\n* `dataframe[index.ROW, index.COLUMN]`\n* `dataframe[[1]]` # returns the first column as a vector\n* `dataframe[1]` # returns the first column wrapped in a data frame\n* `dataframe[c(1,3)]` # returns the 1st and 3rd column wrapped in a data frame\n* `dataframe[1:3,]` # displays all columns but first 1-3 rows only\n* `is.data.frame(framename)` #checks if an object is a data frame\n\n\n## Basics Statistic Functions\n*\t`mean(x)` # x is a vector\n*\t`median(x)`\n*\t`sd(x)`\n*\t`var(x)`\n*\t`cor(x,y)`\n*\t`cov(x,y)`\n*\t`lapply(dataframe, function)` # Apply function like mean/median over a list/dataframe\n\n## Graphs\n*\t`plot(x,y)` # Scatter plot. Only numeric vectors or dataframes are allowed.\n*\t`barplot()` - Bar Chart\n*\t`boxplot()` - Box Plot. Provides a quick visual summary of a dataset. Thick line in middle is the median. Box identifies the 1st(bottom) and 3rd(top) quartiles.\n* `hist(x)` -\tHistogram. Groups data into bins\n\n\n##Appendix\n\n###Command Reference \n* `ls()` or `ls(all.names = TRUE)` # Lists all variables/objects defined in the * session\n* `setwd(“c:/xyz”)` # sets working directory\n* `getwd()` # Gets working directory\n* `runif(8)` # generates 8 random numbers\n* `x <- 9` # assigns 9 to object x in workspace\n* `x` # prints the value of x\n* `rm(x)` # removes the object x\n* `rm(list=ls())` # removes all objects in workspace\n* Save & Load (Binary)\n  * `save()` # saves all objects to default file .RData. Objects still exist in * `memory` (binary format)\n  * `save(obj1, obj2, file=”filename”)`\n  * `load(“filename”)` # loads from file to memory\n* Save & Load (Text)\n  * `write.table(obj1, file=”filename”)` # only 1 obj at a time\n  * `load.table()`\n\n###Packages\n* `install.packages(c(\"ggplot2\", \"devtools\", \"KernSmooth\")` # install the collection of packages from CRAN\n* `library()`        #list all available packages\n* `library(package)` # loads package on to memory\n* `require(package)` # loads package on to memory. Used in scripts. Returns loading status as boolean.\n* `detach(package:name)` # unloads package from memory.\n\n###Help \n* `?func`           # open help page on function 'func'\n* `help(func)`      # same as above\n* `apropos(\"foo\")`  # list all functions containing string foo\n* `example(foo)`    # show an example of function foo\n* `vignette()`      # show available vignettes on installed packages\n* `vignette(\"foo\")` # show specific vignette\n\t\t\n\n# Bibliography\n\n* R Inferno\n* Software for Data Analysis - Programming with R (http://www.springer.com/statistics/computational+statistics/book/978-0-387-75935-7)\n* The R book (http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470973927.html)\n* The Art of R Programming \n* R in Action\n* Ref Cards\n  * http://cran.r-project.org/doc/contrib/Short-refcard.pdf\n  * http://www.statmethods.net/interface/help.html\n* Tutorials\n  * http://www.johndcook.com/R_language_for_programmers.html\n  * http://cran.r-project.org/doc/manuals/R-intro.pdf\n  * http://www.decisionsciencenews.com/?p=261\n  * http://www.r-tutor.com/r-introduction/data-frame\n  * http://tryr.codeschool.com/levels/2/challenges/1"
  },
  {
    "id": 34,
    "title": "RDBMS Products",
    "url": "/technology/rdbms-products.html",
    "content": "[TOC]\n\n# DB2\n\n## Basics\n\n### Special tables\n\n* Global temporary tables - with or without logging - http://www.ibm.com/developerworks/data/library/techarticle/dm-0912globaltemptable/\n* MDC Tables\n\n### Views\n\n* A view is an alternate way of representing data that exists in one or more tables. \n* A view can include some or all of the columns from one or more tables. It can also be based on other views. \n* A view is the result of a query on one or more tables. A view looks like a real table, but is actually just a representation of the data from one or more tables. \n* A view is a logical or virtual table that does not exist in physical storage. \n* It is an efficient way of representing data without needing to maintain it. When the data shown in a view changes, those changes were a result of changes made to the data in the tables themselves. \n* Views are used to see different presentations of the same data. Views are a way to control access to sensitive data. Different users can have access to different columns and rows based on their needs. \n* When the column of a view is directly derived from the column of a base table, that view column inherits any constraints that apply to the base table column. For example, if a view includes a foreign key of its base table, insert and update operations using that view are subject to the same referential constraints as is the base table. \n* Also, if the base table of a view is a parent table, delete and update operations using that view are subject to the same rules as are delete and update operations on the base table. \n* A view can derive the data type of each column from the result table, or base the types on the attributes of a user-defined structured type. This is called a typed view. Similar to a typed table, a typed view can be part of a view hierarchy. \n* A subview inherits columns from its superview. The term subview applies to a typed view and to all typed views that are below it in the view hierarchy. A proper subview of a view V is a view below V in the typed view hierarchy. \n* A view can become inoperative (for example, if the base table is dropped); if this occurs, the view is no longer available for SQL operations.\n* Views CAN contain the following: Aggregate functions and groupings, Joins Other views, distinct clause \n* Views CANNOT contain the following: select into, compute clause, union, order by.\n\nTypes of Views\n* Horizontal view - Slices the source table horizontally to create the view. All of the columns of the source table participate in the view, but only some of its rows are visible through the view. Horizontal views are appropriate when the source table contains data that relates to various organizations or users. They provide a \"private table\" for each user, composed only of the rows needed by that user. \n* Vertical view - TODO\n* Indexed views - TODO \n\n## Command Line Options\n\n* Enter command prompt by typing 'db2'\n* To take input from a file and output to a file: `db2 -tvf db2input.txt > db2output.txt &`\n* To connect to database: `CONNECT to NYCMRDI4 USER cmdrinfr USING s0mepassw0rd`\n* Command to list the databases: `list db directory`\n* Command to list the tables: `list db tables`\n* Read input from file: `db2 -tvf filename`\n* Db2advis - command to advice indexes on sql\n* How to find out if statistics on a table or schema is up-to-date?\n  * If CARD is -1 or STATS_TIME is null or far in the past, then statistics needs to be updated. Non-negative number on CARD denotes the number of rows on the table.\n\n``` sql\nSELECT CARD, STATS_TIME FROM SYSCAT.TABLES WHERE TABNAME='MARGININFO'\n```\n\n  * If NLEAF, NLEVELS & FULLKEYCARD is -1 or STATS_TIME is null or far in the past, then statistics needs to be updated on that index\n\n``` sql\nSELECT NLEAF, NLEVELS, FULLKEYCARD, STATS_TIME, i.* FROM SYSCAT.INDEXES i WHERE TABSCHEMA='CMDRPROD' and TABNAME='MARGININFO'\n```\n  * Via DB2 Command - `reorgchk update statistics on SCHEMA CMDRPROD`\n* Reorg - TODO\n* Runstats - Execute to collect statistics of the table and its indexes to help optimizer choose the best data-access plan\n\n``` sql\nRUNSTATS ON TABLE schema.table WITH DISTRIBUTION AND DETAILED INDEXES ALL;\nRUNSTATS ON TABLE schema.table; \n```\n\n(If reorg is run, then execute runstats also)\nExecute Runstats : after creating an index, after hanging the prefetch size, after executing reorg. Also execute it at regular intervals to keep the statistics current.\n\n* Check transaction log usage : `call sp.xlogfull()`\n* Row count on table without full table scan\n\n``` sql\nSELECT tabname TableName, card RowCount FROM syscat.tables WHERE TABNAME='tableName'\n```\n\n* Truncate a table without transaction logging\n\n``` sql\nLOAD FROM /dev/null of del REPLACE INTO YourTable\n```\n\nThis operation is fully recoverable. Note that on Windows systems, you have to replace `/dev/null` by `NUL`.\n\nOR\n\n``` sql\nALTER TABLE YourTable ACTIVATE NOT LOGGED INITIALLY WITH EMPTY TABLE\n```\n\nCauses all data currently in table to be removed. Once the data has been removed, it cannot be recovered except through use of the RESTORE facility. If the unit of work in which this alter statement was issued is rolled back, the table data will not be returned to its original state. \nWhen this action is requested, no DELETE triggers defined on the affected table are fired. Any indexes that exist on the table are also deleted.\n\n* Dummy select\n\n``` sql\nselect current timestamp from sysibm.sysdummy1;\n```\n\n## Advanced Concepts\n\n### Tablespaces\n\nTable spaces are logical objects used as a layer between logical tables and physical containers. Containers are where the data is physically stored in files, directories, or raw devices. When you create a table space, you can associate it to a specific buffer pool (database cache) and to specific containers.\n\n#### Default Tablespaces\n\nThere are 3 table spaces created automatically when a database is created: \n\n1. **Catalog (SYSCATSPACE)**: The catalog and the system temporary space can be considered system structures, as they are needed for the normal operation of your database. The catalog contains metadata (data about your database objects) and must exist at all times. \n* **System temporary space (TEMPSPACE1)**: is the work area for the database manager to perform operations, like joins and overflowed sorts. There must be at least one system temporary table space in each database. \n* **Default user table space (USERSPACE1)**: This is created by default, but you can delete it. \nTo create a table in a given table space, use the CREATE TABLE statement with the IN table_space_name clause. If a table space is not specified in this statement, the table will be created in the first user created table space. If you have not yet created a table space, the table will be created in the USERSPACE1 table space. \n\n#### Tablespace Types\n\n1. **System-managed space (SMS)**: This type of table space is managed by the operating system and requires minimal administration. This is the default table space type. \n2. **Database-managed space (DMS)**: This type of table space is managed by the DB2 database manager, and it requires some administration\n\n\n### Buffer Pools \n\nA buffer pool is an area in physical memory that caches the database information most recently used. Without buffer pools, every single piece of data has to be retrieved from disk, which is very slow. Buffer pools are associated to tables and indexes through a table space. A buffer pool is an area in memory where all index and data pages other than LOBs are processed.DB2 retrieves LOBs directly from disk. Buffer pools are one of the most important objects to tune for database performance. \n\n### Concurrency\n\n#### Issues\n* Lost updates \n* Access to uncommitted data (only with UR) \n* Non-repeatable read (only with UR & CS) \n* Phantom read phenomenon (only wit UR, CS & RS) \n\n#### Isolation levels \n* Repeatable Read(RR)\n* Read Stability (RS)\n* Cursor Stability (CS)\n* Uncommitted Read (UR)\n\n#### Lock Escalation \nA lock escalation occurs when the number of locks held on rows and tables in the db equals the percentage of the locklist specified by the 'maxlocks' db config param. To reduce the no. of locks, db manager begins converting many small row/block level locks to table locks for all active tables, starting from any locks on LOBs or VARCHARs. Then the table with the next highest no. of locks and so on, until the no. of locks held is decreased to about half of the value specified by 'maxlocks' Exclusive Lock Escalation An exclusive lock escalation is a lock escalation in which the table lock acquired is an 'exclusive lock'. Lock escalations reduce concurrency. Conditions that might cause lock escalations should be avoided. \n\n### DB Federation\n\nDatabase federated support in DB2 allows tables from multiple databases to be presented as local tables to a DB2 server. The databases may be local or remote; they can also belong to different. \n\nDB2 uses NICKNAME, SERVER, WRAPPER, and USER MAPPING objects to implement federation. \n\n#### DB Partitioning\n\n* DPF(DB partioning feature) lets you partition your database across multiple servers or within a large SMP server. This allows for scalability, since you can add new machines and spread your database across them. That means more CPUs, more memory, and more disks from each of the additional machines for your database! Partitioning is a concept that applies to the database, not the instance; you partition a database, not an instance.\n* In a partitioned environment SYSCATSPACE is not partitioned, but resides on one partition known as the catalog partition. The partition from which the CREATE DATABASE command is issued becomes the catalog partition for the new database. All access to system tables must go through this database partition.\n* Each buffer pool in a DPF environment holds data only from the database partition where the buffer pool is located. \n\n#### Partitioning Types\n\n* Row-wide partitioning - TODO\n* Column-wide partitioning - TODO\n\n#### DB Replication\n\nHADR - High Availability Database Replication (from version 9.7) TODO\n\n\n# Oracle\nhttp://download-west.oracle.com/docs/cd/A87860_01/doc/server.817/a76992/toc.htm \n\n* **Optimizers CBO** (Cost-based optimizers) depends on the statistics stored in the Data Dictionary. This approach optimizes for best throughput **RBO** (Rule based optimizers) - This approach optimizes for best response time. \n\n**Data dictionary**- stores statistics about columns, tables, clusters, indexes, and partitions for the CBO. DBMS_STATS statement is used to gather the statistics\n\n# Sybase\n\n## Temporary Database: tempdb\n\nThe tempdb database is a special Sybase supplied database that comes in each server. Data in tempdb is not permanent. The tempdb database is cleared each time the server reboots. Any queries which do any sort of sort operation implicitly use tempdb. These queries include select statments with group by's or order by's. Be careful, if you select a large set of rows and use an order by or group by clause, you query may fail because tempdb isn't big enough. \n\nThe system administrator can extend the size of tempdb Local variables denoted as `@varname` Global variables\n\n* `@@rowcount` - Holds the number of rows returned by the last Transact-SQL statement. Be careful, almost any statement will set this. Even an \"if\" statement which checks it's value. For example:\n``` sql\nselect * from pubs where ....\nif @@rowcount = 0 /* set to 1 after this */\nprint \"no rows returned\"\n```\n\n* `@@error` - Holds status of last statement executed. Zero is success. Once again almost any statement sets this, so use it's value immediately (or save it in a local variable).\n* `@@servername` - The name of the Sybase dataserver.\n* `@@version` - What version of the Sybase server you are using\n\n## Locks\n\nSybase locks pages (2048 bytes) not rows. This is a trade off between the speed of managing locking and level of contention that occurs at runtime.\n\n### Types of locking\n\n1. All Page locking - locks data pages and index pages\n* Data Page only locking (from v11.9)\n* Row level locking (from v11.9)\n\nHow Data pages work in Sybase ASE? http://www.faqs.org/faqs/databases/sybase-faq/part5/ (Page Contention)\n\nHeap Tables Tables with no clustered index.\n\nUpdate statistics 'update statistics ' is the equivalent of runstats in db2 Suppose I have varying lengths of character strings none of which should exceed 50 characters. Is there any advantage of last_name varchar(50) over this last_name varchar (255)? That is, for simplicity, can I just define all my varying strings to bevarchar(255) without even thinking about how long they may actually be? Is there any storage or performance penalty for this. There is no performance penalty by doing this but as another netter pointed out: If you want to define indexes on these fields, then you should specify the smallest size because the sum of the maximal lengths of the fields in the index can't be greater than 256 bytes.\n\nRepeatable Read By default, reads (select) are not locked. Sometimes, this is not appropriate. If you need to guarantee that a selected row doesn't change once read during a transaction, use the select with holdlock. eg.SELECT @lcl_au_id=au_id HOLDLOCK FROM authors sp_recompile One common problem occurs when stored procedures are first executed when the tables they will be accessing are largely empty. The query plans will generally prefer to scan the tables instead of using indexes. As the tables fill with data, performance can significantly degrade.\n\nThe \"sp_recompile\" command can be used to fix this problem: sp_recompile {table_name} This will set a flag in each stored procedure that needs to be recompiled (i.e, that references the specified table). The next time one of these stored procedures is invoked, it will automatically be recompiled Note 'truncate table' and 'bcp' commands bypass triggers.\n\n* How to select first/last/max per group in SQL : http://www.xaprb.com/blog/2006/12/07/how-to-select-the-firstleastmax-row-per-group-in-sql/\n* How to identify the performance order (Big-O notation) of a query\n* How query execution order works when a SQL has sub-queries in it?\n\n# Bibliography\n* DB2\n  * More details on : http://publib.boulder.ibm.com/infocenter/db2luw/v8/index.jsp?topic=/com.ibm.db2.udb.doc/core/r0010410.htm\n  * Command line reference: ftp://ftp.software.ibm.com/ps/products/db2/info/vr8/pdf/letter/db2n0e80.pdf\n  * DB2 System command: http://www3.software.ibm.com/ibmdl/pub/software/dw/dm/db2/dm-0406qi/systemCommands.pdf\n* Sybase\n  * http://www.faqs.org/faqs/databases/sybase-faq/part1/ \n  * http://www.lcard.ru/~nail/sybase/perf/66.htm \n  * http://www.benslade.com/tech/OldIntroToSybase/\n"
  },
  {
    "id": 35,
    "title": "DBMS Concepts",
    "url": "/technology/rdbms.html",
    "content": "[TOC]\n\n# Concepts\n\n## Keys\n\n> Refer to SQL Tips and Techniques-2002\n\n* **Primary Key***\n  * PK is an attribute or a set of attributes that uniquely identify a specific instance of an entity. \n  * PKs enforce entity integrity by uniquely identifying entity instances. \n* **Candidate Key** - an entity can have more than one attribute that can serve as a primary key. Any key or minimum set of keys that could be a primary key is called a candidate key. (Eg. EmpId, SSN, Name of an Employee entity) \n* **Alternate Key** - Rest of the non-primary keys are called alternate keys \n* **Composite Key** - A primary key made up of more than one attribute is known as a composite key \n* **Foreign Key**\n  * is an attribute that completes a relationship by identifying the parent entity. \n  * Foreign keys provide a method for maintaining integrity in the data (called referential integrity) and for navigating between different instances of an entity. \n\n**Difference between a primary key and a unique key?**\nBoth primary key and unique enforce uniqueness of the column on which they are defined. But by default primary key creates a clustered index on the column, whereas unique key creates a nonclustered index by default. Another major difference is that, primary key doesn't allow NULLs, but unique key allows one NULL only. Identity columns & default values\n\n## Integrity\n\n* **Data integrity** - means, in part, that you can correctly and consistently navigate and manipulate the tables in the database. There are two basic rules to ensure data integrity; entity integrity and referential integrity. \n  * **Entity Integrity**- Entity integrity rule states that for every instance of an entity, the value of the primary key must exist, be unique, and cannot be null. \n  * **Referential Integrity**- rule states that every foreign key value must match a primary key value in an associated table. Referential integrity ensures that we can correctly navigate between related entities. FKs can have nulls.\n\n### Constraints\n* Constraints enable the RDBMS enforce the integrity of the database automatically, without needing you to create triggers, rule or defaults.\n* **Types of constraints**: NOT NULL, CHECK, UNIQUE, PRIMARY KEY, FOREIGN KEY \n* **Check Constraints** \n\n## Data Types\n\n## LOB\n\n## Cursors\n\n* **Static Cursor** - Specifies that cursor will use a temporary copy of the data instead of base tables. This cursor does not allow modifications and modifications made to base tables are not reflected in the data returned by fetches made to this cursor. \n* **Dynamic Cursor** - \n* **Forward-ONLY Cursor** - Specifies that cursor can only fetch data sequentially from the first to the last row. FETCH NEXT is the only fetch option supported. \n* **KeySet Cursor** - \n  * Specifies that cursor uses the set of keys that uniquely identify the cursor's rows (keyset), so that the membership and order of rows in the cursor are fixed when the cursor is opened. SQL Server uses a table in tempdb to store keyset. \n  * The KEYSET cursor allows updates nonkey values from being made through this cursor, but inserts made by other users are not visible. \n  * Updates non-key values made by other users are visible as the owner scrolls around the cursor, but updates key values made by other users are not visible. If a row is deleted, an attempt to fetch the row returns an @@FETCH_STATUS of -2\n* **Ref Cursors** - Cursor variables are like pointers to result sets. You use them when you want to perform a query in one subprogram, and process the results in a different subprogram (possibly one written in a different language). A cursor variable has datatype REF CURSOR, and you might see them referred to informally as REF CURSORs.\n* **Implict & Explicit cursors**\n\n## Triggers\n\nTriggers are special kind of stored procedures that get executed automatically when an INSERT, UPDATE or DELETE operation takes place on a table. Triggers can't be invoked on demand. They get triggered only when an associated action (INSERT, UPDATE, DELETE) happens on the table on which they are defined.\n\n### Disadvantages of cursors \nEach time you fetch a row from the cursor,it results in a network round trip, where as a normal SELECT query makes only one round trip, however large the resultset is. Further, there are restrictions on the SELECT statements that can be used with some types of cursors.\n\n## Joins\n\n* http://www.codinghorror.com/blog/2007/10/a-visual-explanation-of-sql-joins.html\n* http://publib.boulder.ibm.com/infocenter/iseries/v5r4/index.jsp?topic=%2Fsqlp%2Frbafyjoin.htm \n\n* **Inner Join** - Records in both table A and table B where the given condition matches. e.g, `SELECT * FROM TableA INNER JOIN TableB ON TableA.name = TableB.name`\n* **Cross Join** - Every possible pair of rows from both the tables. If no condition is provided in Inner join, then it becomes a cross join. e.g., `SELECT * FROM TableA CROSS JOIN TableB`\n* **Full Outer Join** = Left Outer + Right Outer. e.g., `SELECT * FROM TableA FULL OUTER JOIN TableB ON TableA.name = TableB.name`\n* **Right Outer Join** - e.g., `SELECT * FROM TableA RIGHT OUTER JOIN TableB ON TableA.name = TableB.name`\n* **Left Outer Join** - e.g., `SELECT * FROM TableA LEFT OUTER JOIN TableB ON TableA.name = TableB.name`\n* **Outer Join** - Records NOT in table A and table B where the given condition matches. e.g, `SELECT * FROM TableA FULL OUTER JOIN TableB ON TableA.name = TableB.name WHERE TableA.id IS null OR TableB.id IS null `\n* **Equijoin** - \n* **Natural Join**- is an equijoin with redundant columns removed. \n* **Self Join** - \n* **Projection** - The project operator retrieves a subset of columns from a table, removing duplicate rows from the result.\n\n### Join Algorithms\n\n#### Nested Loop Join \n\n* *when one table is small, and other table is large*\n* **What is?** The nested loops join, also called nested iteration, uses one join input as the outer input table and one as the inner input table. The outer loop consumes the outer input table row by row. For every outer row, the inner loop searches for matching rows in the inner input table.\n* In the simplest case, the search scans an entire table or index; this is called a **naive nested loops join**. \n* If the search exploits an index, it is called an **index nested loops join**. \n* If the index is built as part of the query plan (and destroyed upon completion of the query), it is called a **temporary index nested loops join**. (All these variants are considered by the query optimizer.)\n* **When is it effective?** A nested loops join is particularly effective if the outer input is small and the inner input is preindexed and large. In many small transactions, such as those affecting only a small set of rows, index nested loops joins are superior to both merge joins and hash joins. In large queries, however, nested loops joins are often not the optimal choice.\n* Block nested loop join???\n{% img right /technology/nested-loop-join.gif 300 300 %}\n\n#### Merge Join / Sort-Merge Join\n\n* *when both the tables involved in the join are large*\n* The merge join requires both inputs to be sorted on the merge columns, which are defined by the equality (ON) clauses of the join predicate. The query optimizer typically scans an index, if one exists on the proper set of columns, or it places a sort operator below the merge join. In rare cases, there may be multiple equality clauses, but the merge columns are taken from only some of the available equality clauses.\n* Because each input is sorted, the Merge Join operator gets a row from each input and compares them. For example, for inner join operations, the rows are returned if they are equal. If they are not equal, the lower-value row is discarded and another row is obtained from that input. This process repeats until all rows have been processed.\n* The merge join operation may be either a regular or a many-to-many operation. A many-to-many merge join uses a temporary table to store rows. If there are duplicate values from each input, one of the inputs will have to rewind to the start of the duplicates as each duplicate from the other input is processed.\n* If a residual predicate is present, all rows that satisfy the merge predicate evaluate the residual predicate, and only those rows that satisfy it are returned.\n* Merge join itself is very fast, but it can be an expensive choice if sort operations are required. However, if the data volume is large and the desired data can be obtained presorted from existing B-tree indexes, merge join is often the fastest available join algorithm.\n{% img right /technology/merge-join.gif 300 300 %}\n\n#### Hash Join\n\n* *when the data set is large but the result set expected is small*\n* This algorithm also has a startup penalty by forcing you to build a hash table of one of the input sets before the actual join can start. \n* Performance\n  * Compared to the sort merge join this is easier as it involves only one sweep through the data and therefore the computational complexity is `O(n)` while sorting won't be better than `O(n log n)`. So in general you can build the hash faster than you would be able to do the sorting.\n  * The hash also needs to be computed for only one input set and this could be the smaller one.\n  * This makes the hash join often the preferred choice over the sort merge join.\n* Generally speaking the hash join wins when you expect a large result set and the nested loop join wins when you expect a small result set. One of the most dominant problems in this area is the planner getting the estimates wrong and taking the other path.\n* The hash join can only be used if you use equality as join relation.\n* Building the hash needs temporary space and increasing work_mem sometimes helps.\n* The hash join is also a good candidate for parallel processing. \n\n* http://etutorials.org/Misc/advanced+dba+certification+guide+and+reference/Chapter+6.+The+DB2+Optimizer/Joining+in+DB2+UDB/\n* http://pic.dhe.ibm.com/infocenter/db2luw/v9r7/index.jsp?topic=%2Fcom.ibm.db2.luw.admin.perf.doc%2Fdoc%2Fc0005311.html\n\n# Design\n\n## Physical Database Design\n\n* Data compression techniques\n* Data Striping (RAID)\n  * What is RAID and what are different types of RAID configurations? \n  * RAID stands for Redundant Array of Inexpensive Disks, used to provide fault tolerance to database servers. There are six RAID levels 0 through 5 offering different levels of performance, fault * tolerance.\n* Mirroring\n* Denormalization\n* Security\n  * Permissioning - Users & Groups\n\n### Data Modelling\n\n### Normalization\n\n> Refer to Sybase Performance and Tuning Guide\n\n* http://dev.mysql.com/tech-resources/articles/intro-to-normalization.html \n* http://www.bkent.net/Doc/simple5.htm \n* http://publib.boulder.ibm.com/infocenter/dzichelp/v2r2/index.jsp?topic=%2Fcom.ibm.db2z10.doc.intro%2Fsrc%2Ftpc%2Fdb2z_denormalizationforperformance.htm\n\n#### What is?\n* process to eliminate data redundancy, and to remove potential update inconsistencies which arise from inserting, modifying, and deleting data. \n* The goal of normalization is to create a set of relational tables that are free of redundant data and that can be consistently and correctly modified. This means that all tables in a relational database should be in the third normal form (3NF). \n* A relational table is in 3NF if and only if all non-key columns are (a) mutually independent and (b) fully dependent upon the primary key. Mutual independence means that no non-key column is dependent upon any combination of the other columns. The first two normal forms are intermediate steps to achieve the goal of having all tables in 3NF. In order to better understand the 2NF and higher forms, it is necessary to understand the concepts of functional dependencies and lossless decomposition.\n\n#### Types\n\n* 1st Normal Form- A relational table, by definition, is in first normal form. 1NF requires all values of the columns to be atomic. That is, they contain no repeating values. Table in 1NF contains redundancy of data. Redundancy causes what is called as 'Update anomalies'\n* 2nd Normal Form- The second normal form (or 2NF) any non-key columns must depend on the entire primary key. In the case of a composite primary key, this means that a non-key column cannot depend on only part of the composite key.\n* 3rd Normal Form- Third Normal Form (3NF) requires that all columns depend directly on the primary key. Tables violate the 3NF when one column depends on another column, which in turn depends on the primary key (a transitive dependency). One way to identify transitive dependencies is to look at your table and see if any columns would require updating if another column in the table was updated. If such a column exists, it probably violates 3NF. \n* 4th Normal Form-\n* 5th Normal Form- \n* Update Anomalies-Problems that arise when information is inserted, updated or deleted\n\n## Patterns\n\n\n* How do you implement 1-to-1, 1-to-many and many-to-many relationships while designing tables? \n* 1-to-1 relationship can be implemented as a single table and rarely as two tables with primary and foreign key relationships. \n* 1-to-Many relationships are implemented by splitting the data into two tables with primary key and foreign key relationships. \n* Many-to-Many relationships are implemented using a junction table with the keys from both the tables forming the composite primary key of the junction table.\n\n### Bi-temporal milestoning\n* Bi-temporal chaining – Database chaining mechanisms\n* spatial and temporal locality\n\n### Schema Patterns\n* Data Warehouse schema types - http://datawarehouse4u.info/Data-Warehouse-Schema-Architecture.html\n* Star schema\n\n## Anti-Patterns\n\n> Refer to SQL Anti-patterns\n\n* Logical Database Anti-patterns\n  * Comma separated lists\n  * Multi-column attributes\n  * Entity attribute value\n  * Metadata tribbles\n* Physical Database Anti-patterns\n  * ID Required\n  * Phantom Files\n  * FLOAT Antipattern\n  * ENUM Antipattern\n  * Readable Passwords\n* Query Anti-patterns\n  * Ambiguous GROUP BY\n  * HAVING antipattern\n  * Poor Man's Search Engine\n  * Implicit columns in SELECT and INSERT\n* Application Anti-patterns\n  * User-supplied SQL\n  * SQL Injection\n  * Parameter Façade\n  * Pseudokey Neat Freak\n  * Session Coupling\n  * Phantom Side Effects\n\n## Database Refactoring\n\n> Refer to Refactoring Databases\n* Database smells\n* Refactoring strategies\n\n# Performance\n\n## Indexes\n\n> Refer to Sybase - Performance and Tuning Guide\n\n* http://use-the-index-luke.com/sql/table-of-contents \n* http://www.sqlskills.com/blogs/kimberly/guids-as-primary-keys-andor-the-clustering-key/\n* http://www.micmin.com/Session320/Session%20320%20-%20Role%20of%20Indexes.htm \n\nAn index is an ordered set of pointers associated with a table, and is used for performance purposes. \n\n### How Indexes work?\n\nEach index entry contains a search-key value and a pointer to the row containing that value. If you specify the ALLOW REVERSE SCANS parameter in the CREATE INDEX statement, the values can be searched in both ascending and descending order. It is therefore possible to bracket the search, given the right predicate. An index can also be used to obtain rows in an ordered sequence, eliminating the need for the database manager to sort the rows after they are read from the table.\n\nAlthough the optimizer decides whether to use an index to access table data, except in the following case, you must decide which indexes might improve performance and create these indexes. Exceptions are the dimension block indexes and the composite block index that are created automatically for each dimension that you specify when you create a multi-dimensional clustering (MDC) table.\n\nIn addition to the search-key value and row pointer, an index can contain include columns, which are non-indexed columns in the indexed row. Such columns might make it possible for the optimizer to get required information only from the index, without accessing the table itself.\n\n### Limitations\n\nAlthough indexes can reduce access time significantly, they can also have adverse effects on performance. Before you create indexes, consider the effects of multiple indexes on disk space and processing time:\n\n* Each index requires storage or disk space. The exact amount depends on the size of the table and the size and number of columns in the index. \n* Each INSERT or DELETE operation performed on a table requires additional updating of each index on that table. This is also true for each UPDATE operation that changes the value of an index key. \n* Each index potentially adds an alternative access path for a query for the optimizer to consider, which increases the compilation time. \n\n### Index usage criteria \n\nThe query contains a column in a join clause that matches at least the first column of the index. eg. `create index idx1 on emp (division, dep, emptype) `\n\n* All the below queries will make use of the above index. \n  * `select * from emp where division='acct' `\n  * `select * from emp where division='acct' and dept='fin' `\n  * `select * from emp where division='acct' and emptype='exempt' `\n* However, this query would be NOT be able to use the index since it doesn't specify the first column of the index. \n  * `select * from emp where emptype='exempt' `\n\n### Index Types\n\n1. **Clustered** Any index structure having the data accessed in the same way the index is organized so that data with similar or the same key values is stored (or clustered) together. Clustering tends to greatly reduce input/output (I/O) time for queries and sorting.\n* **Non-clustered**\n* **Unique index**\n* **Hashtable index** - An index that maps primary key values to block data addresses in the database for otherwise un-ordered data. Not good for range searches\n* **Bitmapped index**\n  * A collection of bit vectors to form an index that can be used to quickly search secondary indexes or to search data warehouses. Each bit vector represents a different value of an attribute, and the length of each vector is the number of rows (rows) in the table.\n  * Bitmap and Bitmap join indexes\n* **Composite index** - An index based on more than one attribute or key (i.e., a concatenated key).\n* **Covering Index** - An index with enough information to satisfy certain queries by itself, in other words, the query can be satisfied merely by searching the index and not the database.\n* **B+ Tree** \n  * Basic table index based on one or more attributes, often used to enforce uniqueness of primary keys.\n  * These indexes are the standard index type. They are excellent for primary key and highly-selective indexes. Used as concatenated indexes, B-tree indexes can retrieve data sorted by the indexed columns. B-tree indexes have the following subtypes:\n    * **Index-organized tables**: An index-organized table differs from a heap-organized because the data is itself the index. \n    * **Reverse key indexes**: In this type of index, the bytes of the index key are reversed, for example, 103 is stored as 301. The reversal of bytes spreads out inserts into the index over many blocks. \n    * **Descending indexes**: This type of index stores data on a particular column or columns in descending order. \nB-tree cluster indexes\n* **Dense Vs Sparse Index** - A dense index has a pointer to each row in the table; a sparse index has at most one pointer to each block or page in the table.\n* **Function-based indexes**\n* **Application Domain indexes**\n* **Bi-directional indexes**\n\n### When to use Clustered index?\n\n* **Range searches** - Clustered indexes can improve performance for range retrievals because it can be used to set the bounds of a search, even if the query involves the large percentage of the rows in the table. Because the data is in sorted order, the db can use it to find the starting and ending points of the range, and scan only the data pages within the range. \n* Without a clustered index, the rows could be randomly spread throughout the table, and the db would have to perform a table scan to find all rows within the range. \n* Columns containing number of duplicates - Same concept holds true for indexes on columns with a large number of duplicates. With a clustered index, the duplicate values are grouped together. This minimizes the no. of pages that would have to be read to retrieve them. \n* Columns often referenced in an ORDER BY. Most sorts require that the table be copied into a buffer pool(DB2) or work table in tempdb(Sybase). This incurs additional I/O overhead. However if you're performing an ORDER BY on clustered index columns on a table, you can avoid creating a work table even if a query contains no search arguments.\n* Columns other than primary key reference in join clauses - Clustered indexes can also be more efficient for joins that are non-clustered indexes, cos clustered indexes usually are much smaller in size; typically they are atleast on level less in the B-tree. \n* **Single index table** - If you require only a single index on a table, it typically is advantageous to make it a clustered index, as the resulting overhead of maintaining clustered indexes during updates, inserts and deletes can be considerably less than the other one. \n\n### Index Covering \n\n* Index covering is a mechanism for using the leaf level of a non-clustered index the way the data page of a clustered index would work. This occurs when all columns referenced in a query are contained in the index itself. \n* Because the non-clustered index contains a leaf row corresponding to every data row in the table, db can satisfy the query from the leaf rows of the non-clustered index without having to read the data pages. \n* Because all leaf index pages point to the next page in the leaf-page chain, the leaf level of the index can be scanned just like the data pages in a table. \n* Because the leaf index rows typically are much smaller than the data rows, a non-clustered index that covers a query will be faster than a clustered index on the same columns, due to the fewer number of pages that must be read. \n* **Covered Queries** - in a query, if all the columns mentioned in the conditions section are part of an index, then it's a covered query \n\n### Indexing Rules of Thumb\n\n> Refer to Physical Database Design - Database Professional's Guide to Exploiting Indexes, Views, Storage & More\n\n* Index every primary key and most foreign keys in the database.\n* Attributes frequently referenced in SQL WHERE clauses are potentially good candidates for an index.\n* Use a B+tree index for both equality and range queries\n* Choose carefully one clustered index for each table\n* Avoid or remove redundant indexes\n* Add indexes only when absolutely necessary\n* Add or delete index columns for composite indexes to improve performance. Do not alter primary key columns\n* Use attributes for indexes with caution when they are frequently updated.\n* Keep up index maintenance on a regular basis; drop indexes only when they are clearly hurting performance\n* Avoid extremes in index cardinality and value distribution.\n* Covering indexes (index only) are useful, but often overused\n* Use bitmap indexes for high-volume data, especially in data warehouses.\n\n\n### Index Selection Decisions\n\n* Does this table require an index or not, and if so which search key should I build an index on?\n* When do I need multi-attribute (composite) search keys, and which ones should I choose?\n* Should I use a dense or sparse index?\n* When can I use a covering index?\n* Should I create a clustered index?\n* Is an index still preferred when updates are taken into account? What are the tradeoffs between queries and updates for each index chosen?\n* How do I know I made the right indexing choice?\n\n### Properties of an Index (Oracle feature)\n\n* **Usability**\n  * Indexes are usable (default) or unusable. An unusable index is not maintained by DML operations and is ignored by the optimizer. An unusable index can improve the performance of bulk loads. Instead of dropping an index and later re-creating it, you can make the index unusable and then rebuild it. Unusable indexes and index partitions do not consume space. When you make a usable index unusable, the database drops its index segment.\n* **Visibility**\n  * Indexes are visible (default) or invisible. An invisible index is maintained by DML operations and is not used by default by the optimizer. Making an index invisible is an alternative to making it unusable or dropping it. Invisible indexes are especially useful for testing the removal of an index before dropping it or using indexes temporarily without affecting the overall application.\n* **Composite Indexes**\n  * A composite index, also called a concatenated index, is an index on multiple columns in a table. Columns in a composite index should appear in the order that makes the most sense for the queries that will retrieve data and need not be adjacent in the table.\n  * `CREATE INDEX employees_ix ON employees (last_name, job_id, salary);`\n  * Queries that access all three columns, only the last_name column, or only the last_name and job_id columns use this index. In this example, queries that do not access the last_name column do not use the index.\n  * Multiple indexes can exist for the same table if the permutation of columns differs for each index. You can create multiple indexes using the same columns if you specify distinctly different permutations of the columns. For example, the following SQL statements specify valid permutations:\n  * `CREATE INDEX employee_idx1 ON employees (last_name, job_id);`\n  * `CREATE INDEX employee_idx2 ON employees (job_id, last_name);`\n* **Unique and Nonunique Indexes**\n  * Indexes can be unique or nonunique. Unique indexes guarantee that no two rows of a table have duplicate values in the key column or column. For example, no two employees can have the same employee ID. Thus, in a unique index, one rowid exists for each data value. The data in the leaf blocks is sorted only by key.\n  * Nonunique indexes permit duplicates values in the indexed column or columns. For example, the first_name column of the employees table may contain multiple Mike values. For a nonunique index, the rowid is included in the key in sorted order, so nonunique indexes are sorted by the index key and rowid (ascending).\n  * Oracle Database does not index table rows in which all key columns are null, except for bitmap indexes or when the cluster key column value is null.\n\n## Query Optimization\n\nWhen db processes the query, it performs the following steps: \n\n* Parses and normalizes the query, validating syntax and object references \n* Optimizes the query and generates the query plan \n  * Phase 1 - Query Analysis \n    * Find the search arguments (SARG) \n    * Find the ORs c. Find the joins \n  * Phase 2 - Index Selection \n    * Choose the best index for each SARG \n    * Choose the best method for ORs \n    * Choose the best indexes for any join clauses \n    * Choose the best index to use for each table \n  * Phase 3 - Join Order Selection \n    * Evaluate the join orders \n    * Compute the costs \n    * Evaluate other server options for resolving joins \n  * Phase 4 - Plan Selection \n* Compiles the query plan \n* Executes the query plan and returns the results to the user.\n\nHow do you tune a SQL query? How do you use an access plan?\n\n### Query Execution Plan\n\n> Refer to Dissecting SQL Server Execution Plans and SQL Tuning\n* What is?\n* How to read a query execution plan?\n\nPage Extent - Denotes the # of contiguous pages of data read from the hard disk at a time. SQL reads 8 pages(64K) at a time.\n\n## Concurrency \n\nhttp://msdn2.microsoft.com/en-us/library/ms171845(SQL.90).aspx \n\n* Dirty reading\n* Phantom reading\n\n### Locks\n* Locks http://www.dbazine.com/db2/db2-disarticles/gulutzan6 \n  * Shared Lock\n  * Update Lock \n  * Exclusive Lock (http://www.dbazine.com/db2/db2-disarticles/gulutzan6) \n* Deadlock \n  * Deadlock is a situation when two processes, each having a lock on one piece of data, attempt to acquire a lock on the other's piece. Each process would wait indefinitely for the other to release the lock, unless one of the user processes is terminated. SQL Server detects deadlocks and terminates one user's process. \n  * How do you avoid deadlocks?\n* Livelock \n  * A livelock is one, where a request for an exclusive lock is repeatedly denied because a series of overlapping shared locks keeps interfering. SQL Server detects the situation after four denials and refuses further shared locks. A livelock also occurs when read transactions monopolize a table or page, forcing a write transaction to wait indefinitely. \n* Lock contention \n* Lock escalation\n\n### Isolation Levels\n* Access to uncommitted data (only with UR)\n* Non-repeatable read (only with UR & CS)\n* Phantom read phenomenon (only wit UR, CS & RS)\n* Isolation levels\n* Repeatable Read(RR)\n* Read Stability (RS)\n  * Cursor Stability (CS)\n  * Uncommitted Read (UR)\n\n# FAQs\n\n* What's the difference between DELETE TABLE and TRUNCATE TABLE commands? \n  * DELETE TABLE is a logged operation, so the deletion of each row gets logged in the transaction log, which makes it slow. \n  * TRUNCATE TABLE also deletes all the rows in a table, but it won't log the deletion of each row, instead it logs the de-allocation of the data pages of the table, which makes it faster. Of course, TRUNCATE TABLE can be rolled back. \n* Pivoting\n* Co-related subquery? Co-related query is a query in which subquery depends on execution of main query \n``` sql\nSelect DeptNo,Ename,Sal From Emp e1 Where Sal=(Select Max(Sal) From Emp e2 Where e1.DeptNo=e2.DeptNo)\n```\n* What is SQL Injection and how to prevent it?\n* How to select first/last/max per group in SQL : http://www.xaprb.com/blog/2006/12/07/how-to-select-the-firstleastmax-row-per-group-in-sql/ \n* SQL query to get 4th or 5th maximum value from a table \n``` sql\nselect max(id) from EMP A where N=(select count(id) From EMP B where B.ID>=A.ID) \nOR \nselect * from (select rownum rn,id from (select distinct id From EMP order by id desc)) where rn between N-1 and N;\n```\n* How to identify the performance order (Big-O notation) of a query?\n* How query execution order works when a SQL has sub-queries in it?\n* When we need to use USING clause in the sql?For example in this below: SELECT emp_name, department_name, city FROM employees e JOIN departments d USING (department_id) JOIN locations l USING (location_id) WHERE salary > 10000;\n* How to delete duplicate records in a table? \n``` sql\nDELETE FROM test t1 WHERE EXISTS ( SELECT * FROM test t2 WHERE t2.col1=t1.col1 AND t2.rowid <> t1.rowid);\n```\n* What will be the o/p of this query? \n* `SELECT 1 FROM DUAL UNION SELECT 'A' FROM DUAL;` The query would throw an error. The two data types in the union set should be same. Out here it is a 1 and 'A', datatype mismatch and hence the error.\n\n# Bibliography\n\n* Physical Database Design - The Database Professional's Guide to Exploiting Indexes, Views, Storage, and More\n* Refactoring Databases\n* SQL Anti-patterns\n* http://www.geekinterview.com/articles/sql-interview-questions-with-answers.html"
  },
  {
    "id": 36,
    "title": "Retirement",
    "url": "/domain/retirement.html",
    "content": "[TOC]\n\n# Retirement Plan Types\n\n## 1. Defined Contribution Retirement Plans\n\n### a. 401(k)\n\n#### How 401(k) works\n* **Plan sponsor**: your employer\n* **Plan administer**: employer hires a mutual fund company or a brokerage firm to manage the plan and its investments.\n* finite set of investment options are provided by employer typically are mutual funds, company stock, etc.\n* **Asset Allocation**: you decide how much and where to invest.\n* **Funding option**: funding happens thru payroll deduction\n* **Matching Contribution**: \n  * For every dollar you invest, company pays you \\$0.5 to \\$1.0, which is free.\n  * Matching contributions usually vest over time, typically 25% every year or all at once after 3 yrs. If you leave or let go before that, you get nothing.\n  * No tax for matching contribution until you withdraw them in retirement.\n* **Withdrawal** - If you withdraw before age 59.5, you pay 10% penalty on top of income tax. IRS waives the penalty for certain hardship withdrawals like sudden disability, higher education expenses, etc. You could take loan as well.\n* **Switching Jobs** - You have 4 options\n  1. Move money to personal IRA rollover accounts - at a mutual fund company or discount brokerage so that the money grows tax deferred. Make sure you choose 'direct rollover' where the old employer pays a check to the fund company/brokerage firm. If it is made out to you, the money is taxed.\n  2. Move money to new employer's plan\n  3. Leave the money right where it is - Your former employer may not allow you to stay in the plan if your account balance is less than $5,000, however. And because you're no longer an employee, you may miss out on important information about plan changes and investment options.\n  4. Cash out: pay penalty and taxes.\n* **RMD (Required Minimum Withdrawal)** - At age 70.5, you must make minimum withdrawals.\n* *Pros*\n  * Investments are tax deferred. Earnings from the investment like interests, dividends, etc. are tax deferred.\n  * Free matching contribution money\n* *Cons*\n  * There is a max cap on how much you can invest. (~$17,000 p.a.)\n  * Heavy penalty on early withdrawals.\n\n### b. Roth 401(k)\n\n* some employers offer in addition to traditional 401(k). \n* Unlike 401(k), in Roth, taxes are paid before, not during withdrawal. Earning from the contribution grows tax free.\n* No required minimum withdrawal requirement.\n* Your combined contribution to 401(k) and Roth 401(k) cannot exceed $17,000\n\n\n### c. 403(b)\n\n* Offered to employees of government and tax-exempt groups like schools, hospitals, churches, etc.\n* Works the same way as 401(k)\n* Investment choices are limited than corporate plans.\n\n### d. 457 \n\n* Offered to state and local public employees.\n* Works the same way as 401(k)\n* No penalty on early withdrawals.\n\n### e. Thrift Savings Plan\n* Offered to employees of federal government.\n\n## 2. Supplemental Retirement Plans\n\n\n## 3. Individual Investors\n\n### Traditional IRAs\n\n* IRA - Individual Retirement Account. Basically a savings accounts with big tax breaks.\n* IRA itself is not an investment, it is just a basket in which you keep stocks, bonds, mutual funds and other assets.\n* You open your own IRAs.\n* Contribute, money grows tax-free and pay tax on withdrawal in retirement.\n* Anyone earning taxable income can contribute to traditional IRAs.\n* Withdrawals before age 59.5 are penalized with 10%\n* *Pros*\n  * Big tax breaks. Earning on investments are not taxed.\n* *Cons*\n  * High penalty on early withdrawals.\n  * RMD (Required Minimum Withdrawal) at age 70.5\n\n### Roth IRA\n\nSame as IRA, but here you pay taxes first and invest. Money grows tax-free.\nWithdrawals before age 59.5 are penalized with 10% only if earnings are withdrawn.\nPros\nEarning on investments are not taxed.\nNo RMD. You can leave it as long as you want.\nWithdrawals are not penalized as long as earnings are left untouched.\nCons\nThere are income limits for contributing to Roth IRAs (less than $183K).\n\n\n## 4. Self-Employed Individuals Plan\n\n### SEP IRA\n\n* Any business owner or individual with freelance income can open a SEP IRA.\n\n### SIMPLE IRA\n\n* Must have less than 100 employeed earning more than $5000 each. Employer cannot hvae any other retirement plan besides SIMPLE IRA.\n\n### Keoghs\n\n???\n\n## 5. Annuities\n\n* An insurance product that pays out income after retirement. \n* Tax benefits: Investment grows tax deferred. At the time of withdrawal, only the earnings are taxed, not the contribution.\n* Annuities are a popular choice for investors who want to receive a steady income stream in retirement.\n* Make an investment in the annuity, and it then makes payments to you on a future date or series of dates. \n* Early withdrawals are penalized with 10% penalty.\n* Pay out frequency - The income you receive from an annuity can be doled out monthly, quarterly, annually or even in a lump sum payment.\n* Size of payments - determined by a variety of factors, including the length of your payment period.\n* Pay out duration - rest of your life or a set number of years.\n\n### Annuity Types\n\n#### Fixed/Variable/Hybrid\n\n##### Fixed Annuity\n* Similar to bank CDs (Certificate of Deposits)\n* Guaranteed payout - pays guaranteed rates of interest on investment.\n* You are not responsible for choosing the investments. \n* Pros - No tension about market volatility\n* Cons - Do not keep pace with inflation.\n\n##### Variable Annuity\n* You choose from a selection of investments and the payout is based on the performance of the funds chosen.\n* Pros: compared to fixed annuity, inflation is handled here.\n* Cons: \n  * Investment risk due to volatility\n  * Though the investment is tax deferred, the annual expenses are higher compared to regular mutual funds.\n\n##### Equity-indexed Annuity\n* Combination of Fixed and Variable Annuity.\n* As with Fixed Annuity, you get guaranteed minimum return (usually 2-3%)\n* As with Variable Annuity, you have a shot at higher gains since it is tied to the performance of a benchmark index like S&P 500.\n* Pros: safety + probable higher gain. Better than fixed, and less riskier than variable.\n* Cons: Complex. Full returns of the market index gain is not always shared. High surrender charges.\n\n#### Deferred or immediate annuity\n\n##### Deferred Annuity\nWith a deferred annuity, your money is invested for a period of time until you are ready to begin taking withdrawals, typically in retirement.\n\n##### Immediate Annuity\nOpposite of Life Insurance policy. In Life Insurance, you pay regular premiums to an insurer that makes lump sum of cash upon your death. In Immediate Annuity, you pay a bulk amount and receive fixed payments starting immediately until you die.\n\n##### Longevity Annuity\nProtection against outliving your money late in life. This requires you to wait until you reach age 80 or so, to begin receiving payments until death. After death, your heirs get nothing.\n\n\n### Payout options\n* **Period Certain Annuity** - guaranteed a specific amount for a set period of time. If you die before the end of the period, your beneficiary gets the payment for the rest of the period.\n* **Life Certain Annuity** - guaranteed income payout until you die. If you die, your heirs don't get anything.\n* **Life with Period Certain Annuity** - life + period certain annuity. Guaranteed income for life that includes a a period certain phase. If you die during that period, beneficiary will continue to receive the payment for the remainder of the period.\n* **Joint and survivor Annuity** - Beneficiary will continue to receive payouts for the rest of his/her life after you die.\n\n* Pros\n  * Sock away large amount of cash without paying taxes.\n  * No annual contribution limit for an annuity.\n* Cons\n  * High expenses (hidden fees, commissions, surrender charges, high annual fees) cut into profits paid out by annuities. Some companies sell low cost annuities without charging sales commission or surrender charge. These are called 'direct-sold annuities' because there is no insurance agent unlike in an insurance company.\n* Tips\n  * Buy annuities only after maxing out 401(k) plans and IRAs.\n\n## 6. Pension Plans\n\n## 7. Social Security"
  },
  {
    "id": 38,
    "title": "Scala",
    "url": "/technology/scala.html",
    "content": "[TOC]\n\n# Interesting Features\n\n* Scala program can call Java methods and vice versa\n* Interface defined in Java can be implemented in Scala\n* Anonymous functions- e.g.?\n* Pass a function as argument to another function- e.g.?\n* Nested functions - e.g.?\n* Function as a return value of a function - e.g.?\n* Data Types\n  * Unit is like void\n* Everthing is an object including\n  * primitives like int, boolean, etc.\n  * functions\n* Classes\n  * Can have parameters - e.g., `class Complex(real: Double, imaginary : Double)`. Now an object is created with those parameters passed in `new Complex(1.1, 2.3)` .\n* Import statements\n  * Multi-class import - e.g., `import java.util.{Date, Locale}`\n  * To import all classes in a package - `import java.util._`  NOT `java.util.*` because asterisk is an identifier\n  * Static member import - `import java.util.DateFormat._`\n* Method definition\n  * Method with no argument and no return type\n  * Method with 1 argument and no return type\n  * Method with multiple args and no return type\n  * Method with return type\n    * Implicit - `def getName() = name; or def getName = name;` Though the return  type * here is not specified, compiler automatically deduces from variable type  'name'\n    * Explicit -\n  * Anonymous functions\n* Method calls (see program 1)\n  * No argument methods with no brackets - e.g., `new Date` or `class.method`\n  * 1 argument methods can be called in infix format - e.g., `df format date` rather than `df.format(now)`\n* Inheritence\n  * Super class is scala.AnyRef like java.lang.Object\n  * Abstract class is same as Java\n  * When overriding a method from super class, override modifier is mandatory. e.g.,  `override def toString() = \"\" + re + (if (im < 0) \"\" else \"+\") + im + \"i\"`\n* Case class\n  * new keyword is not mandatory to create instances\n  * Getter functions are automatically defined for default constructor parameters - e.g. `caseclass.parameter1` returns parameter1.\n  * `equals,hashCode & toString` methods are provided by-default on the structure of the instances\n* End of statement - no semicolon required\n\n\n## Simple Hello World\n\n``` scala\nobject HelloWorld {\n  def main(args: Array[String]) {\n    println(\"Hello, world!\")\n  }\n}\n```\n \n* Comments\n  * Defining HelloWorld as 'object' means it is both a class and a singleton   instance of it\n  * No return type required for main since it is a procedure method\n  * There is no static fields or methods in Scala\n \nSimple Programs\n\n*Program 1:*\n\n``` scala\nimport java.util.{Date, Locale}\nimport java.text.DateFormat\nimport java.text.DateFormat._\n \nobject FrenchDate {\n  def main(args: Array[String]) {\n    val now = new Date\n    val df = getDateInstance(LONG, Locale.FRANCE)\n    println(df format now)\n  }\n}\n```\n\n*Program 2: Passing function as input to another function*\n\n``` scala\nobject Timer {\n  def oncePerSecond(callback: () => Unit) {\n    while (true) { callback(); Thread sleep 1000 }\n  }\n \n  def timeFlies() {\n    println(\"time flies like an arrow...\")\n  }\n \n  def main(args: Array[String]) {\n    oncePerSecond(timeFlies)\n  }\n}\n```\n\n* Passing anonymous functions, it becomes `oncePerSecond( () => println(\"Time indeed flies\"))`"
  },
  {
    "id": 39,
    "title": "Security",
    "url": "/technology/security.html",
    "content": "[TOC]\n\n# Overview\n\nApplication Security has 4 aspects: \n\n* Authentication - proving user identity, often called user ‘login’.\n* Authorization - access control\n* Cryptography - protecting or hiding data from prying eyes\n* Session Management - per-user time-sensitive state\n\n## Core Concepts\n\n{% img right /technology/shiro-basics.png %}\n\n3 Main concepts in security\n\n1. Subject - \"the currently executing user\". It could be more than a human user. e.g., daemon apps, 3rd party apps, etc.\n* SecurityManager - manages security operations for all users\n* Realm - acts the bridge/connector between the security provider and your application's security data like user accounts, access controls, etc.\n\n# Authentication\n\n* Process of verifying a user's identity. Also called 'login' process.\n* 3 step process\n  * Collect the user’s identifying information, called principals (e.g. username), and supporting proof of identity, called credentials (e.g. password). Combination of principal and credential is called as **Authentication Token**\n  * Submit the **principals** and **credentials** to the system.\n  * If the submitted credentials match what the system expects for that user identity (principal), the user is considered authenticated. \n\n## Basic Authentication\n\nBasic authentication is the simplest protocol available for performing authentication over HTTP. It involves sending a Base64-encoded username and password within a request header to the server. With Basic authentication (with and without SSL), your name and password do get automatically Base64- encoded. \n\nThe server checks to see if the username exists within its system and verifies the sent password. The client needs to send this Authorization header with each and every request it makes to the server.\n\n### Unauthorized request\n\n* The 401 response tells the client that it is not authorized to access the URI it tried to invoke on. \n* The **WWW-Authenticate** header specifies which authentication protocol the client should use. \n* In this case, **Basic** means basic authentication should be used. The realm attribute identifies a collection of secured resources on a website.\n\n``` r Response to an unauthorized request\n HTTP/1.1 401 Unauthorized\n WWW-Authenticate: Basic realm=\"CustomerDB Realm\"\n```\n\n### Response with authorization details\n\n* To perform authentication, the client must send a request with the Authorization header set to a Base64-encoded string of our username and a colon character, followed by the password. If our username is bburke and our password geheim, the Base64-encoded string of bburke:geheim will be `YmJ1cmtlOmdlaGVpbQ==`.\n* The client needs to send this Authorization header with each and every request it makes to the server.\n\n``` r Request with authorization details\nGET /customers/333 HTTP/1.1\nAuthorization: Basic YmJ1cmtlOmdlaGVpbQ==\n``` \n\n\n**Downside**: The problem with this approach is that if this request is intercepted by a hostile entity on the network, the hacker can easily obtain the username and password and use it to invoke its own requests. Using an encrypted HTTP connection, HTTPS, solves this problem. With an encrypted connection, a rogue programmer on the network will be unable to decode the transmission and get at the Authorization header. Still, security-paranoid network administrators are very squeamish about sending passwords over the network, even if they are encrypted within SSL packets.\n\n## Digest Authentication\n\nDigest authentication was invented so that clients would not have to send clear text passwords over HTTP. It involves exchanging a set of secure MD5 hashes of the username, password, operation, URI, and optionally the hash of the message body itself. It is a hash value generated with the following pseudocode:\n\n### Response to an unauthorized request\n\nThe **nonce** and **opaque** attributes are special server-generated keys that will be used to build the subsequent authenticated request.\n\n``` r Response to an unauthorized request\n HTTP/1.1 401 Unauthorized\nWWW-Authenticate: Digest realm=\"CustomerDB Realm\",\nqop=\"auth,auth-int\",\nnonce=\"12dcde223152321ab99cd\",\nopaque=\"aa9321534253bcd00121\"\n```\n\n### Request with Authorization details\n\n* The **nonce** and **opaque** attributes are a copy of the values sent with the earlier WWWAuthenticate header. \n* The **uri** attribute is the base URI you are invoking on. \n* The **nc** attribute is a request counter that should be incremented by the client with each request. This prevents hostile clients from replaying a request. \n* The **cnonce** attribute is a unique key generated by the client and can be anything the client wants. \n* The **response** attribute is where all the meat is. It is a hash value generated with the following pseudocode:\n```\nH1 = md5(\"username:realm:password\")\nH2 = md5(\"httpmethod:uri\")\nresponse = md5(\"H1:nonce:nc:cnonce:qop:H2\")\n```\n* When the server receives this request, it builds its own version of the **response** hash using its stored, secret values of the username and password. If the hashes match, the user and its credentials are valid.\n\n``` r Request with Authorization details\nGET /customers/333 HTTP/1.1\nAuthorization: Digest username=\"bburke\",\nrealm=\"CustomerDB Realm\",\nnonce=\"12dcde223152321ab99cd\",\nuri=\"/customer/333\",\nqop=\"auth\",\nnc=00000001,\ncnonce=\"43fea\",\nresponse=\"11132fffdeab993421\",\nopaque=\"aa9321534253bcd00121\"\n```\n\n### Pros\n\n* The password is never used directly by the protocol. For example, the server doesn't even need to store clear text passwords. It can instead initialize its authorization store with pre-hashed values. \n* Also, since request hashes are built with a nonce value, the server can expire these nonce values over time. This, combined with a request counter, can greatly reduce replay attacks.\nWhen the server receives this request, it builds its own version of the response hash using its stored, secret values of the username and password. If the hashes match, the user and its credentials are valid. \n\n### Cons\n\nThis approach is that unless you use HTTPS, you are still vulnerable to man-in-the-middle attacks, where the middleman can tell a client to use Basic authentication to obtain a password.  \n\n## X.509 certificates\n\n{% img right /technology/security-certs.gif %}\n\n* When you first interact with a secure website, your browser receives a digitally signed certificate from the server that identifies it. \n* Your browser verifies this certificate with a central authority like VeriSign. This is how you guarantee the identity of the server you are interacting with and make\n* sure you’re not dealing with some man-in-the-middle security breach.\n* HTTPS can also perform two-way authentication. In addition to the client receiving a signed digital certificate representing the server, the server can receive a certificate that represents and identifies the client. \n* When a client initially connects to a server, it exchanges its certificate and the server matches it against its internal store. \n* Once this link is established, there is no further need for user authentication, since the certificate has already positively identified the user.\n\n> SSL, or Secure Socket Layer, is a technology which allows web browsers and web servers to communicate over a secured connection. This means that the data being sent is encrypted by one side, transmitted, then decrypted by the other side before processing. This is a two-way process, meaning that both the server AND the browser encrypt all traffic before sending out data.\n\n> Another important aspect of the SSL protocol is Authentication. This means that during your initial attempt to communicate with a web server over a secure connection, that server will present your web browser with a set of credentials, in the form of a \"Certificate\", as proof the site is who and what it claims to be. In certain cases, the server may also request a Certificate from your web browser, asking for proof that you are who you claim to be. This is known as \"Client Authentication,\" although in practice this is used more for business-to-business (B2B) transactions than with individual users. Most SSL-enabled web servers do not request Client Authentication.\n\n### Pros\n\nMost secure way to perform authentication on web.\n\n### Cons\n\nManaging of the certificates is painful. The server must create a unique certificate for each client that wants to connect to the service. From the browser/human perspective, this can be a pain, as the user has to do some extra configuration to interact with the server.\n\n## OpenAuth (OpenID)\n\n<span style=\"color:red\">TODO</span>\n\n# Authorization\n\nAuthorization is essentially access control - controlling what your users can access in your application, such as resources, web pages, etc. \n\n## Simple Access Control List (ACL)\n\n* Roles/Users assigned with access to certain features. Users are assigned to roles. This model is not flexible since roles cannot be added dynamically\n* Permissions are defined for features. Users are assigned permissions. This model allows dynamic addition of users.\n\n# Session Management\n\nApache Shiro enables a Session programming paradigm for any application - from small daemon standalone applications to the largest clustered web applications. This means that application developers who wish to use sessions are no longer forced to use Servlet or EJB containers if they don’t need them otherwise. \n\n# Cryptography\n\nCryptography is the process of hiding or obfuscating data so prying eyes can’t understand it. \n\n## Hashing (a.k.a Message Digest)\n\n* Hashing/Message digests are secure one-way hash functions that take arbitrary-sized data and output a fixed-length hash value. \n* `java.security.MessageDigest` class supports MD5 and SHA digests.\n* Shiro supports hex-encode and Base64 encoding.\n\n## Cipher\n\nCiphers are cryptographic algorithms that can reversibly transform data using a key. We use them to keep data safe, especially when transferring or storing data, times when data is particularly susceptible to prying eyes.\n\n** Types**\n\n* Public-Private key cipher\n* AES 257-bit cipher\n\n# Miscellaneous\n\n* Kerberos - how it works\n* PGP/GPG\n* How to secure passwords - http://www.youtube.com/watch?v=6bR110r-RfY&list=WL08D7E897CDBD47CB (Salt, Bcrypt, Ascrypt, Blowfish algo, AES 256)\n\n# Bibliography\n\n* Books\n  * RESTful Java with JAX-RS - Chapter 12 - Securing JAX-RS\n  * REST in practice - Chapter 9 - Web Security\n* Links\n  * [Application Security With Apache Shiro](http://www.infoq.com/articles/apache-shiro)\n  * Java EE Security - http://docs.oracle.com/javaee/6/tutorial/doc/gijrp.html\n  * Encyclopedia of Security - http://www.microsoft.com/mspress/books/sampchap/6429.aspx"
  },
  {
    "id": 40,
    "title": "SOA",
    "url": "/technology/soa.html",
    "content": "[TOC]\n\n\n\n# Concepts\n\n## What is SOA?\n\n* SOA is a software system structuring principle based on the idea of self-describing service providers.\n* a service is a function (usually a business function) that is accomplished by the interchange of messages between two entities: a service provider, and a service consumer. \n* SOA is just a methodology, an architectural design choice. It has nothing to do with a particular technology \n* It is a type of distributed computing \n* Web services is a realization of SOA \n\n## Why SOA?\n\n* Reduces coupling between the consumer and provider. This permits controlled changes to the provider, that will not have unforeseen effects on the consumer. It also allows the consumer to switch providers easily, provided only that a compatible service interface is provided. Decoupling allows changes to occur incrementally.\n* Increases inter-operability across different systems, technologies and languages like Java, .Net, etc.\n* Since heavy monolithic systems are divided into discrete services, development, upgrade, etc. can happen independently.\n* Reusability of services \n* Predecessors of SOA : CORBA, DCOM, EJB (all 3 are RPC based), SOAP based Web services \n* Downside of the SOA predecessors \n  * Interoperability across systems and technologies proved to be nettlesome. EJB & DCOM are tied to specific platforms\n  * For data exchange, proprietary, binary-based technologies were used unlike XML in SOA\n* Downsides of RPC based solutions \n  * tight coupling between server and client \n  * repeated RPC calls increases network load \n  * data type support between 2 incompatible languages, such as C++ and Java is complicated and challenging. \n  * When should SOA be used and should NOT be used?\n\n## SOA Operations\n\n{% img right /technology/soa-operations.png %}\n\n1. Publish\n2. Find\n3. Bind\n\n## Characteristics of contemporary SOA\n\n1. QoS (Quality of Service) - security, reliability (in message delivery or notification), transactional capabilities (to protect the integrity of the business tasks)\n* Autonomous - services should be independent and self-contained\n* Based on Open Standards - Data exchange is governed by open standards like SOAP, WSDL, XML, etc.\n* Promotes Discovery\n* Interoperability - disparate technologies should not prevent service-oriented solutions from interoperating\n* Composability - composing 1 or more fine-grained services to form a coarse-grained service. Different solutions can be composed of different extensions and can continue to interoperate as long as they support the common extensions required\n* Reusability of services\n* Extensibility of services\n* Layers of abstraction - encapsulates application logic and technology resources\n* Promotes loose-coupling - separation of concerns\n* Stateless\n* Location-, Language- & Protocol-independent\n\n## Message Exchange Patterns (MEP)\n\n* An MEP is a generic interaction pattern that defines the message exchange between two services\n* MEPs can composed to support the creation of large, more complex patterns.\n\n### Primitive MEPs\n1. Request-response\n  * this could be synchronous or asynchronous\n  * typically a \"correlation\" is used to associate a response with the request \n2. Fire-and-forget\n  * This simple asynchronous pattern is based on a *unidirectional* transmission of messages from a source to one or more destinations. \n  * There are few variations in this MEP.\n    * *single-destination* pattern - a source sends a message to one destination only\n    * *multi-cast* pattern - a source sends messages to a predefined set of destinations\n    * *broadcast* pattern - same as multi-cast pattern, except that the message is sent out to a broader range of recipient destinations\n\n### Complex MEPs\n\n* Example of a complex MEP is **Publish-and-subscribe** model\n\n### MEPs and WSDL\n\n#### WSDL 1.1 Spec\n\n1. **Request-response operation** - upon receiving a message, the service must response with a standard message or a fault message\n2. **Solicit-response operation** - upon submitting a message to a service requestor, the service expects a standard response message or a fault message\n3. **One-way operation** - the service expects a single message and is not obligated to respond.\n4. **Notification operation** - The service sends a message and expects no response.\n\n#### WSDL 2.0 Spec\n\n1. **in-out** pattern - equivalent to WSDL 1.1 request-response\n2. **out-in** pattern - equivalent to WSDL 1.1 solicit-response\n3. **in-only** pattern - equivalent to WSDL 1.1 one-way\n4. **out-only** pattern - equivalent to WSDL 1.1 notification\n5. **robust in-only** pattern - a variation of the in-only pattern that provides the option of launching a fault response message as a result of a transmission or processing error\n6. **robust out-only** pattern - like out-only pattern, has an outbound message initiating the transmission. the difference here is that a fault message can be issued in response to the receipt of this message\n7. **in-optional-out** pattern - similar to in-out with an exception. This variation introduces a rule stating that the delivery of a response message is optional and should therefore not be expected by the service requetor that originated the communication. This pattern also supports the generation of a fault message.\n8. **out-optional-in** pattern - reverse of the in-optional-out, where the incoming message is optional. Fault message generation is also supported.\n\n\n\n## Primitive SOA / First Generation Web-services Framework\n\n### Service Roles\n\n* Service Provider - who creates a service description and deploys it. (server side)\n* Service Requestor / Service Consumer - who consumes the service\n  * service provider entity - the organization providing the WS.\n  * service provider agent - the web service itself.\n* Service Registry - who publishes the service description. match maker between provider and requestor.\n* Intermediary service (routing service)\n  1. Passive Intermediary service - It is typically responsible for routing messages to a subsequent location. It may use information in the SOAP message header to determine the routing path, or it may employ native routing logic to achieve some level of load balancing. Either way, what makes this type of intermediary passive is that it does not modify the message.\n  2. Active intermediaries - also route messages to a forwarding destination. Prior to transmitting a message, however, these services actively process and alter the message contents (Figure 5.7). Typically, active intermediaries will look for particular SOAP header blocks and perform some action in response to the information they find there. They almost always alter data in header blocks and may insert or even delete header blocks entirely. \n* Initial sender and ultimate receiver - Initial senders are simply service requestors that initiate the transmission of a message. Therefore, the initial sender is always the first Web service in a message path. The counterpart to this role is the ultimate receiver. This label identifies service providers that exist as the last Web service along a message's path\n* Service Composition / Service Assemblies - A service can invoke one or more other services to complete a task. Each service participating in such composition is called as 'service composition member'. Service composition is frequently governed by WS-* composition extensions, such as WS-BPEL and WS-CDL, which introduce the related concepts of orchestration and choreography.\n\n### Service Models\n\n* Business service model\n* Utility service model - a generic webservice designed for re-use and non-application specific in nature\n* Controller service model - Service compositions are comprised of a set of independent services that each contribute to the execution of the overall business task. The assembly and coordination of these services is often a task in itself and one that can be assigned as the primary function of a dedicated service or as the secondary function of a service that is fully capable of executing a business task independently. The controller service fulfills this role, acting as the parent service to service composition members.\n\n### Service Endpoint or Service Description (WSDL)\n\n* Service Endpoint - A WSDL describes the point of contact for a service provider, also known as the service endpoint or just endpoint. It provides a formal definition of the endpoint interface and also establishes the physical location (address) of the service.\n* 2 categories of WSDL Description\n  1. Abstract description\n    * Describes the interface characteristics of the Web service without any reference to the technology used to host.\n    * It contains `portType` (or `interface` from WSDL 2.0), `operation` and `message`\n\n``` xml WSDL Abstract description\n<portType name=\"glossaryTerms\">\n  <operation name=\"setTerm\">\n    <input name=\"newTerm\" message=\"newTermValues\"/>\n  </operation>\n</portType >\n```\n\n  2. Concrete description - contains\n    * Describes the concrete technology used for physical transport.\n    * It contains\n      * binding -  represents the transport technology the service can use to communicate. Typically it is SOAP. A binding can apply to a particular operation or all operations.\n      * port (or endpoint from WSDL 2.0) - represents the physical address at which a service can be accessed with a specific protocol.\n      * service\n\n``` xml WSDL Concrete description\n<binding type=\"glossaryTerms\" name=\"b1\">\n   <soap:binding style=\"document\"\n   transport=\"http://schemas.xmlsoap.org/soap/http\" />\n   <operation>\n     <soap:operation soapAction=\"http://example.com/getTerm\"/>\n     <input><soap:body use=\"literal\"/></input>\n     <output><soap:body use=\"literal\"/></output>\n  </operation>\n</binding>\n```\n\n### Service Contract or Service Metadata \n\nA service contract is comprised of the following documents:\n\n* WSDL definition\n* XSD schema\n* Policy document - provides rules, preferences, and processing details above and beyond what is expressed in WSDL & XSD.\n* Other legal documents\n\n# Bibliography\n\n* Books\n  * Service Oriented Architecture - Concepts, Technology and Design - Thomas Erl (2005)\n  * SOA - Principles of Service Design - Thomas Erl\n* Sites\n  * http://www.service-architecture.com/articles/web-services/index.html\n  * http://www.servicetechbooks.com/\n  * http://www.servicetechspecs.com\n  * http://www.serviceorientation.com\n  * http://www.soaglossary.com\n  * http://www.whatisrest.com\n  * http://www.servicetechmag.com\n"
  },
  {
    "id": 41,
    "title": "Spring",
    "url": "/technology/spring.html",
    "content": "[TOC]\n\n# Overview\n\n* Dependency injection types: Setter-based, Constructor-based and Annotation-based. \n* `@Autowired` - on a field denotes the bean implementation will injected\n* `@Inject` and `@Resource`. Last 2 are Java JSR-330 based.\n* `ApplicationContext` - different ways to configure. via XML or Java. Multiple application contexts can be defined in a hierarchy.\n* `@Configuration` - marks the class as config class. \n  * Classes can be abstract but not final. \n  * Class with no `@Bean` annotation is now allowed.\n* `@Bean` - \n* Resource Loading\n  * Prefixes are classpath:, file: and http:\n  * Ant-style wild cards - e.g., classpath:/META-INF/spring/*.xml, file:/var/conf/**/*.properties\n* Component Scanning\n  * Enables Spring to scan classpath for classes that are annotated with @Component (or one of the specialized annotations like @Service, @Repository, @Controller, or @Configuration). Application Context needs to be enabled for component scanning via @ComponentScan annotation.\n\n```java\n@Configuration\n@ComponentScan(basePackages = {\"com.apress.prospringmvc.moneytransfer.scanning\",\"com.apress.prospringmvc.moneytransfer.repository\" })\npublic class ApplicationContextConfiguration {}\n```\n\n## Scope\n* By default, all beans in Spring application context is singleton.\n* singleton - \n* prototype - new instance of bean is created every time\n* thread - new bean created and bound to current thread. Thread dies - bean destroyed.\n* request - new bean created and bound to the current javax.servlet.ServletRequest. Request dies - bean destroyed.\n* session - new bean created and bound to the current javax.servlet.HttpSession. Request dies - bean destroyed.\n* globalSession - new bean is created when needed and stored in the globally available session (which is available in Portlet environments). If no such session is available, the scope reverts to the session scope functionality.\n* application - This scope is very similar to the singleton scope; however, beans with this scope are also registered in javax.servlet.ServletContext.\n\n## Profiles\n* Enables creating different configuration for different environments like testing, local deployment, cloud deployment, etc.\n* To enable a profile, tell the application context which profiles are activeby setting a system property called 'spring.profiles.active' (in a web environment, this can be a servlet initialization parameter or web context parameter).\n\n```java\n@Configuration\n@Profile(value = \"test\")\npublic static class TestContextConfiguration {\n   @Bean\n   public TransactionRepository transactionRepository() {\n      return new StubTransactionRepository();\n   }\n}\n```\n\n* @EnableCaching - Enables support for bean methods with the @Cacheable annotation.\n* @EnableWebMvc - Enables support for the powerful and flexible annotation-driven controllers with request handling methods. This feature detects beans with the @Controller annotation and binds methods with the @RequestMapping annotations to URLs."
  },
  {
    "id": 42,
    "title": "Statistics",
    "url": "/datascience/statistics.html",
    "content": "[TOC]\n\n# Charts\n\n## Pie chart\n* Used to visualize proportions\n* Never use percentage as proportions\n\n## Bar chart\n* Prefer horizontal bar chart when the category names are longer.\n* Segmented bar chart is used to show both frequency and percentage.\n\n## Histogram\n* Histogram's bar area must be proportional to frequency.\n* Frequency Density = Frequency / Group Width\n\n> What is the difference between Histogram & Bar chart?\n> * Widths are constant in bar charts. It varies in histogram.\n> * No gaps between bars in histogram.\n\n## Line Chart\n* Use only for numerical data. Never for categorical data.\n\n> Rule: When using percentages in charts, show frequency also. \n\n## What type of chart to use?\n| To show                                 | use           |\n| ----------------------------------------|---------------|\n| Category + Frequency                    | Pie chart     | \n| Category + Percentage                   | Bar chart     |\n| Category + Frequency + Percentage       | Segmented Bar |\n| Range of numbers + Frequency            | Histogram     |\n| Range of numbers + Cumulative Frequency | Line chart    |  \n\n---\n\n# Measuring Central Tendency\n\nThere are 3 types of average: Mean, Median & Mode.\n\n## Mean ($\\mu$)\n* **Outliers** - An extreme high or low value that stands out from the rest of the data.\n* **Skewed Data** - When outliers pull the data to the left or right.\n\n## Median\n* Sort and find the middle value. \n* Use this when the data is skewed.\n* Can fluctuate if the data is symmetrical.\n\n## Mode\n* Most frequent value. There can be more than one mode in a data set. \n* Bimodal - data set with 2 modes\n* Group / category with highest frequency is `modal class`\n* When to use?\n  * When the data is categorical\n  * For the data with clusters\n* When not to use?\n  * When there are many modes.\n\n---\n\n# Measuring Spread\n\n## Range\n* The range is a way of measuring how spread out a set of values are. It's given by:\n`range = upper bound - lower bound`.\n* The range only describes the width of the data, not how it’s dispersed between the bounds. \n* Range value is misleading when there are outliers.\n\n## Quartiles\n* Quartiles are values that split your data into quarters. \n* The lowest quartile is known as the *lower quartile*, or first quartile\n(Q1), and the highest quartile is known as the *upper quartile*, or third\nquartile (Q3). The quartile in the middle (Q2) is the *median*, as it splits\nthe data in half. \n* The lowest quartile is called the *lower quartile* (Q1), and the highest quartile is called the *upper quartile* (Q3). The middle quartile is the *median*.\n* **Interquartile Range (IQR)** - is the range of central 50% of the data between lower and upper quartiles. You find it by calculating `Upper quartile - Lower quartile`.\n* Box and whisker chart or Box plot is used to visualize the range, IQR and median.\n\n## Percentiles\n* If you break up a set of data into percentages, the values that split the data are called *percentiles*. For example, if the data is split into tenths (10% each), then the values are called *deciles*.\n* P<sub>k</sub> is the value k% of the way through your data. If you scored 50 and knew\nthat P<sub>90</sub> = 50, you’d have beaten or matched the score of 90% of other people.\n* Quartiles are a type of percentile. Q1 is P<sub>25</sub>, Q2 is P<sub>50</sub> and Q3 is P<sub>75</sub>. \n* We can use percentiles to construct a new range called the **interpercentile range**.\n\n---\n\n# Measuring Variability\n\n## Variance & Standard Deviation ($\\sigma$)\n* The variance is a way of measuring spread, and it’s the average of the distance of values from the mean squared.\n\n\\(\n  Variance = \\frac{\\Sigma(x-\\mu)^2} {n} \n\\)\n\n* For faster variance calculation, use below formula. Here you don’t have to calculate \\({\\Sigma(x-\\mu)^2}\\) for every number. \n\n\\( Variance = \\frac{\\Sigma x^2} {n} - \\mu^2 \\)\n\n* **Standard Deviation** is a way of saying how far typical values are from the mean. The smaller the standard deviation, the closer values are to the mean. The smallest value the standard deviation can take is 0. \\(\\sigma = \\sqrt{variance}\\)\n\n## Standard Score ($z$)\n* Standard scores give you a way of comparing values across different sets of data\nwhere the mean and standard deviation differ. They’re a way of comparing\nrelated data values in different circumstances. \\( z = \\frac{x - \\mu} {\\sigma} \\)\n* You find the standard score of a particular value using the mean and standard\ndeviation of the entire data set.\n\n*Example*: Imagine a situation in which you have two basketball players of different ability. The first player gets the ball into the net an average of 70% of the time, and he\nhas a standard deviation of 20%. The second player has a mean of 40% and a\nstandard deviation of 10%. \nIn a particular practice session, Player 1 gets the ball into the net 75% of the time, and Player 2 makes a basket 55% of the time. Which player does best against their personal track record?\n\n\nPlayer 1                       |   | Player 2                      \n------------------------------ |---|-------------------------------\n$x$ = 75                       |   | $x$ = 55                      \n$\\mu$ = 70                     |   | $\\mu$ = 40                    \n$\\sigma$ = 20                  |   | $\\sigma$ = 10                 \n$z1 = \\frac{75-70}{20} = 0.25$ |   | $z2 = \\frac{55-40}{10} = 1.5 $\n\n# Probability\n\n## Basics\n\n* Event - An outcome or occurrence that has a probability assigned to it\n* Probability = (# of ways of winning) / (# of possible outcomes)\n\n> P(A) = n(A) / n(S)\n\nwhere \n\n* P(A) - probability of event A occurring\n* n(A) - number of ways of getting an event A\n* n(S) - number of possible outcomes\n* S - **possibility space** or **sample space**\n\n### Complementary event\n  * A<sup>I</sup> is the complementary event of A. It is the probability that event A does not occur.\n\n> P(A) + P(A<sup>I</sup>) = 1\n\n* Use Venn Diagram to easily visualize the probabilities \n\n{% img right /datascience/venn-diagram.png %}\n\n* Adding probabilities - e.g., what is the probability of getting an even number in a dice throw.\n\n\\(\nP(even) = P(2) + P(4) + P(6) \\\\\n        = 1/6 + 1/6 + 1/6 \\\\\n        = 3/6 = 0.5\n\\)\n\n### Exclusive events\n\n* If two events are mutually exclusive, only one of the two can occur. e.g., head and tail in a coin toss\n\n### Intersection events\n\n* If two events intersect, it’s possible they can occur simultaneously. e.g., black and even number in roulette \n* **i\\(\\bigcap\\)tersection**\n  * \\(A \\bigcap B\\) refers to intersection between event A and B. \n  * Think of this symbol as **and**\n* **\\(\\bigcup\\)nion**\n  * \\(A \\bigcup B\\) refers to union of A and B. It includes all of the elements in A and B.\n  * Think of this symbol as **or**\n  * If \\(A \\bigcup B = 1\\), then A and B are said to be **exhaustive**. Between them, they make up the whole of S.\n\n\\(\n  P(A \\bigcup B) = P(A) + P(B) + P(A \\bigcap B) \\\\\n  where P(A \\bigcup B) is P(A or B) \\\\\n  P(A \\bigcap B) is P(A and B)\n\\)\n\n* Mutually exclusive events have no elements in common with each other, so \\(P(A \\bigcap B) = 0\\)\n\n### Conditional probabilities\n\n{% img right /datascience/decision-tree.png %} \n\n* measures the probability of an event occurring relative to another occurring.\n* it is represented by symbol \"|\". e.g., P(A|B) is read as the probability of A given that wek now B has happened.\n* conditional probabilities are best visualized using probability tree.\n\n\\(\n  \\begin{split}\n  P(A | B) = \\frac{P(A \\bigcap B)} {P(B)} \\\\\n  which means, P(A \\bigcap B)} = P(A | B) \\times P(B) \\\\\n  \\end{split}\n\\)\n\nSquare bracket\n\n\\[\n  P(A | B) = \\frac {P(A \\bigcap B)} {P(B)} \\\\\n  which means, P(A \\bigcap B)} = P(A | B) \\times P(B) \\\\\n\\]\n\n\nDollar\n\n$$\n  P(A | B) = \\frac {P(A \\bigcap B)} {P(B)} \\\\\n  which means, P(A \\bigcap B)} = P(A | B) \\times P(B) \\\\\n$$\n\n# Appendix\n\n## About Roulette Wheel\n\n* It has 38 pockets that the ball can fall into.\n* The main pockets are numbered from 1 to 36, and each pocket is colored either red or black.\n* There are two extra pockets numbered 0 and 00. These pockets are both green.\n\n\n\n# Bibliography\n\n* Head First Statistics"
  },
  {
    "id": 43,
    "title": "Transaction Management",
    "url": "/technology/transaction.html",
    "content": "[TOC]\n\n\n\n# Overview\n\n* JTA & JTS\n  * JTA is a high level, implementation-independent, protocol independent API that allows applications and application servers to access transactions. An API like JDBC implemented by vendors - typically by commercial servers or by open source txn managers such as JBoss Txn Service or JOTM.\n  * JTS (Java Transaction Services) - JTS specifies the implementation of a Transaction Manager which supports JTA and implements the Java mapping of the OMG Object Transaction Service (OTS) 1.1 specification at the level below the API. JTS propagates transactions using the Internet Inter-ORB Protocol (IIOP).\n* JTA interfaces\n  * `UserTransaction` Interface\n  * `javax.transaction.UserTransaction` - allows to programmatically begin, commit or rollback txns, or get status.\n  * `TransactionManager` Interface\n  * primarily used within the Declarative Txn Model.\n\n# Transaction Properties\n\n<span style=\"color:red\">TODO </span>\n\n## ACID property\n\n* **Atomicity** - means a txn must either be a commit or rollback all updates as a single unit of work.\n* **Consistency** - means during the course of the txn, the resource (db or EMS) will not be left in an inconsisten state.\n* **Isolation** - During the course of the txn, intermittent status of various participants is not visible to the external world.\n* **Durability** - means when the txn is committed, then it is guaranteed that the txn is complete and the db or JMS updates are permanent.\n\n## BASE property\n\n* Basically Available\n* Soft state\n* Eventual Consistency\n\n## ACID vs. BASE\n\n???\n\n## CAP Theorem\n\ndistributed databases uses.\n\nhttp://ivoroshilin.com/2012/12/13/brewers-cap-theorem-explained-base-versus-acid/\n\n### Combination 1: CA \n\n* What does it mean?\n* When to use this?\n \n### Combination 2: CP \n\n* What does it mean?\n* When to use this?\n \n### Combination 3: AP \n\n* What does it mean?\n* When to use this?\n\n# Transaction Models\n\n## Local transactions\n\n* Txn is not managed by the framework, but by the local resource manager like db or messaging provider.\n* Developer manages connection, not the txn.\n* **Pros**\n  * Simple code - All you have to do is to reset the auto commit on Connection to false\n  * Works well for simple applications\n* **Cons/limitations**\n  * Error-prone. Plenty of room for developers to make mistakes which could be disastrous.\n  * Works only on a single resource. Cannot co-ordinate a txn across global resources like Db and EMS.\n  * Say if the txn code is split between different DAOs, the connection needs to be explicitly passed (called as connection passing strategy) which is typically error-prone.\n\n## Programmatic transactions\n\n* Leverages JTA API implementation\n* Developer manages txn rather than the connection, using javax.transaction.UserTransaction\n\n``` java EJB Example\nUserTransaction txn = sessionCtx.getUserTransaction();\ntxn.begin();\ntry{\n    myDAO.updateOne(...);\n    myDAO.updateTwo(...);\n    txn.commit();\n} catch(...){\n    txn.rollback();\n    throw e;\n}\n```\n\n``` java Spring Example\norg.springframework.transaction.support.TransactionTemplate = new ...\ntransactionTemplate.execute(new TransactionCallback(){\n    public Object doInTransaction(TransactionStatus status){\n      try{\n          myDAO.updateOne();\n      }catch(...){\n          status.setRollbackOnly();\n          throw e;\n      }\n    }\n  }\n);\n```\n\n* In the above EJB example, txn context is propagated to the DAO. Unlike the local txn model, DAO need not manage connections/txns. All it needs to do is get connections from a pool.\n* In the above Spring example, there is no need to explicitly invoke begin() or commit(). Also, the rollback is hinted via the txn status, and not on txn itself.\n* Typically an instance of `UserTransaction` is obtained via JNDI look up. \n\n``` java\nUserTransaction txn = (UserTransaction)new InitialContext()\n\t\t\t\t\t.lookup(\"javax.transaction.UserTransaction\");\n```\n\nHowever, the look up string name could be different for app servers. To run the code outside of a container like for unit test cases, TransactionManager interface is used as below.\n\n``` java Load the txn manager factory class\n//Websphere EJB txn manager example\nClass txnClass = Class.forName(\"com.ibm.ejs.jts.jta.TransactionManagerFactory\"); \n\nTransactionManager mgr = (TransactionManager)txnClass\n\t\t\t\t\t.getMethod(\"getTransactionManager\", null).invoke(null, null);\n\n//Start the txn via txn manager\nmgr.begin();\n```\n\n* When to use?\n  * client-initiated transactions\n  * Localized JTA transactions - If the process has multiple steps and if a txn is required only during a particular phase, then the only way to achieve this localized JTA txn is via programmatic model.\n  * For performance reasons.\n* Cons\n  * Error-prone - since developer is handling txns, if exceptions are not handled properly in the code, it could be disastrous.\n  * Transaction Context Problem: A txn context cannot be passed from a DAO that implements programmatic txn model into another DAO implementing the same txn model. Because, when one of them invoke the other, both will try to begin a new txn on separate threads. This violates the ACID principle since failure in other thread won't be visible to the other.\n\n## Declarative transactions\n\n* Framework or container manages the txn (which is why it is also called Container Managed Transactions or CMT)\n* Txns are configured through configuration parameters. e.g., XML descriptors in EJB or bean definition file `ApplicationContext.xml` in Spring.\n* Developer only says when to rollback. In Spring, rollback rules are specified via `TransactionAttributeSource` interceptor.\n\n``` java EJB Example\n@Stateless\n@TransactionManagement(TransactionManagementType.CONTAINER)\npublic class MyDAO{\n   @TransactionAttribute(TransactionAttributeType.REQUIRED) \n   public void update(){\n      try{\n          myDAO.updateOne(...);\n          myDAO.updateTwo(...);\n      }catch(...){\n          sessionCtx.setRollbackOnly();\n          throw e;\n      }\n   }\n}\n```\n\n* As in the above EJB example, developer invokes only the setRollbackOnly method. At class level, we specify that it uses declarative transaction through the annotation. \n* In Spring, developer need not call the method explicitly. Instead the rollback rules of when to rollback is specified in the TransactionAttributeSource interceptor. We specify that it uses declarative transaction through TransactionProxyFactoryBean proxy - the txn bean is wrapped with a proxy.\n\n### Transaction Attributes\n\nIn declarative txn, we must tell the container when to begin a txn, which methods should participate in a txn, etc. There are 6 transaction attributes \n\n* Transaction Attributes\n  * can be specified at method-level and bean-level. \n  * bean-level setting applies for all the methods in the class, which can be overridden.\n  * even if not specified, default attribute is applied to all the methods.\n* Spring interface `Synchronization` provides callback methods for the `afterBegin()`, `beforeCompletion()`, and `afterCompletion()` of a JTA transaction.\n\n\n\n\n| Attribute Value (For Spring prefix PROPAGATION_ ) | Txn is needed to execute the method?| What if a txn is already open?| What if no txn open?| When to use? | \n| -- | -- | -- | -- | -- |\n| REQUIRED | Yes | Use it | Start a new one |    |\n| MANDATORY | Yes | An open txn must always exist before invoking the method | Throws exception. Never starts a new one. |   |\n| REQUIRESNEW | Yes. Always start a new txn. | Suspend existing txn, start new one and resume the previous one after completing the new one. | Start a new one | When an activity needs to be committed regardless of the surrounding txn. E.g. audit logging during trading operation |\n| SUPPORTS | No | Use it. In fact, any uncommitted change made by the surrounding txn is also visible. | It works as it and doesn’t start a new txn. |   |\n| NOTSUPPORTED | No | Suspend existing txn, complete the method invocation and resume the txn. |  | For example, invoking a stored proc containing a DDL within the context of an XA txn will throw exception. This attribute is useful in such cases. |\n| NEVER | No. Never start a txn. | Throws exception | N/A | |\n \n\n# Transaction Isolation Level\n\n\nTransaction isolation is a function of db concurrency and db consistency. As we increase the level of txn isolation, we in effect lower the db concurrency but increase the db consistency. (Isolation­­­ & Consistency are inversely proportional to concurrency )\n\n## Dirty Read / Read Uncommitted\n\n* Allows transactions to read non-committed updates made by other transactions.\n* Lowest level of isolation supported by EJB & Spring.\n\n## Read Committed\n\n* Allows multiple transactions to access the same data, hiding the non-committed updates from other transactions until they are committed.\n* This is the default isolation setting for most of the databases.\n\n## Repeatable Read\n\nEnsures that once a set of values are read from the db for a particular txn, that same set of values will be read every time the select statement is executed, unless the txn holding the read and write locks modifies the data.\n\n## Serializable\n\n* Interleaving txns are stacked up so that only one txn is allowed access to data at a time.\n* Lowest level of isolation supported by Java.\n\n| Dirty Read / Uncommitted Read | Read Committed | Repeatable Read | Serializable | \n| ----------------------------- | -------------- | --------------- | ------------ | \n| {% img /technology/dirty-read.png %} | {% img /technology/read-committed.png %} | {% img /technology/repeatable-read.png %} | {% img /technology/serializable.png %} |\n\n# Transaction Read Phenomena\n\nTransaction Read Phenomena\n\n\nhttp://docs.oracle.com/cd/B28359_01/server.111/b28318/consist.htm\n\n## Dirty Read / Uncommitted Read\n\n* One process (P1) modifies a row, and another process (P2) then reads that row before it is committed by P1. If P1 then rolls back the change, P2 will have read a row that was never committed and that may thus be considered to have never existed.\n* Isolation Level: `READ UNCOMMITTED`\n\n## Non-Repeatable Read\n\n* Process P1 reads a row. Process P2 then modifies or deletes that rows and commits the change. If P1 re-reads the row it receives the modified value or discovers the row has been deleted.\n* Isolation Level: `READ COMMITTED`\n\n## Phantom Read\n\n* Process P1 reads the set of rows N that satisfy some search condition. Process P2 then executes statements that generate one or more rows that satisfy the search condition. If P1 repeats the query it obtains a different collection of rows.\n* Phantom Vs. Non-repeatable\n  * The Non-Repeatable Read is a phenomena specific to a read of a single record. When data has changed in this record, and the record is read again, the changed data is returned. This is a non-repeatable read.\n  * The Phantom Read is a phenomenon that deals with queries that return sets. The thing that’s changing in a phantom read is not the data in the records; it’s the set membership that has changed.\n  * For records that have been deleted, if a transaction reads them (or rather fails to read them) it would seem that this is both a non-repeatable read and a phantom read. But for the purposes of the ISO/ANSI standard it is in fact considered a non-repeatable read.\n\n## Serializable Vs. Snapshot\n\n???\n\n# Distributed Transaction Processing\n\nDistributed txn is a txn that spans over 1 or more resources. It could be between 2 different dbs, or 2 different messaging channels, or db and a messaging queue/topic.\n\n## XA Transaction Processing\n\n{% img right /technology/xa-transaction.png %}\n\n* The X/Open XA Interface is a bi-directional system-level interface that forms the communication bridge between a transaction manager and 1 or more resource managers. \n* The Transaction Manager manages the lifecycle of a txn, and co-ordinates resources. In JTA, txn manager is abstracted through the javax.transaction.TransactionManager interface and implemented through the underlying transaction service.\n* The Resource Manager controls and manages the actual resource participating in the txn like db or JMS queue.\n* XA txn should only be used when a transaction needs to be coordinated between multiple resources, i.e., databases, queues or topics. \n\n* What is the relation between XA and JTA?\n\n???\n\n\n### XA Resource\n\n* Without XA, messages sent to a topic/queue are typically read by receivers immediately. With XA, the message in the queue would not be released until the txn is committed.\n* To perform a XA txn between multiple resources, each participating resource should be an XA resource. (Some vendors support a feature where 1 resource could be a non-XA resource.### )\n\n## 2-phase commit protocol\n\n* Mechanism used by XA to coordinate multiple resources during a global transaction. \n* A txn manager coordinates txns between resource managers using a two-phase commit protocol. \n* The two-phase commit protocol provides the ACID properties of transactions across multiple resources. \n* In phase 1, \n  * the transaction manager tells each resource to \"prepare\" to commit; that is, to perform all operations for a commit and be ready either to make the changes permanent or to undo all changes. \n  * Each resource manager responds back with READY, READ_ONLY or NOT_READY. \n* In phase 2, if all resource managers respond back with READY, the transaction manager tells all resource managers to commit their changes; otherwise, it tells them all to roll back and indicates transaction failure to the application. Participants that respond with a READ_ONLY are removed from the 2nd phase. \n* 2-phase commit is possible due to the bi-directional communication capabilities of the XA interface.\n* **Last Participant Support** / **Last Resource Commit**\n  * Some commercial containers allow this feature where an non-XA resource to participate in a global txn. The non-XA resource participates only in the phase 1 of the txn.\n\n| 2PC Commit Scenario | 2PC Rollback Scenario |\n| ------------------- | --------------------- |\n| {% img /technology/2pc-commit.png %} | {% img /technology/2pc-rollback.png %} |\n\n## Heuristic Exceptions\n\nDuring the 2-phase commit process a Resource Manager may use heuristic decision making and either commit or rollback its work independent of the Txn Mgr. Heuristic decision making is a process that involves making intelligent choices based on various internal and external factors. When a Resource Manager does this it is reported back to the client through Heuristic Exception.\n\nThey only occur under XA during the 2-phase commit process, specifically after a participant has responded in phase 1. The most common reason for this is a timeout condition between phase 1 and 2. When communication is lost or delayed, the resource managers might make a decision to commit or rollback its work in order to free up resources.\n\n### Heuristic Exception Types\n\nThe 3 JTA Heuristic exceptions in JTA are\n\n* HeuristicRollbackException - between phase 1 and 2, if *all the resource mgrs* decides to rollback the txn, then upon entering phase 2 of the commit request this exception is thrown back to the caller.\n* HeuristicMixedException - same as above, but this is thrown if *one of the resource mgrs* decides to rollback.\n* HeuristicCommitException\n\n# Transaction Strategies\n\nTwo golden rules apply to all of the transaction strategies :\n\n* The method that starts the transaction is designated as the transaction owner\n* Only the transaction owner can roll back the transaction\n\n## 1. API Layer Strategy\n\n{% img right /technology/api-txn-strategy.png %}\n\n* Transaction Owner: API Layer - this is where the begin, commit and rollback of a txn occurs\n* When to apply this?\n  * apps with coarse-grained API layer\n  * apps with multiple client channels like webservice client, desktop client, web client, etc.\n* Rules for implementing this strategy\n  * only public methods in the API layer should have txn logic\n  * all public write methods are marked with REQUIRED txn attribute\n  * all public read method are marked with SUPPORTS\n  * all public write methods should handle checked exceptions with a rollback logic\n* Limitations/Restrictions\n  * When a public write method calls another public write method in a txn, and if an exception occurs, the rollback logic could potentially be handled by the 2nd method instead of the txn owner.\n  * Clients cannot make a multiple calls to API layer as a single unit of work.\n  * Extra attention needed if the same public method is called by clients that act as a txn owner and clients does not start a txn. (see [IBM article](http://www.ibm.com/developerworks/java/library/j-ts3/index.html#restrictions) for more details)\n\n## 2. Client Orchestration Strategy\n\n* Transaction Owner: Client Layer. Though both client & API layer contains the txn logic, only the client layer begins, commits and rolls back the txn. API layer has only  txn attributes marked on the methods.\n* When to apply this?\n  * apps with complex and fine-grained API layer\n  * cannot use with clients that cannot propagate txn to API layer, e.g., JMS clients, web service clients, etc.\n* Rules for implementing this strategy\n  * only client & API layer contains the txn logic. Client layer is the txn owner\n  * typically with this strategy, programmatic model is used in client. The exception to this rule is if the client business delegate in the client layer controlling the transaction scope is managed as a Spring bean by the Spring Framework. In this case, you can use the declarative transaction model provided by Spring.\n  * all public write methods in API layer are marked as MANDATORY - no rollback logic in them\n  * all public read methods in API layer are marked as SUPPORT.\n  * If the client layer is making remote calls to the API layer, the client layer must use a protocol and transaction manager that supports the propagation of a transaction context (such as RMI-IIOP).\n* Limitations/Restrictions\n  * Client layer must be able to start a txn and propagate it to the API layer. This is not possible with JMS client or web service client\n\n## 3. High Concurrency Strategy\n\n???\n\n## 4. High Performance Strategy\n\n???\n\n# Open Items\n\n* MVCC, Optimistic locking\n* Paxos consensus protocol\n\n# Bibliography\n\n* Books\n  * Java Transaction Management Strategies - Mark Richards\n  * Java Transaction Processing: Design and Implementation - Mark Little, Jon Maron, Greg Pavlik\n  * Principles of Transaction Processing - Philip A. Bernstein, Eric Newcomer\n* Websites\n  * IBM - Txn Mgmt Series - Mark Richards - http://www.ibm.com/developerworks/views/java/libraryview.jsp?site_id=1&contentarea_by=Java&sort_by=Date&sort_order=1&start=1&end=6&topic_by=&product_by=&type_by=All%20Types&show_abstract=true&search_by=transaction%20strategies:&industry_by=&series_title_by=\n  * Spring Txn Mgmt - http://static.springsource.org/spring/docs/3.0.x/reference/transaction.html\n  * http://www.jboss.org/jbosstm/resources/fundamentals.html\n  * http://www.pjug.org/jta-j2ee-pjug-2003-07-22.ppt\n  * [Nuts And Bolts Of TP](http://www.subbu.org/articles/transactions/NutsAndBoltsOfTP.html)\n  * [Distributed transactions in Spring, with and without XA](http://www.javaworld.com/article/2077963/open-source-tools/distributed-transactions-in-spring--with-and-without-xa.html)\n"
  },
  {
    "id": 44,
    "title": "VCS",
    "url": "/technology/vcs.html",
    "content": "# Overview\n\n* Difference between VCS and DVCS. \n* What is the advantage of having a distributed VCS?\n  * no single point of failure in the event of a crash or corruption\n* Principles and best practices when it comes to branching\n\n\n# Git\n\n* Distributed VCS developed by Linus Torvalds\n* <span style=\"color:red\">Why Git?</span>\n* What is the advantage of having a staging area in Git?\n* Git Vs SVN\n\n## How Git works?\n\n{% img /technology/git-local-remote.png %}\n\n## Workflow models\n\n* **SVN-style centralized workflow** \n  * A very common Git workflow, especially from people transitioning from a centralized system, is a centralized workflow. Git will not allow you to push if someone has pushed since the last time you fetched, so a centralized model where all developers push to the same server works just fine.\n* **Integration Workflow**\n  * a single person who commits to the 'blessed' repository, and then a number of developers who clone from that repository, push to their own independent repositories and ask the integrator to pull in their changes. This is the type of development model you often see with open source or GitHub repositories.\n* **Dictator and Lieutenants Workflow**\n  * For more massive projects, you can setup your developers similar to the way the Linux kernel is run, where people are in charge of a specific subsystem of the project ('lieutenants') and merge in all changes that have to do with that subsystem. Then another integrator (the 'dictator') can pull changes from only his/her lieutenants and push those to the 'blessed' repository that everyone then clones from again.\n\n\n| Centralized workflow | Integration Workflow |\n| -------------------- | -------------------- |\n| {% img /technology/git-centralized-workflow.png %} | {% img /technology/git-integration-workflow.png %} |\n\n## Advantages\n\n* Distributed, not centralized: \n  * With Git, you have a local copy/clone of the entire repository which could be used offline. Due to this, there is no single point of failure in case of a crash or corruption. Every developer has his own copy of the repository. \n* Smaller & Faster - To save space and transfer time, the data is stored after applying compression.\n* Branching and merging is easier\n* Atomic transactions: Like SVN, transactions are atomic - ensures that the version control database is not left in a partially changed or corrupted state while an update or commit of number of unrelated changes is happening.\n* Content-Addressable file store - SHA1 hash value is generated out of the file contents to identify a file.\n\n## Basic concepts\n\n* Checkout vs clone, Commit Vs Push\n* Branching vs Forking\n  * Branches are light-weight and merging is easy.\n  * In SVN, each file & folder can come from a different revision or branch. This leads to confusion in case of a failure.\n* Workflows\n  * Unlike other VCS systems, Git does not impose any particular workflow.\n  * Well-suited for open source community development. \n  * Git-SVN Bridge - The central repository is a Subversion repo, but developers locally work with Git and the bridge then pushes their changes to SVN.\n* Clean command - what does it do?\n* Bisect command - what does it do?\n* Revision or version numbers\n* Unlike SVN which creates .svn directories in every single folder, Git only creates a single .git folder.\n* Stashing - ???\n* Sparse checkouts.\n* Git tracks content rather than file - renaming a file, moving it to a different location\n* Command line, TortoiseGit, \n* version control outside of source code\n\n\nhttps://git.wiki.kernel.org/index.php/GitSvnComparsion\n\n## Advanced Concepts\n\n### Content-Addressable Names\n\nThe Git object store is organized and implemented as a content-addressable storage system. Specifically, each object in the object store has a unique name produced by applying SHA1 to the contents of the object, yielding an SHA1 hash value. Because the complete contents of an object contribute to the hash value and the hash value is believed to be effectively unique to that particular content, the SHA1 hash is a sufficient index or name for that object in the object database. Any tiny change to a file causes the SHA1 hash to change, causing the new version of the file to be indexed separately. SHA1 values are 160-bit values that are usually represented as a 40-digit hexadecimal number, such as 9da581d910c9c4ac93557ca4859e767f5caf5169. Sometimes, during display, SHA1 values are abbreviated to a smaller, unique prefix. Git users speak of SHA1, hash code, and sometimes object ID interchangeably.\n\nAn important characteristic of the SHA1 hash computation is that it always computes the same ID for identical content, regardless of where that content is. In other words, the same file content in different directories and even on different machines yields the exact same SHA1 hash ID. Thus, the SHA1 hash ID of a file is an effective globally unique identifier. A powerful corollary is that files or blobs of arbitrary size can be compared for equality across the Internet by merely comparing their SHA1 identifiers.\n\n### Pack files\n\nEfficient file storage mechanism. If you were to just change or add one line to a file, Git might store the complete, newer version and then take note of the one line change as a delta and store that in the pack too.\n\nThe main points I like about DVCS are those :\n\nYou can commit broken things. It doesn't matter because other peoples won't see them until you publish. Publish time is different of commit time.\nBecause of this you can commit more often.\nYou can merge complete functionnality. This functionnality will have its own branch. All commits of this branch will be related to this functionnality. You can do it with a CVCS however with DVCS its the default.\nYou can search your history (find when a function changed )\nYou can undo a pull if someone screw up the main repository, you don't need to fix the errors. Just clear the merge.\nWhen you need a source control in any directory do : git init . and you can commit, undoing changes, etc...\nIt's fast (even on Windows )"
  },
  {
    "id": 45,
    "title": "Web Concepts",
    "url": "/technology/webprogramming/webconcepts.html",
    "content": "[TOC]\n\n# HTTP\n\n## HTTP Basics\n* Browser-based web applications see only a tiny fraction of the features of HTTP. \n* Non-RESTful technologies like SOAP and WS-* use HTTP strictly as a transport protocol and thus use a very small subset of its capabilities. Many would say that SOAP and WS-* use HTTP solely to tunnel through firewalls\n* HTTP Request has 4 parts:  the method, the target URL, the HTTP headers, and the entity-body.\n  * HTML `<a>` tag: has URL and the HTTP method(implicitly definied by HTML spec)\n  * HTML form: has all 4 parts in it.\n  * URI Template: only has the URL part. It defines nothing about the HTTP request except for the target URI. It’s not telling you to make a GET request,   a POST request, or any kind of request in particular. That’s why URI Templates   don’t make sense on their own.\n\n## HTTP Methods\n\nHTTP has its well-known verbs, officially known as methods or protocol semantics. HTTP verbs 1 to 4 correspond to the CRUD (Create, Read, Update, Delete) operations. 5, 6 are used by clients to explore an API. \n\n #  | HTTP verb  | CRUD operation  | Safe  | Idempotent\n -  | ---------  | --------------  | ----  | ----------\n 1  | POST       | Create          | No    | No\n 2  | GET        | Read            | Yes   | Yes\n 3  | PUT        | Update          | No    | Yes\n 4  | DELETE     | Delete          | No    | Yes\n 5  | HEAD       | Read            | Yes   | Yes\n 6  | OPTION     |                 |       | \n 7  | CONNECT    |                 |       | \n 8  | TRACE      |                 |       | \n 9  | LINK       |                 | No    | Yes\n 10 | UNLINK     |                 | No    | Yes\n \n Any GET request should be sideeffect free (idempotent) because a GET is a read rather than a create, update, or delete operation. A GET as a read with no side effects is called a 'safe GET'.\n\n## HTTP Content Negotiation (Conneg)\n\nClients invoking the services could expect the response in various data formats, languages and encodings. HTTP Content Negotiation feature comes handy for such cases.\n\n* Response Data Format\n  * clients could specify the response format via \"Accept\". If the requested format is not supported, then 'not accepted' error is returned. \n```\nGET http://example.com/stuff\nAccept: application/xml, application/json\n```\n  * specifying preference using wild cards. \n```\nGET http://example.com/stuff\nAccept: text/*, text/html;level=1, */*, application/xml\n```\n  * Order of preference\n    * when multiple preference are provided, the most specific types takes priority. In above example, 'text/html;level=1' takes precedence.\n    * 'q' MIME type property could be used as well. Higher the q value, more preferred it is. Default q value is 1.0. e.g., `text/*;q=0.9, */*;q=0.1, audio/mpeg, application/xml;q=0.5`. \n* Language Negotiation\n```\nGET http://example.com/stuff\nAccept-Language: fr;q=1.0, es;q=1.0, en=0.1\n```\n* Encoding Negotiation\n```\nGET http://example.com/stuff\nAccept-Encoding: gzip;q=1.0, compress;0.5; deflate;q=0.1\n```\n\n## Caching\n\n* Browser caching\n* Proxy caches (CDNs)\n* HTTP caching\n  * Cache-control\n    * private - shared intermediaries like proxy or CDNs cannot cache. Only clients can cache.\n    * public - anyone can cache\n    * no-cache - \n    * no-store - cached data is stored in disks.\n    * no-transform - intermediary caches typically transforms data like images by compressing.\n    * max-age - expiration time\n    * s-maxage - expiration time for intermediary caches\n  * Revalidation: When the cache is stale, the cacher can ask the server if the data it is holding is still valid. This is called revalidation. To be able to perform revalidation, the client needs some extra information from the server about the resource it is caching. The server will send back a Last-Modified and/or an ETag header with its initial response to the client. If the client supports revalidation, it will store this timestamp along with the cached data.\n\n    * Last-Modified<br/>\n`HTTP/1.1 200 OK`<br/>\n`Content-Type: application/xml`<br/>\n`Cache-Control: max-age=1000`<br/>\n`Last-Modified: Tue, 15 May 2009 09:56`\n\n\n    * Conditional GET\n       * the client may opt to revalidate its cache of the item. To do this it does a conditional GET request by passing a request header called If-Modified-Since with the value of the cached Last-Modified header. For example: \n```\nGET /customers/123 HTTP/1.1\nIf-Modified-Since: Tue, 15 May 2009 09:56 EST\n```\n\n* ETag or Entity Tag\n  * The ETag header is a pseudounique identifier that represents the version of the data sent back. Its value is any arbitrary quoted string and is usually an MD5 hash. Here’s an example response:\n```\nHTTP/1.1 200 OK\nContent-Type: application/xml\nCache-Control: max-age=1000\nETag: \"3141271342554322343200\"\n```\n\n---\n\n# Web Tools\n\n* [cUrl](http://curl.haxx.se/)\n* Web Log Analytics Tool - Splunk\n* [Simian Army](http://techblog.netflix.com/2011/07/netflix-simian-army.html)\n* [Chaos monkey](http://techblog.netflix.com/2012/07/chaos-monkey-released-into-wild.html)\n\n\n# Bibliography\n\n* Books\n  * RESTful Web APIs - OReilly 2013\n  * HTTP - The Definitive Guide"
  },
  {
    "id": 46,
    "title": "Web Services",
    "url": "/technology/webservices.html",
    "content": "[TOC]\n\n\n# RESTful Services\n\n## What is REST?\n\n* stands for REpresentational State Transfer\n* A resource in the RESTful sense is something that is accessible through HTTP because this thing has a name—URI (Uniform Resource Identifier). \n* Though REST usually means REST over HTTP, it is actually not protocol-specific. Despite the occurrence of Transport in its name, HTTP acts as an API in RESTful approach and not simply as a transport protocol. \n\n## REST basic definitions\n\n* **What is a Resource?** The technical term for the thing named by a URL is resource.\n* **What is a Representation?** Whatever document the server sends back through the URL request, we call that document a representation of the resource. A representation can be any machine-readable document containing any information about a resource.\n* **What is Addressability?** The principle of addressability just says that every resource should have its own URL. If something is important to your application, it should have a unique name, a URL, so that you and your users can refer to it unambiguously.\n* **What is Application State?** Using a browser when you visit a site's homepage, from there to \"About Us\" page and from there to \"Contact Us\" page, the state of the browser is changing. In REST terminology, this is called 'Application State' change.\n* **What is Resource State?** State of the resources being served via the web service. It can be static or dynamic. PUT and POST methods typically alter the state of the resource.\n* **What is Hypermedia?** Hypermedia is the general term for things like HTML links and forms: the techniques a server uses to explain to a client what it can do next. Hypermedia is a way for the server to tell the client what HTTP requests the client might want to make in the future. It’s a menu, provided by the server, from which the client is free to choose.\n* **What is a hypermedia control?** HTML `<a>` tag, HTML `<form>`, HTML `<img>`, URI Template, etc.\n\n* **What is HATEOAS?** “Hypermedia as the engine of application state”. To say that hypermedia is the engine of application state is to say that we all navigate the Web by filling out forms and following links.\n* **What is REST?** Representational State Transfer. The server sends a representation via GET operations describing the state of a resource. The client sends a representation via POST/PUT describing the state it would like the resource to have. That’s representational state transfer.\n* **What is a safe method?** GET & HEAD are defined as safe HTTP methods. It’s just a request for information. Sending a GET request to the server should have the same effect on resource state as not sending a GET request—that is, no effect at all. Incidental side effects like logging and rate limiting are OK, but a client should never make a GET request hoping that it will change the resource state.\n* **What is Idempotence?** Sending a request twice has the same effect on resource state as sending it once. GET, DELETE and PUT are idempotent. This notion comes from math. Multiplying a number by zero or one is an idempotent operation. Once you multiply a number by zero, you can keep multiplying it by zero indefinitely and get the same result: zero. \n* URL Vs URI \n  * A URI has two subtypes: \n    1. The URL, which specifies a location, and \n    2. and the URN, which is a symbolic name but not a location.\n  * URI - short string to identify a resource. URI may or may not have a representation. URI is nothing but an identifier. E.g., `urn:isbn:9781449358063`. It designates a resource: the print edition of a book. Not any particular copy of this book, but the abstract concept of an entire edition.\n  * URL - short string to identify a resource. Every URL is a URI. URL always has a representation. URL is an identifier that can be dereferenced (get a representation of a resource using the identifier).\n\n## How REST works?\n\nIn the usual case of web service access to a resource, the requester receives a representation of the resource if the request succeeds. It is the representation that transfers\nfrom the service machine to the requester machine. In a REST-style web service, a client does two things in an HTTP request:\n\n* Names the targeted resource by giving its URI, typically as part of a URL.\n* Specifies a verb (HTTP method), which indicates what the client wishes to do; for example, read an existing resource, create a new resource from scratch, edit an existing resource, or delete an existing resource.\n \nAs web-based informational items, resources are pointless unless they have at least one representation. In the Web, representations are MIME typed. The most common type of resource representation is probably still text/html, but nowadays resources tend to have multiple representations.\n \nFor the record, RESTful web services are Turing complete; that is, these services are equal in power to any computational system, including a system that consists of SOAP-based web services or DOA stubs and skeletons.\n\n## RESTful Architectural Principles\n\n### Addressable resources\n\nThe key abstraction of information and data in REST is a resource, and each resource must be addressable via a URI (Uniform Resource Identifier).\n\n### A uniform, constrained interface\n\nThe Uniform, Constrained Interface - The idea behind it is that you stick to the finite set of operations of the application protocol you’re distributing your services upon. This means that you don’t have an “action” parameter in your URI and use only the methods of HTTP for your web services. HTTP has a small, fixed set of operational methods. Use a small set of well-defined methods to manipulate your resources.\n\n### Representation-oriented\n\ninteract with services using representations of that service. A resource referenced by one URI can have different formats. Different platforms need different formats. For example, browsers need HTML, JavaScript needs JSON (JavaScript Object Notation), and a Java application may need XML.\n\n### Communicate statelessly\n\nstateless means that there is no client session data stored on the server. Client should maintain sessions, if required. A service layer that does not have to maintain client sessions is a lot easier to scale, as it has to do a lot fewer expensive replications in a clustered environment. It’s a lot easier to scale up, because all you have to do is add machines.\n\n### Hypermedia As The Engine Of Application State (HATEOAS)\n\n* Hypermedia is a document-centric approach with the added support for embedding links to other services and information within that document format. The more interesting part of HATEOAS is the “engine.”  Let your data formats drive state transitions in your applications.\n* The architectural principle that describes linking and form submission is called HATEOAS. \n* HATEOAS stands for Hypermedia As The Engine Of Application State.\n* The idea of HATEOAS is that your data format provides extra information on how to change the state of your application. On the Web, HTML links allow you to change the state of your browser. When reading a web page, a link tells you which possible documents (states) you can view next. When you click a link, your browser’s state changes as it visits and renders a new web page. HTML forms, on the other hand, provide a way for you to change the state of a specific resource on your server. When you buy something on the Internet through an HTML form, you are creating two new resources on the server: a credit card transaction and an order entry.\n* When applying HATEOAS to web services, the idea is to embed links within your XML or JSON documents. While this can be as easy as inserting a URL as the value of an element or attribute, most XML-based RESTful applications use syntax from the Atom* Syndication Format as a means to implement HATEOAS.\n\n\n## WSDL & WADL \n\n### WSDL\n\n* stands for Web Service Description Language\n* WSDL documents can describe either category of web service, SOAP-based or REST-style, but there seems to be little interest in WSDLs and WSDL-based tools for RESTful services.\n\n### WADL\n\n* Web Application Description Language \n* JAX-RS implementations such as Metro do provide a WSDL counterpart, the WADL document that describes a JAX-RS service and can be used to generate client-side code.\n* wadl2java utility tool generates Java code from a WADL document.\n* The publisher of JAX-RS service generates the WADL dynamically, although a WADL, like a WSDL, can be edited as needed—or even written from scratch. The syntax for getting the WADL differs slightly among JAX-RS implementations. In the Jersey implementation, the document is available as application.wadl. E.g, if the resource URI is localhost/resourceA/ then the Jersey generated WADL can be accessed at localhost/resourceA/application.wadl. If it were CXF, then localhost/resourceA?wadl\n* The WADL document is language-neutral but its use is confined basically to the Java world. Other languages and frameworks have their counterparts; for example, Rails has the ActiveResource construct that lets a client program interact with a service but without dealing explicitly with documents in XML or JSON.\n* The trade-off in using a tool such as wadl2java to avoid dealing explicitly with XML or similar payloads:\n  * The upside is avoiding an XML or comparable parse.\n  * The downside is learning yet another API.\n\n## Java APIs for RESTful services\n\nJava Web Service APIs include:\n\n* HttpServlet and its equivalents (e.g., JSP scripts)\n* JAX-RS (Java API for RESTful services) - Jersey is the reference implementation\n* Restlet, which is similar in style to JAX-RS\n* JAX-WS (Java API for Web Services) which is a relatively low-level API. Metro is the reference implementation.\n\n### Servlet based Web Services\n\nJAX-RS and Restlet are roughly peers (arguably). Both of these APIs emphasize the use of Java annotations to describe the RESTful access to a particular CRUD operation. Each framework supports the automated generation of XML and JSON payloads. When published with a web server such as Tomcat or Jetty, JAX-RS and Restlet provide servlet interceptors that mediate between the client and the web service.\n\n### JAX-RS API\n\nJAX-RS is a framework that focuses on applying Java annotations to plain Java objects. \n\n* It has annotations to bind specific URI patterns and HTTP operations to individual methods of your Java class. (@Path and @GET, etc.,)\n* It has parameter injection annotations so that you can easily pull in information from the HTTP request. (@PathParam)\n* It has message body readers and writers that allow you to decouple data format marshalling and unmarshalling from your Java data objects. \n* It has exception mappers that can map an application-thrown exception to an HTTP response code and message.\n\nIn vanilla JAX-RS, services can either be singletons or per-request objects. \n\n* A singleton means that one and only one Java object services HTTP requests. \n* Per-request means that a Java object is created to process each incoming request and is thrown away at the end of that request. Per-request also implies statelessness, as no service state is held between requests.\n\nIn JAX-RS, any non-JAX-RS-annotated parameter is considered to be a representation of the HTTP input request’s message body. Only one Java method parameter can represent the HTTP message\nbody. This means any other parameters must be annotated with one of the JAX-RS annotations.\n\nIn JAX-RS, you are also allowed to define a Java interface that contains all your JAX-RS annotation metadata instead of applying all your annotations to your implementation class. This approach isolates the business logic from all the JAX-RS annotations. The JAX-RS specification also allows you to define class and interface hierarchies if you so desire.\n\n* Implementations include Jersey (RI), JBoss RESTEasy, Apache Wink and Apache CXF, Apache Axis2???\n* relies upon Java annotations to advertise the RESTful role that a class and its encapsulated methods play.\n* JAX-RS has APIs for programming RESTful services and clients against such services; the two APIs can be used independently.\n* JAX-RS uses Java annotations heavily but there are no annotations to express hyperlinks\n\n#### @Path\n\nThe `@javax.ws.rs.Path` annotation in JAX-RS is used to define a URI matching pattern for incoming HTTP requests. It can be placed upon a class or on one or more Java methods. For a Java class to be eligible to receive any HTTP requests, the class must  be annotated with at least the `@Path(\"/\")` expression. These types of classes are called JAX-RS root resources.\n\n`@Path` can have complex matching expressions so that you can be more specific on what requests get bound to which incoming URIs. `@Path` can also be used on a Java method as sort of an object factory for subresources of your application.\n\nTo receive a request, a Java method must have at least an HTTP method annotation like `@javax.ws.rs.GET` applied to it. This method may or may not have an `@Path` annotation on it, though. \n\n``` java @Path at class level\n@Path(\"/orders\")\npublic class OrderResource {\n    @GET\n    public String getUnpaidOrders() {\n       ...\n    }\n}\n\nRelative URI: /orders\n```\n\n``` java @Path at class and method level\n@Path(\"/orders\")\npublic class OrderResource {\n    @GET\n    @Path(\"unpaid\")\n    public String getUnpaidOrders() {\n       ...\n    }\n}\nRelative URI: /orders/unpaid\n```\n\n``` java @Path with wildcard expressions\n@GET\n@Path(\"customers/{firstname}-{lastname}\")\npublic String getCustomer(@PathParam(\"firstname\") String first, @PathParam(\"lastname\") String last) {\n   ...\n}\n```\n\n``` java @Path with regular expressions\nRegular expressions\n@GET\n@Path(\"{id : \\\\d+}\")\npublic String getCustomer(@PathParam(\"id\") int id) {\n   ...\n}\n```\n\n##### Matrix Parameters\n\nE.g., `http://example.cars.com/mercedes/e55;color=black/2006`\n\nMatrix parameters are name-value pairs associated with a URI. These are different from query parameters. These are more like adjectives and are not included to uniquely identify a resource.\n\n##### Subresource Locators\n\nSubresource locators are Java methods annotated with `@Path`, but with no HTTP method annotation, like `@GET`, applied to them. This type of method returns an object that is, itself, a JAX-RS annotated service that knows how to dispatch the remainder of the request.\n\n#### JAX-RS Injections - Request header related annotations\n\nWhen the JAX-RS provider receives an HTTP request, it finds a Java method that will service this request. If the Java method has parameters that are annotated with any of these injection annotations, it will extract information from the HTTP request and pass it as a parameter when it invokes the method.\n\n1. `@PathParam` - to extract values from URI template parameters.\n* `@MatrixParam` - to extract values from a URI’s matrix parameters.\n* `@QueryParam` - to extract values from a URI’s query parameters.\n* `@FormParam` - to extract values from posted form data.\n* `@HeaderParam` - to extract values from HTTP request headers.\n* `@CookieParam` - to extract values from HTTP cookies set by the client.\n* `@Context` - This class is the all-purpose injection annotation. It allows you to inject various helper and informational objects that are provided by the JAX-RS API.\n\n#### HTTP Content Negotiation in JAX-RS\n\nThere are multiple ways to implement the content negotiation discussed above:\n\n* Each method is responsible for returning response in a specific format.\n\n``` java\n@Produces({\"application/xml\")\npublic Customer getCustomerXml(@PathParam(\"id\") int id) {...}\n\n@Produces({\"application/json\"})\npublic Customer getCustomerJson(@PathParam(\"id\") int id) {...}\n```\n\n* A single method could be responsible to return responses in either xml or json format. Return type is a Java object which is annotated with JAXB annotations. Based on the information in 'Accept', either XML or JSON is returned.\n\n``` java\n@Produces({\"application/xml\", \"application/json\"})\npublic Customer getCustomer(@PathParam(\"id\") int id) {...}\n```\n\n* For complex negotiations, where multiple combinations of data formats, languages and encodings need to be dealt, JAX-RS provides classes like HttpHeaders, Variant, VariantBuilder, etc. which could be leveraged.\n* Negotiation by URI patterns: Some client like Firefox browser do not support conneg. In such cases, embed conneg information in URI. E.g., \n\n```\n/customers/en-US/xml/3323\n/customers/3323.xml.en-US\n```\n\n* Custom media types: Example: `application/vnd.rht.customers+xml`. The convention is to combine a vnd prefix, the name of your new format, and a concrete media type suffix  delimited by the “+” character.\n\n### RESTlet \n\n* The Restlet web framework supports RESTful web services, and the API is similar to JAX-RS; indeed, a Restlet application can use JAX-RS annotations such as @Produces instead of or in addition to Restlet annotations.\n* A Restlet web service has three main parts, each of which consists of one or more Java classes:\n  * A programmer-defined class, in this example AdagesApplication, extends the Restlet Application class. The purpose of the extended class is to set up a routing table, which maps request URIs to resources. The resources are named or anonymous Java classes; the current example illustrates both approaches. The spirit of Restlet development is to have very simple resource classes.\n  * There are arbitrarily many resource classes, any mix of named or anonymous. In best practices, a resource implementation supports a very small number of operations on the resource—in the current example, only one operation per resource. For example, the adages2 service has seven resources: six of these are named classes that extend the Restlet ServerResource class and the other is an anonymous class that implements the Restlet interface. The named classes are CreateResource, the target of a POST request; UpdateResource, the target of a PUT request; XmlAllResource, the target of a GET request for all Adages in XML; JsonAllResource, the target of a GET request for all Adages in JSON; XmlOneResource, the target of a GET request for a specified Adage; and so on.\n  * The backend POJO classes are Adage and Adages, each slightly redefined from the earlier adages web service.\n* These APIs also mimic the routing idioms that have become so popular because of frameworks such as Rails and Sinatra.\n\n### JAX-WS API\n\n* JAW-WS is an API used mostly for SOAP-based services but can be used for REST-style services as well. In the latter case, the @WebServiceProvider annotation is central. The @WebServiceProvider interface is sufficiently flexible that it can be used to annotate either a SOAP-based or a REST-style service; however, JAX-WS provides a related but higher level annotation, @WebService, for SOAP-based services. The @WebServiceProvider API is deliberately lower level than the servlet, JAX-RS, and Restlet APIs, and the @WebServiceProvider API is targeted at XML-based services. For programmers who need a low-level API, Java supports the @WebServiceProvider option. JAX-RS, Restlet, and @WebServiceProvider have both service-side and client-side APIs that can be used independently of one another. For example, a Restlet client could make calls against a JAX-RS service or vice versa.\n* JAX-WS includes APIs for RESTful and SOAP-based web services, although JAX-WS seems to be used mostly for the latter. The reference implementation is Metro, which is part of the GlassFish project. Although JAX-WS technically belongs to enterprise rather than core Java, the core Java JDK (1.6 or greater) includes enough of the Metro distribution to compile and publish RESTful and SOAP-based services. JAX-RS and Restlet are state-of-the-art, high-level APIs for developing RESTful services; by contrast, the JAX-WS API for RESTful services is low-level. Nonetheless, JAX-WS support for RESTful services deserves a look, and the JAX-WS API for SOAP-based services.\n* The JAX-WS API has two main annotations. \n* `@WebServiceProvider` - a POJO class annotated this can deliver both SOAP-based and a RESTful one\n\n\nFollowing are the JAX-WS Implementations\n\n#### Metro\n\n* http://www.oracle.com/technetwork/java/index-jsp-137051.html \n* is the reference implementation\n* integrated web services stack provided by Oracle Java. \n* Metro stack consisting of JAX-WS, JAXB, and WSIT (Web Services Interoperability Technologies), enable you to create and deploy secure, reliable, transactional, interoperable Web services and clients.\n\n#### Apache CXF\n\n* Apache CXF is an open source services framework. CXF helps you build and develop services using frontend programming APIs, like JAX-WS and JAX-RS. These services can speak a variety of protocols such as SOAP, XML/HTTP, RESTful HTTP, or CORBA and work over a variety of transports such as HTTP, JMS or JBI.\n* Features: Generating WSDL from Java and vice-versa, Spring support, OSGi support, WS* support, proprietary Aegis Databinding (similar to JAXB), RESTful services\n\n#### Apache Axis2\n\n* a Web Services / SOAP / WSDL engine\n* Features: proprietary ADB Databinding (faster than CXF)\n\n\n# SOAP Services\n\nThere are two ways of developing SOAP web services; contract-first and code-first approaches. \n\n1. In a contract-first approach, the web service definition or the WSDL is created initially and the service implementation is done after that. \n2. In a code-first approach, the service implementation classes are developed at the beginning and usually the WSDL is automatically generated by the service container in which the web service is deployed.\n\n## Downsides of SOAP services\n\nThe performance degradation due to heavy XML processing and the complexities associated with the usage of various WS-* specifications are two of the most common disadvantages of the SOAP messaging model.\n\n## Difference between REST and SOAP\n\n* SOAP is a messaging protocol in which the messages are XML documents, whereas REST is a style of software architecture for distributed hypermedia systems, or systems in which text, graphics, audio, and other media are stored across a network and interconnected through hyperlinks.\n* In the Web, HTTP is both a transport protocol and a messaging system because HTTP requests and responses are messages. The payloads of HTTP messages can be typed using the MIME (Multipurpose Internet Mail Extension) type system. MIME has types such as text/html, application/octet-stream, and audio/mpeg3.\n* A RESTful request targets a resource, but the resource itself typically is created on the service machine and remains there. A resource may be persisted in a data store such as a database system.\n\n# Data Binding Tools\n\n## GSON\n\nCreated by Google\n\n## JAX-B\n\n* JAX-B stands for Java API for data binding; the associating of a Java data type such as String to an XML Schema (or equivalent) type, in this case xsd:string\n* Implementations: ???\n* How to do in-memory transformations from Object to XML and vice versa\n* `schemagen` is a core Java JDK has a schemagen utility that generates an XML schema from a POJO source file. The utility can be invoked from the command: % schemagen Adage.java\n* `xjc` is another core JDK utility, that works in the other direction. Given an XML Schema, xjc can generate Java classes to represent the XML types in the schema.\n\n## Jackson\n\n* Created by FasterXML.\n* Jackson is an XML/json parser and data binder. \n* Jackson is a:\n  * FAST (measured to be faster than any other Java json parser and data binder)\n  * Streaming (reading, writing)\n  * Zero-dependency (does not rely on other packages beyond JDK)\n  * Powerful (full data binding for common JDK classes as well as any Java bean class, Collection, Map or Enum), Configurable\n  * Open Source (Apache License – or, until 2.1, alternatively LGPL)\n  * JSON processor. It provides JSON parser/JSON generator as foundational building block; and adds a powerful Databinder (JSON<->POJO) and Tree Model as optional add-on blocks.\n  * This means that you can read and write JSON either as stream of tokens (Streaming API), as Plain Old Java Objects (POJOs, databind) or as Trees (Tree Model). \n\n## Jettison\n\n??? \n\n## JSON\n\n* http://json-schema.org/\n* JSON-P format - P stands for with padding.\n* JSONP originally signified a way to work around the traditional same domain policy that prevents a page downloaded from a domain such as server.foo.org from communicating with a domain other than foo.org; JSONP still serves this purpose. The JSONP workaround involves script elements in a page, as these elements allow code to be downloaded from anywhere; the downloaded code can then perform arbitrary processing, which includes communicating with servers in arbitrary domains. JSONP works nicely with web services.\n* JSONP brings an event-driven API to client-side processing. Using JSONP, the programmer can do the following:\n  * Provide a URL to a data source.\n  * Specify a callback function to be executed, in browser context, once the data from the specified source arrives.\n\n## XStream\n\n* Created by ThoughtWorks\n* XStream includes a persistence API and has extensions in support of the Hibernate ORM (Object Relation Mapper). Among the more interesting features of XStream is that its API does not center on the get/set methods that define Java properties. XStream can serialize into XML an instance of a Java class that has nothing but private fields.\n* XStream also supports selective or fine-grained serialization and deserialization.\n* The core XStream library also supports the conversion of Java objects to and from JSON. There are various JSON drivers available in this library, the simplest of which is the JsonHierarchicalStreamDriver. This driver supports the serialization of Java objects to JSON but not the inverse operation. If deserialization from JSON to Java is needed, then a driver such as Jettison is a good choice because it interoperates cleanly with XStream.\n* XStream supports customized JSON serialization.\n* The XStream API is remarkably low fuss but likewise powerful. This API has gained steadily in popularity among Java developers who are looking for quick and easy ways to convert between Java objects on the one side and either XML or JSON documents on the other side.\n\n# Open Questions\n\n* There are no annotations in JAX-RS to express hyperlinks. You have to design those yourself. what does that mean?\n* JAX-RS defines: transitional links which describe optional next actions and structural links which provide optional detailed information. Transitional links tell a client where to proceed next, while structural links help to shorten representations in order to avoid aggregate data. Details are replaced by links. Transitional links have some support in JAX-RS 2.0, but structural links are not supported due to their level of complexity.????\n* URL opacity - http://www.zapthink.com/2012/10/08/the-power-of-opacity-in-rest/ \n* Routing idiom JAX-RS API implements mimic from Rails???\n\n# Tools\n\n* cUrl\n* soapUI\n\n# Bibliography\n\n* Books\n  * Building Web Services with Java (2E)\n  * Java Web Services - Up & Running - O'Reilly 2013\n  * RESTful Java with JAX-RS -2010\n  * RESTful Web APIs - O'Reilly 2013\n  * Web Services Testing with soapUI (2012)\n  * Service Oriented Architecture - Thomas Erl\n* Sites\n  * [Oracle - Web Services Interoperability Technologies](http://docs.oracle.com/cd/E19502-01/820-1072/ahiaj/index.html)\n  * [SlideShare - RESTful Web APIs](http://www.slideshare.net/rnewton/2013-06q-connycrestfulwebapis)\n\n"
  },
  {
    "id": 47,
    "title": "Written Communication",
    "url": "/softskills/written.html",
    "content": "## Excerpts from book: HBR Guide to Better Business Writing\n\n* Under the purpose of writing\n  * Know why you are writing. Know what you want the outcome to be.\n  * Say clearly and convincingly, what the issue is and what you want to accomplish.\n  * Focus on the reaction you are trying to elicit from the reader.\n* Understand your reader\n  * Respect your reader's time constraints. Understand that your readers have no time to waste: Get to the point quickly and clearly to ensure that your message gets read.\n  * Use a tone appropriate to your audience. \n  * Highlight the important thing \"what's in it for them\". If they can easily see how your message is relevant to them, they will be more likely to read it and respond.\n  * Connect with particular reader to connect with larger audiences. If you focus on a smart nonspecialist who is in your audience, you'll strike a balance between sophistication and accessibility. Your writing will be more appealing and persuasive.\n* Divide the writing into 4 separate tasks\n  * MACJ - Madman, Architect, Carpenter, Judge\n  * **Madman**\n    * gathers ideas and material first. Dumps all the best idea to come early by methodically brainstorming at the beginning of the process.\n  * **Architect**\n    * organizes the madman's raw material into a sensible outline. Distills ideas into 3 main propositions.\n    * Categorize the main points in sets of three (4 or more is too much)\n  * **Carpenter**\n    * Write the draft copy as quickly as possible using architect's outline and madman's ideas without worrying about perfecting the prose.\n    * Don't get stuck waiting for an inspiration. Try giving yourself 5 to 10 minutes for each section when drafting.\n    * Don't edit and perfect until the draft is finished.\n    * If you are stuck with something, move to the next section.\n  * **Judge**\n    * assume the role of the Judge to edit, polish, and improve the piece. Do this in several distinct passes, each time focusing on only one element of your writing.\n* Approach the writing as a series of manageable tasks using the MACJ method.\n* The Who-Why-What-When-How Chart\n* Who are you writing for? Consider your audience's concerns, motivations, and background.\n* Why are you writing? Keep your purposes firmly in mind. Every sentence should advance it.\n* What needs saying? Include only the main points and details that will get your message across.\n* When are you expecting actions to be taken? State your time frame.\n* How will your communication benefit your readers? Make it clear to readers how you're meeting their needs.\n\n\n### Sample Sentences\n\n* Friendly Tone \n  * Could it be that the work isn't finished?\n  * **Perhaps**, you are still planning...\n  * **We feel certain** that you have every intention to comply with the law...\n  * Although we have no doubt that your oversight was a **good-faith error**, ...\n* Good news\n  * We are **delighted**...\n* Bad news\n  * We are **troubled** to learn...\n"
  },
  {
    "id": 48,
    "title": "XML",
    "url": "/technology/xml.html",
    "content": "## DTD & XSD\n* Commonly used DTDs - FpML, DocBook, HRML, RDF\n* In XML DTD, how do you create an external entity reference in an attribute value? XML DTD dont support external entity reference in attribute values\n* How would you build a search engine for large volumes of XML data?\n* Diff b/w DTD & XML schema?\n  * DTD doesn't have external entity reference\n  * XSD supports data types\n  * XSD supports namespaces - solves the problem of tag name conflicts\n* Namespaces-\n* XPath, XSLT, XLink, XPointer, XQuery\n\n## XML Parsing\n* Steps to parse an XML with an example - DOM & SAX - Event-based parser\n* SAX (Sequential Access/Push)\n  * Disadvantage—user must keep track of previous events\n* DOM (Random Access/Pull)\n  * Advantage—simple to find particular elements\n* XMLPullParser (Sequential Access/Pull)\n  * Advantage—flow may be familiar to more programmers\n  * Disadvantage—may have more code than the other two alternatives\n* Diff b/w DOM & SAX?\n* Types\n  * Validating & Non-validating parsers\n  * Push parsers\n    * Advantage—can be simpler code, once paradigm is understood\n  * Pull parsers\n    * Advantage—appears as a common control style (e.g., loop) in multiple languages\n\n\n| | Sequential| Random | \n| -- | -- | -- |\n| Push | SAX | None |\n| Pull | XMLPullParser| DOM | \n\n## Data Binding\n\n### What is XML Data Binding?\n* http://www-128.ibm.com/developerworks/library/x-databdopt/\n* What other XML binding tools are available? - Sun's JAXB, Castor\n* Advantages\n  * DOM generates an in-memory tree for the entire document. In cases where the document is very large, DOM becomes quite memory intensive and performance degrades substantially. XMLBeans scores well on performance by doing incremental unmarshalling and providing xget methods to access built-in schema data types.\n  * SAX is less memory intensive compared to DOM. However SAX requires that developers write callback methods for event handlers. This is not required by XMLBeans.\n  * JAXB and Castor are XML/Java technology binding technologies like XMLBeans, but none of these provide 100 percent schema support. One of the biggest advantages of XMLBeans is its nearly 100 percent support for XML Schema. Also, XMLBeans allow access to the full XML Infoset. This is useful because the order of the elements or comments might be critical for an application.\n  * XMLBeans also provide for on-time validation of the XML instance being parsed.\n  * XMLBeans include innovative features such as XML cursors and support for XQuery expressions.\n\n### JAXB\n\n### XMLBeans\n"
  }
]